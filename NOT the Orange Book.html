
<!-- saved from url=(0032)http://cryptome.org/jya/ntob.htm -->
<html mode="normal"><head><meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
  <title>NOT the Orange Book</title>
<style id="night_mode">html[mode="night"] { -webkit-filter: contrast(120%) brightness(95%) invert(); }html[mode="night"] img, html[mode="night"] i, html[mode="night"] video { -webkit-filter: invert(); }html[mode="night"] i span { -webkit-filter: invert(); }html[mode="night"] object[type="application/x-shockwave-flash"], html[mode="night"] object[type="application/x-shockwave-flash"] { -webkit-filter: invert(); }html[mode="night"] embed[type="application/x-shockwave-flash"], html[mode="night"] embed[type="application/x-shockwave-flash"] { -webkit-filter: invert(); }</style><style type="text/css"></style><style type="text/css"></style><style>img.chromoji { width:1em !important; height:1em !important; }.chromoji-font, #chromoji-font { font-size:1em !important; }</style></head>
<body bgcolor="#ffffff" text="#000000" link="#0000ff" vlink="#551a8b">
<p>
1 November 1998<br>
Source: <a href="mailto:PaulMerrill@ACM.Org">Paul H. Merrill</a>
</p><p>
This document available Zip-compressed:
<a href="http://jya.com/ntob.zip">http://jya.com/ntob.zip</a> (96K)
</p><p>
  </p><hr>
<p>
<table cellpadding="40" align="Center" bgcolor="#ff8000" width="100%">
  <tbody><tr>
    <td><center>
	<table cellpadding="20" align="Center" bgcolor="white" width="100%">
	  <tbody><tr>
	    <td><h1 align="Center">
		<font color="Teal"><font color="Navy"><br>
		</font></font><big><big>NOT<br>
		</big></big>the Orange Book<br>
	      </h1>
	      <h3>
		<p align="Center">
		<b>A Guide to the Definition, Specification, Tasking, and<br>
		Documentation for the Development of Secure <br>
		Computer Systems<br>
		<small>Including Condensations of the Members of <br>
		the </small></b><small>the National Computer Security Center's<br>
		<b>Rainbow Series and Related Documents</b></small><br>
		<br>
		<br>
		<br>
		<b>By Paul H. Merrill</b><br>
		<br>
		<br>
	      </p></h3>
	      <p align="Center">
	      <b>Merlyn Press<br>
	      Wright-Patterson Air Force Base</b>
	      </p><p align="Center">
	      <b> 1992<br>
	      <br>
	      </b></p></td>
	  </tr>
	</tbody></table>
      </center>
    </td>
  </tr>
</tbody></table>
</p><p>
<br wp="br2">
</p><p>
  </p><hr>
<p align="center">
<strong>Works by the Author from Merlyn Press</strong>
</p><p align="center">
<strong>Graphics User's Manual for the NCR Worksaver System<br>
Appendix I: TRIGS COMPUSEC Requirements<br>
TRIGS Computer Lifecycle Management Plan<br>
TRIGS Software Risk Management Plan<br>
Test Report: Sigma II Silver Harvester<br>
SoftWare Evaluation Team Report<br>
Software Quality Assurance<br>
PHIP Segment Specification<br>
Rainbow Readers' Digest<br>
NOT The Orange Book</strong> <br wp="br1">
<br wp="br2">
  </p><hr>
<p align="center">
Copyright 1992 Paul H. Merrill
</p><p align="center">
All rights reserved with the exception of unrestricted use by the government.
</p><p align="center">
  </p><hr>
<p align="center">
</p><center>
  <table cellpadding="20" align="Center" width="75%">
    <tbody><tr>
      <td><h3 align="Center">
	  <strong>Dedication and Acknowledgement</strong>
	</h3>
	<p>
	To Hugh Lynn, without whom this never would have gotten started. To Terry
	Tucker, without whose inspiration this would not be what it is. To Larry
	Miner, without whose indulgence this would never have been finished. To Jim
	Plaisted, Laura Picon, Mel Hoeferlin, Dave Hensley, and Dan O'Connor, without
	whose kind words this would not have been as well-aimed. To Larry Yelowitz
	and DoctorDave Gobuty, without whose pressure the diamond might not be so
	pure. To Steve Job, for making Apple what it was. And, of course, to Mom
	and PoP.
	</p><h2 align="center">
	  <strong>Foreword</strong>
	</h2>
	<p>
	This book was started to serve as a text from which to teach an introductory
	course in Computer Security. As the writing progressed, it became apparent
	that more depth was needed than a simple introductory course would entail
	... and ... that the work would need to serve those people not taking the
	course. I sincerely hope that this helps you as much as it was intended to.</p></td>
    </tr>
  </tbody></table>
</center>
<p>
  </p><hr>
<h1 align="center">
  <strong>Introduction</strong>
</h1>
<p>
This book was written to help reduce the onslaught of information available
in the field of operational computer security to manageable proportions and
to help make sense of the process needed to correctly determine the level
of computer security needed for a specific program. There are four major
groups of intended readers who can gain from the use of this text.
</p><p>
<b>Active COMPUSEC Professionals:</b> Those who regularly work with COMPUSEC
issues will find that this book works quite nicely to bring together, in
a manageable size, the gems from a shelf full of reference publications.
After all, who can remember it all, all of the time; paper was invented so
people could forget. Also, this book should help to locate that fine nuance
which is "in one of those books over there" but eludes capture on the tip
of the tongue at the moment.
</p><p>
<b>Novice COMPUSEC Professionals:</b> Those who have only recently begun
to work the COMPUSEC issues will find that this book helps to point out what
they don't know and then take a good stab at filling the void, to working
levels at least.
</p><p>
<b>COMPUSEC-Associated Professionals:</b> For the mass of people who work
in association with COMPUSEC professionals, especially on a program which
has COMPUSEC as a significant portion of the effort, this book serves to
enlighten without wasting an inordinate amount of time.
</p><p>
<b>COMPUSEC Unknowns:</b> For those who aren't sure whether their program
requires active computer security measures, this book serves to point out
what there is to be gained by COMPUSEC in an integrated security engineering
effort.
</p><p>
<em><b>NOT The Orange Book</b></em> is not intended to replace the
<a href="http://www.radium.ncsc.mil/tpep/library/rainbow/">Rainbow Series
</a>or the associated publications produced by other governmental bodies.
Rather it seeks to point the way in a shorter and simpler format. But, just
as Cliff Notes are not the same as the classics covered by them, there is
still a need, at times, to read the full text of the standard documents.
Neither is this book intended to replace the engineering process (or the
thought process) in determining the computer security requirements. The use
of this book has been envisioned in the following ways. <br wp="br1">
<br wp="br2">
<b>Table of Contents:</b> The table of contents is written in the Old Style,
with major topics within the section included in the table itself. If a
particular topic is in question, between the titles and the topics, the
appropriate section should be able to be found with little difficulty. If
it is certain that the full text is going to be needed for close scrutiny,
the entry includes the title, number, and color (if a Rainbow Member) of
the unDigested document.
</p><p>
<b>Defining the System: </b>A guided tour of the thought processes and basic
algorithms involved seeks to help the Reader to determine the level of computer
security needed for the particular system and its environment. As a part
of this process the tradeoffs which need to be considered between computer
security and the other securities are discussed.
</p><p>
<b>Spare Parts Bin:</b> In the various portions of this section are the spare
parts needed to specify the requirements and task the work effort and
documentation for the various levels of computer security.
</p><p>
<b>Digests: </b>Each of the digests uses the information in the Table of
Contents, with amplification, as a header and follows with the highlights
from the particular book. If the digest leaves questions unanswered, going
to the full text is probably in order.
</p><p>
<b>Case Studies: </b>Through the use of several case studies (at high levels
of abstraction) the Reader may be able to focus the other information and
tools discussed and provided by this book.
</p><p>
<b>Glossary:</b> There are two "Glossaries" in this book. The first is the
digest of TG-004, the second is a glossary of the terms which need definition
in this book. While it would have been nice to have only one glossary, that
would have required deletion of TG-004 (not good for completeness) or the
inclusion of terms in the TG-004 digest which are not in TG-004 (not good
for purity.)
</p><p>
  </p><hr>
<br wp="br2">
<h1 align="center">
  <strong>Table of Contents</strong>
</h1>
<p>
<strong>Dedication and Acknowledgement</strong>
</p><p>
<strong>Foreword </strong>
</p><p>
<strong>Introduction</strong>
</p><p>
<strong>Table of Contents</strong>
</p><h3>
  <b><a href="http://cryptome.org/jya/ntob.htm#I">Section I: Building A Secure System</a></b>
</h3>
<blockquote>
  <strong>System Security Engineering Management</strong>
  <blockquote>
    Systems Security Engineering as a Part of Systems Engineering<br>
    CompuSec Engineering as a Part of Systems Security Engineering<br>
    The "Securities"<br>
    System Accreditation<br>
    Security After Deployment<br>
    The Fundamental Laws of Computer Security
  </blockquote>
  <p>
  <strong>Determining the System's Security Needs</strong>
  </p><blockquote>
    Threats and Vulnerabilities =&gt; Risks<br>
    Sharing the Security Needs ... or ... "CompuSec and the Securities"<br>
    Yellow Books (I &amp; II)<br>
    Lowering the CompuSec Needs
  </blockquote>
  <p>
  <strong>Statement of Work Issues</strong>
  </p><blockquote>
    Format Considerations
    <blockquote>
      Separate WBS Item / Scattered Throughout
      <blockquote>
	Cost <br>
	Quality<br>
	Oversight<br>
	Perceived Importance
      </blockquote>
    </blockquote>
    <p>
    System Security Engineering Management Program
    </p><blockquote>
      The Securities<br>
      Oversight of Program<br>
      Industrial Security and the Rest
    </blockquote>
    <p>
    Documentation
    </p><blockquote>
      For Itself<br>
      For Oversight Effort<br>
      Pertinent Documents
    </blockquote>
  </blockquote>
</blockquote>
<h3>
  <b><a href="http://cryptome.org/jya/ntob.htm#II">Section II: Spare Parts</a></b>
</h3>
<blockquote>
  <strong>C1 Class</strong>
  <blockquote>
    Discretionary Access Control (DAC)<br>
    Identification And Authentication<br>
    SOW Tasking
  </blockquote>
  <p>
  <strong>C2 Class</strong>
  </p><blockquote>
    Discretionary Access Control (DAC)<br>
    Identification And Authentication<br>
    Audit<br>
    System Security Architecture<br>
    SOW Tasking
  </blockquote>
  <p>
  <strong>B1 Class</strong>
  </p><blockquote>
    Discretionary Access Control (DAC)<br>
    Identification And Authentication<br>
    Audit<br>
    System Security Architecture<br>
    Labels<br>
    Mandatory Access Control (MAC)<br>
    SOW Tasking
  </blockquote>
  <p>
  <strong>B2 Class</strong>
  </p><blockquote>
    Discretionary Access Control (DAC)<br>
    Identification And Authentication<br>
    Audit<br>
    System Security Architecture<br>
    Labels &amp; Mandatory Access Control (MAC)<br>
    SOW Tasking
  </blockquote>
  <p>
  <strong>B3 Class</strong>
  </p><blockquote>
    Discretionary Access Control (DAC)<br>
    Identification And Authentication<br>
    Audit<br>
    System Security Architecture<br>
    Labels &amp; Mandatory Access Control (MAC)<br>
    SOW Tasking
  </blockquote>
  <p>
  <strong>A1 Class</strong>
  </p><blockquote>
    Discretionary Access Control (DAC)<br>
    Identification And Authentication<br>
    Audit<br>
    System Security Architecture<br>
    Labels &amp; Mandatory Access Control (MAC)<br>
    SOW Tasking
  </blockquote>
  <p>
  <strong>CDRL Inputs</strong>
  </p><p>
  <strong>Data Item Descriptions (DIDs)</strong>
  </p><blockquote>
    Subsystem Design Analysis Report<br>
    System Security Management Plan<br>
    Security Vulnerability Analysis<br>
    System/Subsystem Specification Document for AISs<br>
    Adversary Mission Analysis<br>
    Logistical Support Analysis
  </blockquote>
  <p>
</p></blockquote>
<h3>
  <b><a href="http://cryptome.org/jya/ntob.htm#III">Section III: Rainbow Readers' Digest</a></b>
</h3>
<blockquote>
  <strong>DOD 5200.28-STD Orange </strong>(Formerly: CSC-STD-001-83) <br>
  <strong>DoD Trusted Computer System Evaluation Criteria</strong>
  <blockquote>
    Fundamental Computer Security Requirements<br>
    Divisions and Classes of Systems<br>
    Testing Guidelines<br>
    Commercial Product Evaluation<br>
    Requirements
  </blockquote>
  <p>
  <strong>CSC-STD-002-85 Green <br>
  DoD Password Management Guideline</strong>
  </p><blockquote>
    Individual Password<br>
    Password Change<br>
    Password Protection<br>
    Password Length
  </blockquote>
  <p>
  <strong>CSC-STD-003-85 Yellow I <br>
  Computer Security Requirements</strong>
  </p><blockquote>
    Minimum User Clearance (R<sub>Min </sub>)<br>
    Maximum Data Sensitivity (R<sub>Max </sub>)<br>
    Risk Index<br>
    Computer Security Requirements
  </blockquote>
  <p>
  <strong>CSC-STD-004-85 Yellow II<br>
  Rationale Behind Computer Security Requirements</strong>
  </p><blockquote>
    Risk Index<br>
    Security Risk Index Matrix<br>
    Security Index Matrix For Open Security Environments<br>
    Security Index Matrix For Closed Security Environments
  </blockquote>
  <p>
  <strong>CSC-STD-005-85 Dark Blue<br>
  DoD Magnetic Remanence Security Guideline</strong>
  </p><blockquote>
    Declassification and Clearing<br>
    Declassification Permission<br>
    Properly Functioning Media<br>
    Non-functional Media<br>
    Destruction
  </blockquote>
  <p>
  <strong>NCSC-TG-001 Tan<br>
  A Guide to Understanding Audit</strong>
  </p><blockquote>
    Audit Requirements Overview<br>
    Audited Events<br>
    Selective Audit
  </blockquote>
  <p>
  <strong>NCSC-TG-002 Blue<br>
  Trusted Product Evaluations A Guide for Vendors</strong>
  </p><blockquote>
    Phases of the Trusted Product Evaluation Program<br>
    Technical Description of the Product<br>
    Legal Agreement
  </blockquote>
  <p>
  <strong>NCSC-TG-003 Tangerine I<br>
  A Guide to Understanding Discretionary Access Control</strong>
  </p><blockquote>
    Implementation Methodologies<br>
    Control Permission and Access Modes<br>
    Requirements
  </blockquote>
  <p>
  <strong>NCSC-TG-004 Aqua <br>
  Glossary of Computer Security Terms</strong>
  </p><p>
  <strong>NCSC-TG-005 Red I<br>
  Trusted Network Interpretation</strong>
  </p><blockquote>
    Security Policy<br>
    New Evaluation Areas<br>
    Network Components<br>
    Cascading
  </blockquote>
  <p>
  <strong>NCSC-TG-006 Tangerine II <br>
  A Guide to Understanding Configuration Management</strong>
  </p><blockquote>
    Configuration Management (CM) Use<br>
    CM Requirements<br>
    CM Tasks
  </blockquote>
  <p>
  <strong>NCSC-TG-007 Burgandy<br>
  A Guide to Understanding Design Documentation</strong>
  </p><blockquote>
    C2 Design Documentation Requirements<br>
    B1 Design Documentation Requirements<br>
    B2 Design Documentation Requirements<br>
    B3 Design Documentation Requirements<br>
    A1 Design Documentation Requirements
  </blockquote>
  <p>
  <strong>NCSC-TG-008 Lavender<br>
  A Guide to Understanding Trusted Distribution</strong>
  </p><blockquote>
    Trusted Distribution (TD) Assurances<br>
    Post-Production Protection<br>
    Transit Protection
  </blockquote>
  <p>
  <strong>NCSC-TG-009 Venice Blue<br>
  Computer Security Subsystem Interpretation</strong>
  </p><blockquote>
    Required Features<br>
    Assurance Requirements<br>
    Documentation Requirements
  </blockquote>
  <p>
  <strong>NCSC-TG-011 Red II<br>
  Trusted Network Interpretation Environments Guideline</strong>
  </p><blockquote>
    Network Security Architecture and Design<br>
    Risk Assessment<br>
    Network Security Services
  </blockquote>
  <p>
  <strong>NCSC-TG-013 Hot Pink<br>
  Rating Maintenance Phase Program Document</strong>
  </p><blockquote>
    Preevaluation Phase<br>
    Vendor Assistance Phase/Design Analysis Phase<br>
    Evaluation Phase<br>
    Rating Maintenance Phase
  </blockquote>
  <p>
  <strong>NCSC-TG-014 Purple<br>
  Guidelines for Formal Verification Systems</strong>
  </p><blockquote>
    Endorsement And ETL Listing<br>
    Technical factors<br>
    Features<br>
    Assurance<br>
    Required Documentation
  </blockquote>
  <p>
  <strong>NCSC-TG-015 Brown<br>
  A Guide to Understanding Trusted Facility Management</strong>
  </p><blockquote>
    Security Administrator<br>
    Secure Operator<br>
    Account Administrator<br>
    Auditor
  </blockquote>
  <p>
  <strong>NCSC-TG-017 Light Blue<br>
  Identification and Authentication</strong>
  </p><blockquote>
    Authentication by Knowledge<br>
    Authentication by Ownership<br>
    Authentication by Characteristic<br>
    Implementation<br>
    I&amp;A Requirements by Class
  </blockquote>
  <p>
  <strong>NCSC-TG-019 Blue<br>
  Trusted Product Evaluation Questionnaire</strong> <br wp="br1">
  <br wp="br2">
  <strong>NCSC-TG-020 Gray<br>
  Access Control List (ACL) Features for UNIX </strong>
  </p><p>
  <strong>NCSC-TG-021 Lilac<br>
  Trusted Database Management System Interpretation </strong>
  </p><blockquote>
    Conditions for Evaluating by Parts<br>
    Local/Global Requirements<br>
    Interpretation of the Orange Book Requirements
  </blockquote>
  <p>
  <strong>NCSC-TG-025 Green<br>
  Data Remanence in Automated Information Systems</strong>
  </p><blockquote>
    Standard Clearing / Purging Methods<br>
    Considerations<br>
    Approved Procedures for Various Media
  </blockquote>
  <p>
  <strong>NCSC-TG-026 Fluorescent Orange <br>
  Security Features User's Guide</strong>
  </p><blockquote>
    Audience<br>
    Format<br>
    Presentation<br>
    Example SFUGs
  </blockquote>
  <p>
  <strong>C Technical Report 79-91 Yellow<br>
  Integrity in Automated Information Systems</strong>
  </p><blockquote>
    Integrity Goals<br>
    Integrity Principles<br>
    Integrity Policies and Mechanisms<br>
    Integrity Separation Policies<br>
    General Integrity Policies
  </blockquote>
  <p>
  <strong>NTISSAM COMPUSEC/1-87<br>
  Advisory Memorandum on Office Automation Security </strong>
  </p><blockquote>
    User Responsibilities<br>
    Security Officer Responsibilities
  </blockquote>
  <p>
  <strong>MIL-STD 1785<br>
  System Security Engineering Program Management Requirements</strong>
  </p><blockquote>
    Concept Exploration Phase<br>
    Demonstration and Validation Phase<br>
    Full-Scale Development Phase<br>
    Production and Deployment Phase
  </blockquote>
  <p>
  <strong>DRS-2600-5502-86<br>
  Security Requirements for System High<br>
  and Compartmented Mode Workstations</strong>
  </p><blockquote>
    System High Requirements<br>
    Compartmented Mode Requirements
  </blockquote>
</blockquote>
<h3>
  <b><a href="http://cryptome.org/jya/ntob.htm#IV">Section IV: Case Studies</a></b>
</h3>
<blockquote>
  <strong>NDG: New Development Gonculator</strong>
  <blockquote>
    Threats<br>
    Data / Classified material<br>
    Implementation
  </blockquote>
  <p>
  <strong>UG: Upgrade Gonculator</strong>
  </p><blockquote>
    Threats<br>
    Data / Classified material<br>
    Implementation
  </blockquote>
  <p>
  <strong>CGG: Communications Group Gonculator </strong>
  </p><blockquote>
    Threats<br>
    Data / Classified material<br>
    Implementation
  </blockquote>
  <p>
  <strong>GIGS: Ground Intelligence Gonculator System </strong>
  </p><blockquote>
    Threats<br>
    Data / Classified material<br>
    Implementation
  </blockquote>
  <p>
  <strong>Yellow Books</strong>
  </p><blockquote>
    NDG Assessment<br>
    UG Assessment<br>
    CGG Assessment<br>
    GIGS Assessment
  </blockquote>
</blockquote>
<h3>
  <b><a href="http://cryptome.org/jya/ntob.htm#V">Section V: Notes</a></b>
</h3>
<blockquote>
  <strong>Abbreviations and Acronyms</strong>
  <p>
  <strong>Glossary</strong>
</p></blockquote>
<p>
  </p><hr>
<p>
</p><h1 align="center">
  <strong>Section <a name="I">I</a>:</strong>
</h1>
<h1 align="center">
  <strong>Building A Secure System </strong>
</h1>
<h2 align="center">
  <strong>I. Building a Secure Computer System</strong>
</h2>
<p>
As the Information Age progresses, the reliance on computers is increasing
at a steady pace. Along with this reliance comes an ever increasing need
to apply the standard management practices, which are a part of the rest
of our lives, to computers. Security has long been a standard management
practice which now needs to make its way into the management of computer
systems too. People who would never leave their office unlocked will leave
their computer modem activated without a second thought. People who would
never hand over their checkbook will leave their financial data on a diskette
unprotected. The same people who would never hand out the combination to
their safe will resist the use of password protection on a computer with
the same information stored. Security must be part and parcel of a computer
system, and it must be built into the system with minimum negative impact
and maximum return on the investment.
</p><h3>
  System Security Engineering Management
</h3>
<p>
The security aspects of a program are maintained and nourished through Systems
Security Engineering Management as set forth in MIL-STD-1785. Systems Security
Engineering covers the entire spectrum of security activities with an integrated
approach that allows for methodical and comprehensive coverage of the security
effort.
</p><p>
<u><b>Systems Security Engineering as a Part of Systems Engineering</b></u>
</p><p>
Through the Systems Engineering discipline, Systems Security Engineering
in general, and Computer Security (CompuSec) in particular, can be accomplished
in an efficient and orderly manner. The iterative analytical techniques which
are so much a part of the Systems Engineering process are totally applicable
to the requirements definition for the Systems Security Engineering process
as well. Top level functions still decompose into lower level functionality.
The design tradeoffs and requirements analysis are still studied, interpreted,
and selected in the same manner. MIL-STD-1785 gives the tasks to be performed
and their sequencing; Systems Engineering gives the methodology to accomplish
the tasking.
</p><p>
<u><b>Computer Security Engineering as a Part of Systems Security
Engineering</b></u>
</p><p>
Though only lightly touched upon in MIL-STD-1785, computer security (CompuSec)
is an integral part of system security engineering for programs which incorporate
computers processing sensitive data. Due to the ever increasing storage capacity,
processing power, and transmission rates, damages and losses from computers
have become a very real concern across the whole of society. An entire
briefcaseful of classified data will fit on a single diskette. The average
computer heist is orders of magnitude greater than the average bank robbery.
Because computers operate so much faster than humans, the computer must handle
a significant portion of the security.
</p><p>
<u><b>The "Securities"</b></u>
</p><p>
Systems Security Engineering is concerned with a group of security disciplines
which are interrelated and have significant overlap in the protection given
against various vulnerabilities. Each must be considered, along with its
strengths and weaknesses during system requirements definition and development.
</p><blockquote>
  <b>Information Security (INFOSEC):</b> Concerned with access to information
  without regard to the form of the information. (Closely related to CompuSec
  with a large area of overlap.)
  <p>
  <b>Physical Security:</b> Concerned with physical access to the protected
  resources. (Locks, doors, fences, and guards.)
  </p><p>
  <b>Computer Security (CompuSec):</b> Concerned with regulating and recording
  access to computer resources and the data residing in the computer.
  </p><p>
  <b>Personnel Security:</b> Concerned with the verified "Goodness" of the
  personnel involved with a system (Clearances).
  </p><p>
  <b>Product Security:</b> Concerned with the security of the "product" during
  the manufacturing process. (A CompuSec concern for Configuration Management
  and Trusted Distribution)
  </p><p>
  <b>Industrial Security:</b> Concerned with the developing contractors' security
  aspects and activities. (Higher Industrial Security is one way to lower CompuSec
  requirements.)
  </p><p>
  <b>Operations Security (OPSEC):</b> Concerned with operational information
  and the restricting of data to the appropriate personnel. (Loose Lips )
  </p><p>
  <b>Communications Security (COMSEC):</b> Concerned with the secure communications
  and cryptographical aspects. (Often lumped with CompuSec and called INFOSEC.)
  </p><p>
  <b>Emanations Security (EMSEC, Tempest):</b> Concerned with stray electronic
  impulses and the ability to use them to derive useful information.
  </p><p>
  <b>Administrative Security (Procedural Security):</b> Concerned with the
  procedures used to provide for security. (Hand-written audit trails,
  Administrative restriction to a given security level on a given machine,
  Two-Man rule, etc.)
</p></blockquote>
<p>
<u><b>System Accreditation</b></u>
</p><p>
No matter what kind of computer system is being developed, there will be
someone (or some agency), responsible for allowing the system to operate
with the data needed. This someone, the accreditor {or Designated Approving
Authority (DAA), or any number of other names depending on the system} looks
at the entire system and all of the securities and evaluates the interactions
to determine the overall security suitability of the total system. Early
and active involvement of the DAA in the development of the requirements
and the system design is necessary to the development of a secure system
which will be allowed to operate, as planned, when finished.
</p><p>
<u><b>Security After Deployment</b></u>
</p><p>
Whatever security is designed and built into the system during development
must take into account the security measures which will be implemented after
system deployment. Computer security measures require action from a security
person at least on a part-time basis and, for larger systems, teams of security
personnel are needed full time. In addition, the various implementation levels
for physical security and personnel security can either raise or lower the
necessary security measures which need to be incorporated into the computer
system itself. (Obviously the security measures for an Automatic Teller Machine
(ATM) are radically different than the measures for the bank's mainframe
computer.) Security measures considered during design and development must,
therefore, take into account usability and personnel availability as well
as other security measures which may modify the security needs of the computer
system itself.
</p><p>
<b><u>The Fundamental Laws of Computer Security</u> </b><br wp="br1">
<br wp="br2">
The First Law of Computer Security
</p><blockquote>
  P(Bany) = 1.0
  <p>
  The probability of a Bust on any secure system is 1.0<br>
  If someone really wants in.
</p></blockquote>
<p>
The Second Law of Computer Security
</p><blockquote>
  The best security system ever built will not function<br>
  If not used.
</blockquote>
<p>
The Third Law of Computer Security
</p><blockquote>
  To err is Human<br>
  To really screw things up, use a Computer.
</blockquote>
<p>
The Fourth Law of Computer Security
</p><blockquote>
  The audit trail is there to tell you who to shoot.
</blockquote>
<p>
  </p><hr>
<h3>
  Determining the System's Security Needs
</h3>
<p>
In order to levy appropriate CompuSec requirements and task the developing
contractor properly, it is first necessary to determine the types of security
needed and the levels of security for each type needed. This book does not
seek to fully define the levels of security for all of the "Securities" -
just identify the tradeoffs which can be made between the "Securities" and
then fully define the level of CompuSec needed for a given set of assumptions
about the system, its environment, and its capabilities.
</p><p>
<u><b>Threats and Vulnerabilities =&gt; Risks</b></u>
</p><p>
The purpose of the CompuSec requirements and tasking levied on a system is
to lower the risks of the system. Risks occur when a threat finds a vulnerability
to attack. By reducing either the threat or the system's vulnerability to
the threat, the risk is reduced.
</p><p>
<b>Vulnerabilities:</b> Vulnerabilities can be grouped into two main categories
for CompuSec purposes; the system itself and the data which is stored, processed,
and/or transmitted by the system.
</p><p>
The computer portion of the system itself is relatively fragile by nature
and is susceptible to system shutdown or slowdown without very much effort
on the part of the threat. Even a relatively small degradation in performance
is sufficient to cause the system to become effectively worthless. In addition,
the typical non-embedded system is a high dollar value piece of equipment
which is always a favorite target.
</p><p>
The data used within the system is obviously a target for the threats to
the system. After all, the manipulation of the data is why the computer system
is being developed. Whether classified or not, the data is needed by the
user of the system or it should not be on the system. Any data that is needed
by the user is also needed by those Not So Friendly people in the world and/or
the Not So Friendlies would like to see the data not be available to the
user.
</p><p>
<b>Threats:</b> Threats to a system come in a wide variety of shapes and
sizes. An airborne system has the threat that it might fall to Earth. A ground
based system has the threat of power surges during a thunder storm. Either
of these threats can effectively deny the user the use of the system and
its data without any malicious intent on the threats part. In addition, there
are indeed Not So Friendly people out there who will want a system and its
data, either for their own or to deny the use of the system to the user.
Each threat must be considered for each system, though the nature of the
system will limit the viable threats somewhat. (Computer Centers rarely suffer
from bird strikes and crash from the sky.)
</p><p>
<b>Risks:</b> When the Vulnerable assets of a system are subject to targeting
by the Threats to the system, Risk of Bad Things happening is present. The
point behind the CompuSec engineering effort is to reduce the risks to an
acceptable level so that the Bad Things won't happen beyond the system's
level to cope with them. (Because the Bad Things for one system are different
than the Bad Things for another system, the Approach to determining the needs
for a system is the purpose of this section.)
</p><p>
<u><b>Sharing the Security Needs or"CompuSec and the Securities"</b></u>
</p><p>
Theoretically the computer system could be built which would allow anyone,
even Not So Friendly folk, to sit down at the terminal and have an acceptable
level of risk. In fact, this is essentially the case for the network of ATMs
raising its head all over the place. This is not, however, the optimum situation
for most systems. Through a well-reasoned engineering trade-off process,
a suitable mix of the securities can be found which will minimize performance
degradation and cost while remaining in the realm of well understood techniques
and well within the state-of-the-art (and probably within the
state-of-the-technology.)
</p><p>
<b>Performance Considerations:</b> Whatever security measures are levied
on the system will have some effect on the performance of the system. In
the case of the ATMs, ease of use is reduced by the need to have the Card
and the limited functionality of the available options. If human intervention
is required for each access to data, the queue will build to intolerable
levels for an active system. Requiring the system to maintain security labels
on each subject and object within the system will add unnecessary throughput
to a system which operates at a single security level. A facility entry system
which backs-up the personnel around the block at shift change is most probably
counter-productive. Some of the basic trade-offs between CompuSec and the
other Securities are:
</p><p>
<b><i>Layered Physical Security</i></b> will allow for more ready access
to the terminals for a limited set of users, provided that the Physical Security
measures are sized properly for the actual traffic flow. The Physical Security
tends to be manpower intensive and or to use emerging technology which will
add another set of CompuSec concerns regarding the computer that runs the
physical security. In most instances, some level of Physical Security will
be required.
</p><p>
When control over the users is possible, <b><i>Personnel Security</i></b>
can reduce the level of CompuSec required. Unfortunately, operational
considerations do not always allow for sufficient controls to be placed on
the personnel. The ultimate case in point is the ATM Network, but, in this
day and age of multinational cooperation, the limiting of personnel to US
nationals goes out the window when the system is sold through Foreign Military
Sales (FMS). The limiting of personnel to relatively high clearance levels
will add to the lifecyle cost of the system unless the users are, by the
nature of their duties, already cleared to the required level.
</p><p>
While labor-intensive, <b><i>Procedural Security</i></b> can solve many
"unsolvable" situations. The system operators must have the ability to circumvent
the normal operations of the system in order to perform some of their tasks
- Procedural Security is the answer. Overuse of this technique will limit
the ability of the "watchers" to watch effectively, and the higher the use
the higher the problem of watching the watchers grows.
</p><p>
Intelligent use of these securities will allow for a greater degree of trust
to be granted the system's software through development by cleared personnel
and configuration management throughout the life of the system, including
upgrades. All of those little devils like Trojan Horses, Viruses, Logic Bombs,
Worms, etc. will be greatly reduced, and possibly stopped, through careful
application of <b><i>Administrative, Product, and Industrial
Securities</i></b>.
</p><p>
<b>Costs:</b> Additional requirements, of any kind, add to the development
cost of a system. In some cases, though, the lifecycle cost will be lower
because of the increased requirements. The following are some of the aspects
of the cost of the requirements that need to be considered.
</p><p>
Because the majority of the CompuSec requirements are realized in software,
the development cost of CompuSec requirements are substantial. To some degree
these costs can be lowered through the purchase of COTS systems from the
National Computer Security Center's (NCSC) Evaluated Product List (EPL) for
the appropriate level of security. The other securities are typically realized
as hardware subsystems and as operational procedure manuals. Depending on
the level of security required, these can be COTS turnkey systems and procedures
which are simple and straight forward. In the extreme case, the requirements
can represent a major development effort in their own right.
</p><p>
The payoff for the expense in development is that if the computer performs
a function, a person does not need to. CompuSec requirements which are executed
properly reduce the manpower needed for the life of the system. The personnel
needs linked to Physical Security are high and the Administrative Security
methodologies also are labor intensive. Personnel Security can become
prohibitively expensive in more resources than mere money if the required
clearance levels grow too far beyond the minimum necessary in an effort to
simplify the security requirements in other security disciplines.
</p><p>
<b>Level of Understanding:</b> Of all of the security disciplines which are
managed by System Security Engineering Management, CompuSec is probably the
least well understood. While there is nothing especially difficult about
CompuSec, its relative newness leads to misunderstandings concerning its
requirements which would not happen in another discipline. Because of this
low misunderstanding threshold, any requirements which are leveled in the
CompuSec arena must be stated in the clearest form possible and monitored
closely to ensure proper execution.
</p><p>
<b>Do-Ability:</b> In conjunction with the generally low level of understanding
of the CompuSec discipline, the do-ability of CompuSec functionality bottoms
out in much shallower water than with functionality that is better understood.
The state-of-the-art for CompuSec is not on a par with the
state-of-the-technology for other aspects of systems development. Each time
a CompuSec requirement is levied it must be carefully examined to ensure
the do-ability.
</p><p>
<u><b>Yellow Books (I &amp; II)</b></u>
</p><p>
The Yellow Books are members of the Rainbow Series put out by the NCSC. (Actually
they are CSC-STD-003-85 and CSC-STD-004-85. Digests of these two standards
can be found in Section III: Rainbow Readers' Digest.) The sole purpose of
these two documents is to give a standard method for determining the needed
Orange Book Class for a given system with its given set of circumstances.
The approach taken by the Yellow Books is conceptually simple: take the level
of data on the system and compare it to the clearances of the people with
access to the system. The greater the difference between the lowest cleared
person and the highest level of data, the higher the risk. The following
steps are taken to quantify this risk.
</p><p>
<b>Minimum User Clearance Rating (R<sub>Min</sub>):</b> Through the use of
the table in the Yellow Books, a numeric rating is given to the clearance
of the lowest cleared personnel who will have access to the system. This
number will be between 0 (Uncleared, without access to Sensitive Unclassified
Information) and 7 (TS/SBI with access to Multiple Categories of TS Data).
</p><p>
<b>Maximum Data Sensitivity Rating (R<sub>Max</sub>):</b> Through the use
of the appropriate table in the Yellow Books, a numeric rating is given to
the sensitivity of the most sensitive data operated on by the system. The
number will be between 0 (Unclassified) and 7 (TS with two or more categories
of Secret or TS data).
</p><p>
<b>Risk Index:</b> The Risk Index is computed by subtracting the
R<sub>Min</sub> from the R<sub>Max</sub>. When a non-positive (zero or negative)
value is the result {all users cleared to equal to or higher than all of
the data}, the Risk Index is 1 if there are any categories to which any user
does not have access and 0 otherwise. When a positive value is the result,
the Risk Index is that result.
</p><blockquote>
  (<strong>Risk Index = R<sub>Max</sub> - R<sub>Min</sub></strong>)
</blockquote>
<p>
<b>Modes of Operation:</b> The CompuSec requirements for a system vary with
the mode of operation and the controls that are necessary to allow for operation
in that mode. There are four recognized modes of operation for secure computer
systems. Each of these modes has its own environment in which to operate
and conditions that indicate its use.
</p><p>
The <b><i>Dedicated Mode</i></b> of operation is indicated for a system when
each user has clearance for all of the data on the system, formal access
to all of the data, and a valid need-to-know for all of the data.
</p><p>
The system <b><i>high mode</i></b> of operation is indicated for a system
when each user has clearance for all of the data on the system and formal
access to all of the data on the system, but not all of the users have a
valid need-to-know for all of the data on the system.
</p><p>
The <b><i>compartmented mode</i></b> of operation is indicated for a system
when each user has clearance for all of the data on the system but not all
users have formal access or a valid need-to-know for all of the data on the
system.
</p><p>
The <b><i>multilevel mode</i></b> of operation is indicated for systems where
not every user has clearance for all of the data on the system, formal access
to all of the data on the system, or a valid need-to-know for all of the
data on the system.
</p><p>
<b>Development Environment:</b> Malicious logic planted by the developers
during development is almost impossible to find until it is too late. When
a system is developed by personnel who are verified to not be Not So Friendly
People the system can be trusted to act in the manner in which it was designed
(at least more so than a system which may have been developed by malicious
programmers.) Because of this, the Yellow Books allow for less stringent
CompuSec requirements when the system is developed in a closed environment
than if it is developed in an open environment.
</p><p>
There are two required conditions for a Closed Development Environment, both
of which must be met, to qualify a development environment as Closed.
</p><p>
<b>Developers:</b> The developers must have clearances and authorizations
equal to the data which will be processed by the system, or at least Secret
clearance for systems that will process data at or above Secret. (This is
to reduce the risk of malicious logic being inserted by the developers.)
</p><p>
<b>Configuration Control:</b> Configuration control must be sufficient to
ensure no malicious logic is inserted after development.
</p><p>
If either of the above conditions are not met, the development environment
is Open. It should be noted that most COTS systems are developed in an Open
Environment. (In fact, most commercial vendors fail both conditions).
</p><p>
<b>Orange Book Class:</b> Now that the Risk Index, Mode of Operation, and
Development Environment type have been selected/defined for the system, the
Orange Book Criteria Class needed for the system can be determined. The actual
CompuSec requirements and tasking are based upon the Orange Book Class indicated.
</p><blockquote>
  <b>C1:</b> Provides for nominal Discretionary Access Control (DAC).
  <p>
  <b>C2:</b> Provides for more finely grained DAC, auditing, and accountability
  through individual login procedures.
  </p><p>
  <b>B1:</b> Additionally provides for Mandatory Access control (MAC), an informal
  policy model, and export labeling.
  </p><p>
  <b>B2:</b> Additionally provides for a formal model, covert channel analysis,
  a structured Trusted Computing Base (TCB), and stringent Configuration
  Management.
  </p><p>
  <b>B3:</b> Additionally provides for a small TCB which contains only security
  policy enforcement functions, a separate security administrator function,
  and all accesses to objects are to be mediated.
  </p><p>
  <b>A1:</b> Functional requirements are the same as B3. Additionally provides
  for formal design specification and verification techniques and more stringent
  documentation and Configuration Management requirements.
</p></blockquote>
<p>
<u><b>Lowering the CompuSec Needs</b></u>
</p><p>
Now that the various trade-off options have been discussed and an initial
Orange Book class has been identified with the Yellow Books, the iterative
process of tuning the system operational concept to lower the CompuSec needs
begins. The following areas are the primary areas where progress can be made
in this effort.
</p><p>
<b>Classified Needs:</b> The assumed classified needs of the system should
be reviewed to ensure the validity of each level of classified or sensitive
data. In some instances, the data requirements of the system could be satisfied
with a lower level of data which can materially lower the level of CompuSec
requirements. Nice-To-Haves aren't so nice when they get to be expensive.
</p><p>
<b>Operational Personnel:</b> If the system concept calls for most of the
operational personnel to be cleared to Level X and a few to be cleared only
to the lower Level Y, it should be investigated whether the few can be reasonably
cleared to Level X as well. If, on the other hand, only a few of the personnel
are cleared (conceptually) to Level X, it should be investigated whether
the Level X personnel (and the Level X data) could be segregated into a subsystem
of the total system which is not accessible to the Level Y personnel.
</p><p>
Environmental Considerations: The net effects of the other securities should
be reviewed to tune the trade-offs on iteration of the security requirements
definition. In some instances, slightly raising the other Securities'
requirements will greatly lower the CompuSec requirements. In other cases,
it may become clear that relieving the other Securities of some of their
requirements will have no negative impact on the system because CompuSec
is going to need to cover that aspect of security anyway.
</p><h3>
  Statement of Work (SOW) Issues
</h3>
<p>
As the Class of requirements increases, the documentation requirements and
other tasks also increase. By the time that the jump from B3 to A1 comes
along, the only changes are to the tasking and documentation; the functional
requirements are identical. This part of the book will supply the Spare Parts
and "installation instructions" for the SOW.
</p><p>
There are some decisions to be made for the specific program in question;
these decisions will be discussed in the Format Considerations portion. The
impacts of the decisions are subtle, but, like much subtlety, the effects
can be truly insidious.
</p><p>
System Security Engineering Management (SSEM), as set forth in MIL-STD-1785,
covers a broad range of security disciplines which includes computer security.
The SSEM Program portion shows the paths which will help the program arrive
at the appropriate destination for the system. It is especially important
that the other securities neither wash out the computer security nor allow
the computer security to wash them out.
</p><p>
The Documentation portion gives a guided tour of the various documents which
are peculiar to, or measurably altered by, computer security.
</p><p>
The Tasks portion breaks the tasks into digestible chunks and presents them
by Orange Book Class. The final arrangement in the SOW will be based on the
decisions which need to be made with the help of the Format Considerations
portion presented earlier in the SOW part and as modified by the SSEM program
portion.
</p><h3>
  Format Considerations
</h3>
<p>
The formatting of the tasking within the SOW can have impacts beyond the
surface impression. The continuity of the security effort and the cost of
that effort are both affected by the layout of the tasking as well as the
reporting of the effort and its costs. The decision must be made early in
order to have the security built into the program instead of a Johnny-Come-Lately
effort tacked on to the main effort after it is too late to achieve much
more than expensive Lip Service.
</p><p>
<u><b>Separate WBS Item / Scattered Throughout </b></u>
</p><p>
At the lower extreme, the C1 Class systems require very little in the way
of special requirements or extra documentation. For such systems there is
no need to have a special niche set in the Work Breakdown Structure (WBS)
for the CompuSec effort.
</p><p>
On the other hand, the A1 Class systems have such intensive requirement sets,
software proofs, and documentation that the set of activities represents
a significant portion of the overall effort for the system. For such systems
there is a definite need to elevate security in general, or CompuSec in
particular, a relatively high niche in the WBS for reporting purposes and
to give a unified front for the related, and interdependent, activities involved
in the design and development of an A1 Class system.
</p><p>
Now that the decisions for the extremes are taken care of, consideration
must be given to the middle ground. The relative scale and scope of the CompuSec
effort as a portion of the total effort will be the primary determining factor
for a given system. Secondary considerations are the relative awareness of
the CompuSec arena by the contractor personnel involved and the relative
newness of the techniques which are planned to be used. A relatively high
level WBS element dedicated to the CompuSec effort will generally lead to
a CompuSec "office" within the contractor with the charge of monitoring the
implementation of the requirements and handling the documentation requirements.
</p><p>
<u><b>Cost Quality Oversight Perceived Importance</b></u>
</p><p>
The higher the level of the WBS element for CompuSec is defined, the finer
the detail cost accounting for the CompuSec effort will be. This is, of course,
the way the WBS works. In conjunction with the finer detail of the cost
accounting, the actual cost will also tend to rise with the level of the
WBS. More management emphasis and a higher level manager to manage the effort
equate to more effort expended and more effort expended equates to higher
cost for the CompuSec effort.
</p><p>
With the higher level of management attention, the quality of the work performed
tends to improve somewhat. If the tasking is scattered about the system effort
the tendency exists for the CompuSec portion of the effort to get slighted
in favor of the "Real Effort". As the effort is drawn together, the "Real
Effort" becomes the CompuSec effort. This results in a more concerted effort
and trade-offs being made which favor the being viewpoint (at least part
of the time.)
</p><p>
Along with the cost visibility comes overall program oversight of the effort
both on the part of the contractor and the government. This improved oversight
of the effort can result in great savings because the CompuSec arena is not
well understood for the most part. As time marches on and more contractors
(and government personnel) become experienced with CompuSec the great need
for special oversight will wane, but, for now, the greater the oversight
the better. In addition to the direct government oversight, if the contractor
has a cadre of experienced personnel, the CompuSec "office" at the contractor
can serve as an Internal Independent Verification and Validation (IIV&amp;V)
team. Of course, the usual problems related to IIV&amp;V will still exist;
the reporting chain will not reach high enough, the IIV&amp;V personnel will
be pulled to perform Software Engineering at the drop of a schedule, etc.
For a time, the visibility and oversight will be improved greatly.
</p><p>
The single greatest reason for elevating the level of the WBS element for
the CompuSec effort is the perceived importance of the effort by the contractor.
The contractor is resource limited. The areas which are perceived as being
important to the government will receive the higher priorities in the allocation
of resources. If the CompuSec effort is perceived as being of low importance,
the resources allocated will be low priority resources.
</p><h3>
  System Security Engineering Management Program
</h3>
<p>
The System Security Engineering Management (SSEM) Program is called for by
MIL-STD-1785. While the CompuSec portion of the SSEM Program is the primary
emphasis of this book, the Program as a whole needs to be examined to determine
the appropriate way to task the portions.
</p><p>
<u><b>The Securities</b></u>
</p><p>
Each of the Securities mentioned earlier in this Section are covered by SSEM.
For any given program, some, all, or none of the securities will have minimal
impact or import. Each must be examined and the appropriate measures, studies,
etc. must be taken to counter the threats. For the most part, the measures
to be taken will take the form of support subsystems and/or procedural and
administrative measures. By the start of Engineering and Manufacturing
Development (EMD), and the writing of the EMD SOW, the appropriate tasking
should be clear for each of the securities. The SSEM Program should cover
the group as a whole with separate sections as needed for the actual design
and implementation.
</p><p>
<u><b>Oversight of Program</b></u>
</p><p>
In order to maintain an appropriate level of oversight by the government,
it is a good idea to levy the SSEM Program Management tasks as one of the
direct tasks under System Engineering. This allows the tasks to receive the
proper attention by the proper personnel. Within the SSEM PM section, the
various securities can be broken out as needed.<u></u>
</p><p>
<u><b>Industrial Security and the Rest</b></u>
</p><p>
One care that should be taken is to ensure that none of the securities ride
rough-shod over the others. (Yes, that includes CompuSec) Another security
which tends to grow a life of its own is Industrial Security. While definitely
needed, Industrial Security should be kept well separated from the rest of
the securities (except perhaps Product Security). A good model for a program
which includes a fairly stiff CompuSec effort would be; System Engineering
=&gt; SSEM =&gt; Industrial Security, CompuSec, The Other Securities.<u></u>
</p><h3>
  Documentation
</h3>
<p>
Along with the functional requirements for each of the Classes of secure
computer systems come documentation requirements. In some cases, the
documentation needs closely parallel the standard documentation (users guides,
etc.) and these needs can be filled by replacement or modifications to the
standard documents. In other cases, the CompuSec documents have no equivalent
document (<em>Formal Top Level Specification</em>, <em>Computer Security
Policy Model</em>, etc.).
</p><p>
<u><b>For Itself</b></u>
</p><p>
Some of the CompuSec documentation is needed because the document produced
is needed by the operators of the system. For instance, the user's manuals,
especially the <em>Security Features Users Guide</em>, are needed to allow
the full and efficient use of the secure system as designed and built. On
the other hand, the security test documentation and the covert channel analysis
are needed by the security personnel to help circumvent penetration attempts
during the operational phase of the system lifecycle. While these documents
are not part of the standard documentation package for most systems, they
are essential to the ultimate security of the system.
</p><p>
<u><b>For Oversight Effort</b></u>
</p><p>
Other documents in the package are for program oversight purposes. For instance,
the <em>Computer Security Policy Model</em> is used as an intermediate document
to ensure the correct interpretation and implementation of the <em>Computer
Security Policy</em>. While these documents serve no innate long term purpose,
the long term effects of not having the documents are massive. Because the
CompuSec arena is not well understood and the vocabulary is basically unstable,
there is an increased need for the contracting agency to maintain good oversight
of the contractor's effort (and for the contractor to do the same).
</p><p>
<u><b>Pertinent Documents</b></u>
</p><p>
Because the documents are not those typically used for most programs, here
is a list of the basic documents and their descriptions in order to help
familiarize the reader with the terrain when the SOW tasking, CDRL, and tailored
DIDs portions are reached.
</p><p>
<b>System Security Engineering Management Plan:</b> This is the cornerstone
document for the security engineering effort. In it the contractor lays out
the plan for managing the entire security engineering effort. Along with
the other securities comes CompuSec and the plans to interpret, allocate,
and implement CompuSec requirements and taskings. The document usually works
best when detailed plans are given for the next phase of the program and
broad plans are given for the remainder of the program. Updates at the beginning
of each phase will then allow for the each layer of detailed planning to
be based on a firm understanding of the approaches being taken. This is the
document which will allow the government to gain confidence in the contractor's
understanding of the tasking and requirements in a timely manner.
</p><p>
<b>Computer Security Management Plan:</b> This Plan is a CompuSec specific
offshoot of the SSEM Plan. Here the detailed plans for CompuSec are laid
out in excruciating detail. This allows the contractor and the government
to ensure the understanding of the effort by the team which will actually
be performing the tasking. On a large program with an intensive security
engineering effort both documents are needed to allow for the varying levels
of abstraction involved. On a smaller program, or a program with less intensive
security needs, one or the other of the documents should be sufficient by
itself.
</p><p>
<b>Security Vulnerability Analysis (SVA):</b> The SVA is generated during
Concept Exploration and updated during Dem Val. By the time that FSD rolls
around the SVA is complete and is used by the designers to determine the
appropriate implementations to counter the vulnerabilities.
</p><p>
<b>Computer Security Policy:</b> The Policy contains the stated rules and
assumptions under which the system will be built and function. Some of the
topics covered would be the assumed level of personnel that will operate
the system, the mode of operation for the system, whether Mandatory Access
Control will be used, and the assumed operational environment for the system.
The Policy really should be written by the government but typically it is
left to the contractor to determine the Policy for the system, which works
well if the government takes an active role in the approval process.
</p><p>
<b>Computer Security Policy Model:</b> This is the bridging document between
the <em>Policy</em> and the requirements. Depending on the Class of the system
the model is either a formal mathematical model or an informal English language
descriptive model. While the Model tends to be a good-sized document it should
be given close attention to ensure complete understanding of the
<em>Policy</em> by the contractor.
</p><p>
<b>Security Concept of Operations:</b> This is the "Artists Rendition" of
the CompuSec arena. This is where the conceptual implementation of the Policy
is laid out and the interplay of the various Securities is discussed. This
document should be written for the ease of understanding by the non-Security
professional. This is the probable source (along with the <em>Policy</em>)
for the inputs to the Yellow Books in the determination of the needed Class
of security requirements and tasking for the system.
</p><p>
<b>Security Architecture Study:</b> This study covers the finer details of
the security architecture after the initial determination of the needed Class
has been made. The results can result in changes in the needed Class through
reallocation to the Other Securities.
</p><blockquote>
  NOTE: The <em>Policy</em>, <em>SVA</em>, <em>Model</em>, <em>Security</em>
  <em>Con</em> <em>Ops</em>, and <em>Security</em> <em>Architecture</em>
  <em>Study</em> are developed and finalized around the same time period and
  are iteratively developed as the interdependencies and repercussions of the
  decision process are felt.
</blockquote>
<p>
<b>Covert Channel Analysis Report:</b> This report is mandated for systems
at or above Class B2. The methods of passing data outside normal, controlled
channels are analyzed and any which are of sufficient bandwidth are studied
for elimination/minimization purposes.
</p><p>
<b>Computer Security Audit Analysis:</b> This analysis is performed on a
recurring basis to trace the implementation of the audit trail requirements.
Understanding of the contractor approach and realization of the requirements
can be gained as well as the impacts of the audit process in processor
throughput, network bandwidth availability, and storage space required. The
periodic release is needed because the actual system performance costs continue
to become more finely defined as the implementation approaches completion.
</p><p>
<b>Security Features Users Guide (SFUG):</b> This is the guide to understanding
the functionality of the security features, their interactions, and guidelines
for their use. For the lower Classes of systems, the SFUG can be a section
of the users' manual but as the classes grow, so does the SFUG. Whenever
possible, the SFUG should be a free-standing document for ease of use (and
finding it).
</p><p>
<b>Trusted Facility Manual:</b> This manual covers the duties and roles of
the security related positions on the system. The manual is sometimes realized
as Positional Handbooks for each of the positions with the pertinent details
needed for each position in its own Handbook. If realized as a single volume,
the details for each position related to the security implementation needs
to be present.
</p><p>
<b>Descriptive Top Level Specification (DTLS):</b> Starting at the B2 Class,
the DTLS describes the Trusted Computing Base (TCB) in intimate detail,
especially the TCB interface.
</p><p>
<b>Formal Top Level Specification (FTLS):</b> This is an A1 Class required
document that is the formal (mathematical) brother of the DTLS. The FTLS
must be produced with a endorsed formal specification system and must be
mapped to the code of the TCB.
</p><p>
<b>Security Test Documentation:</b> Security test documentation serves two
purposes: during development and test the documentation is used for the separate
testing of the security features to ensure the security of the system. The
documentation is then maintained to allow for retesting after modifications
and updates to the system and for the use of the security personnel in the
evaluation of the risks related to proposed changes to the systems and its
environment.
</p><p>
<b>Security Test Plan:</b> The test plan, like most test plans, covers the
Big Picture without going into great detail. It is the best view of the testing
effort, though, and can be quite useful for gaining insight into the security
implementation.
</p><p>
<b>Security Test Procedures:</b> The procedures, like most procedures, are
excruciatingly detailed directions for the test itself. Where these test
procedures differ is the pointing away from simple requirement satisfaction
and more toward security satisfaction.
</p><p>
<b>Security Test Report:</b> The test report is the results of the testing
and should be maintained through the life of the system to ensure continued
protection and to document flaws which may exist.
</p><p>
  </p><hr>
<p>
</p><h1 align="center">
  <strong>Section <a name="II">II</a>:</strong>
</h1>
<h1 align="center">
  <strong>Spare Parts</strong>
</h1>
<h2 align="center">
  <strong>II. Spare parts</strong>
</h2>
<p>
In <u><b>Section I: Building a Secure System</b></u> the determination of
the appropriate Class of secure system was made. In addition, the pros and
cons of SOW and WBS options were discussed and decisions were to be made
based on the particular system being developed. Also, a list of pertinent
documents were discussed for the CompuSec arena.
</p><p>
In <u><b>Section II: Spare Parts</b></u> the pieces are listed which can
be put together to form the CompuSec portions of the specification, SOW,
and CDRL for the system in question. The section is broken into parts based
on the Class of system determined in Section I. For each of the Classes from
C1 through A1, the requirements, SOW tasking, and CDRL inputs are listed.
</p><p>
<b>Requirements:</b> The requirements are laid out as a separate appendix
to the specification. While this is not intensely needed for the lower Classes,
by the time that the B-level Classes are reached, the requirements are involved
enough to necessitate the creation of a separate appendix.
</p><p>
<b>SOW Tasking:</b> The SOW portion is composed of paragraphs which will
need to be arranged in the SOW in accordance with the decisions, made in
Section I, concerning SOW formatting.
</p><p>
<b>CDRL Inputs:</b> The CDRL input section gives essentially all of the
document-specific except for the distribution section which will need to
be determined for each system individually.
</p><blockquote>
  NOTE -- The Tasking and CDRL inputs are not separated by phase. If the program
  has clear phases, some of the tasks and documentation will need to be tailored
  accordingly.
</blockquote>
<p>
Following the portions concerned with the various Classes of systems, there
is a portion containing the major Data Item Descriptions (DID). In some cases
there will be a need to tailor the DIDs. Such tailoring should be performed
only with the greatest of care.
</p><p>
Two things to remember when using these Spare Parts are:
</p><p>
These are the basic minimums for a generic system. For your specific system
there may be portions which just do not apply and there may be portions which
need to be added.
</p><p>
Nothing replaces careful thought and consideration.
</p><p>
  </p><hr>
<h3>
  C1 Class
</h3>
<p>
The C1 class secure computer system is the lowest level of CompuSec<strong>
</strong>requirements defined by the Orange Book. C1 class systems are
appropriate for operation in the dedicated mode of operation only. The
protections are not sufficient to protect against an internal attack.
</p><p>
There are a limited number of high level subjects and objects which are protected
at all and the limits on the sharing of objects are not restrictive.
</p><p>
The users are required to login but the system does not need to be able to
identify individual users uniquely. This implies that group logins (or project
logins) are allowed.
</p><p>
The Trusted Computing Base (TCB) is required to protect itself (software)
for outside interference and tampering and to be able to validate the operations
of the TCB hardware and firmware.
</p><p>
<b>C1 Class Requirements</b>
</p><blockquote>
  10.1 Discretionary Access Control (DAC)
  <blockquote>
    10.1.1 The TCB shall control access between named users and named objects.
    <p>
    10.1.2 The TCB shall allow users to specify and control sharing of objects
    by named individuals or groups or both.
  </p></blockquote>
  <p>
  10.2 Identification and Authentication
  </p><blockquote>
    10.2.1 The TCB shall require users to identify themselves before performing
    any other actions on behalf of that user.
    <p>
    10.2.2 The TCB shall authenticate the user's identity before performing any
    other actions on behalf of that user.
    </p><p>
    10.2.3 The TCB shall protect authentication data from unauthorized access.
  </p></blockquote>
  <p>
  10.3 The TCB shall protect itself from external interference and tampering.
  </p><p>
  10.4 The TCB shall have the capability to validate the correct operations
  of the TCB's hardware and firmware.
</p></blockquote>
<p>
<b>C1 Class SOW Tasking</b>
</p><p>
<b>A. Data Accession List.</b> The contractor shall maintain a complete list
of all data generated as a result of this contract. The contractor shall
list the data by title, date, and subject. The list shall include all memos,
letters, meeting minutes, phone logs, etc. All data not required by the CDRL
shall be considered contractor format. The document shall be titled
<em>Gonculator Data Accession List.</em> (DI-A-3027A/T)
</p><p>
<b>B. System Description.</b> The contractor shall prepare separately published
common appendices which describes the system for use with the system
documentation. These appendices shall be prepared in an Unclassified version,
if possible, and such classified versions that are required for a full
description of the Gonculator System. The contractor shall use the common
appendices in place of the system description within the bodies of the
documentation. The descriptions shall be titled <em>Gonculator System Description
Appendix, </em> (Appropriate Classification)<strong><em>
</em></strong>Version. (DI-GDRQ-80567/T)
</p><p>
<b>C. System Security Management Program.</b> The contractor shall conduct
a System Security Management Program in accordance with the approved System
Security Management Plan.
</p><p>
<b>D. System Security Management Plan.</b> The contractor shall develop a
system security management plan describing the contractor's security engineering
and management approach. The plan should include all aspects of system security,
including computer security. The document shall be titled <em>Gonculator
System Security Management Plan.</em> (DI-MISC-80839/T)
</p><p>
<b>E. Security Vulnerability Analysis.</b> The contractor shall conduct a
security vulnerability analysis and document the results. The study shall
include identification of logical security vulnerabilities of the system,
defining functional requirements which may secure the system from exploitation,
and choosing safeguards to reduce identified vulnerabilities. The document
shall be titled <em>Gonculator Security Vulnerability Analysis.</em>
(DI-MISC-80841/T)
</p><p>
<b>F. Computer Security Policy.</b> The contractor shall prepare a document
that defines the security policy enforced by the computer system. The document
shall be titled <em>Gonculator Computer Security Policy.</em> (DI-GDRQ-80567/T)
</p><p>
<b>G. Security Features Users Guide.</b> The contractor shall generate a
Users' Guide that documents the protection mechanisms provided by the system,
guidelines for their use, and how the protection mechanisms interact with
each other. The users guide may be published as either a common appendix
to the positional handbooks or a stand-alone document titled <em>Gonculator
Security Features Users' Guide</em>. (DI-MCCR-80019A/T)
</p><p>
<b>H. Trusted Facility Manual.</b> The contractor shall generate a manual
that documents cautions about functions and privileges that should be controlled
when running the secure facility in accordance with DOD-5200.28-STD. The
document shall be titled <em>Gonculator Trusted Facility Manual.</em>
(DI-MCCR-80019A/T)
</p><p>
  </p><hr>
<h3>
  C2 Class
</h3>
<p>
The C2 class secure computer system enforces a more finely grained DAC than
C1 class systems do. C2 class systems are appropriate for operation in the
dedicated or system high modes of operation only. The protections include
individual accountability.
</p><p>
There are a limited number of high level subjects and objects which are
protected. Propagation of access rights is controlled. Access is controlled
at the granularity of named individual and/or group of named individuals.
</p><p>
The users are required to login and the system needs to be able to identify
individual users uniquely. While individuals are individuals, group access
rights are still allowed.
</p><p>
Reuse of storage objects (memory, disk space, buffers, etc.) is only allowed
after the object is cleared to disallow any access to the old data.
</p><p>
Audit is required to make users responsible for their actions. Half of the
theory behind audits is to allow for the security personnel to find wrongful
acts and identify the perpetrator; the other half of the theory is that an
advertised audit process will keep Honest people Honest.
</p><p>
The Trusted Computing Base (TCB) is required to protect itself (software)
for outside interference and tampering and to be able to validate the operations
of the TCB hardware and firmware.
</p><p>
<b>C2 Class Requirements</b>
</p><blockquote>
  10.1 Discretionary Access Control (DAC)
  <blockquote>
    10.1.1 The TCB shall control access between named users and named objects.
    <p>
    10.1.2 The TCB shall protect all named objects from unauthorized access.
    </p><p>
    10.1.3 The TCB shall allow for the inclusion or exclusion of access to named
    objects at the level of the single user.
    </p><p>
    10.1.4 The TCB shall allow authorized users to specify and control sharing
    of objects by named individuals or groups of individuals or both.
    </p><p>
    10.1.5 The TCB shall provide controls to limit propagation of access rights.
  </p></blockquote>
  <p>
  10.2 The TCB shall clear all memory objects before reallocation.
  </p><p>
  10.3 Identification and Authentication
  </p><blockquote>
    10.3.1 The TCB shall require users to uniquely identify themselves before
    performing any other actions on behalf of that user.
    <p>
    10.3.2 The TCB shall authenticate the user's unique identity before performing
    any other actions on behalf of that user.
    </p><p>
    10.3.3 The TCB shall protect authentication data from unauthorized access.
    </p><p>
    10.3.4 The TCB shall associate the user's unique identity for all auditable
    actions taken by the user.
  </p></blockquote>
  <p>
  10.4 Audit
  </p><blockquote>
    10.4.1 The TCB shall be able to create an audit trail.
    <p>
    10.4.2 The TCB shall maintain the audit trail on-line for a minimum of thirty
    days.
    </p><p>
    10.4.3 The TCB shall protect the audit trail from modification or unauthorized
    access.
    </p><p>
    10.4.4 The TCB shall audit the following event types:
    </p><blockquote>
      a. Login.
      <p>
      b. Logout.
      </p><p>
      c. Access to objects.
      </p><p>
      d. Deletion of objects.
      </p><p>
      e. Actions taken by system operators, administrators, and security officers.
    </p></blockquote>
    <p>
    10.4.5 The TCB shall include the following information in each audit trail
    record:
    </p><blockquote>
      a. Date and time of event.
      <p>
      b. User identity.
      </p><p>
      c. Event type.
      </p><p>
      d. Success or failure of action.
      </p><p>
      e. Name of object, if any.
    </p></blockquote>
    <p>
    10.4.6 The TCB shall selectively audit the actions of one or more users based
    on individual identity.
  </p></blockquote>
  <p>
  10.5 System Security Architecture
  </p><blockquote>
    10.5.1 The TCB shall protect itself from external interference and tampering.
    <p>
    10.5.2 The TCB shall isolate the resources to be protected by access controls
    and auditing.
  </p></blockquote>
  <p>
  10.6 The TCB shall have the capability to validate the correct operations
  of the TCB's hardware and firmware.
</p></blockquote>
<p>
<b>C2 Class SOW Tasking</b>
</p><p>
<b>A. Data Accession List.</b> The contractor shall maintain a complete list
of all data generated as a result of this contract. The contractor shall
list the data by title, date, and subject. The list shall include all memos,
letters, meeting minutes, phone logs, etc. All data not required by the CDRL
shall be considered contractor format. The document shall be titled
<em>Gonculator Data Accession List.</em> (DI-A-3027A/T)
</p><p>
<b>B. System Description.</b> The contractor shall prepare separately published
common appendices which describes the system for use with the system
documentation. These appendices shall be prepared in an Unclassified version,
if possible, and such classified versions that are required for a full
description of the Gonculator System. The contractor shall use the common
appendices in place of the system description within the bodies of the
documentation. The descriptions shall be titled <em>Gonculator System Description
Appendix, </em> (Appropriate Classification)<strong><em>
</em></strong>Version. (DI-GDRQ-80567/T)
</p><p>
<b>C. System Security Management Program.</b> The contractor shall conduct
a System Security Management Program in accordance with the approved System
Security Management Plan.
</p><p>
<b>D. System Security Management Plan.</b> The contractor shall develop a
system security management plan describing the contractor's security engineering
and management approach. The plan should include all aspects of system security,
including computer security. The document shall be titled <em>Gonculator
System Security Management Plan.</em> (DI-MISC-80839/T)
</p><p>
<b>E. Security Vulnerability Analysis.</b> The contractor shall conduct a
security vulnerability analysis and document the results. The study shall
include identification of logical security vulnerabilities of the system,
defining functional requirements which may secure the system from exploitation,
and choosing safeguards to reduce identified vulnerabilities. The document
shall be titled <em>Gonculator Security Vulnerability Analysis.</em>
(DI-MISC-80841/T)
</p><p>
<b>F. Computer Security Policy.</b> The contractor shall prepare a document
that defines the security policy enforced by the computer system. The document
shall be titled <em>Gonculator Computer Security Policy.</em> (DI-GDRQ-80567/T)
</p><p>
<b>G. Computer Security Audit Analysis.</b> The contractor shall analyze
the audit schema for the system including events to be audited, audit record
structures, throughput requirements, storage needs, and archival storage
techniques. The document shall be titled <em>Gonculator Computer Security
Audit Analysis.</em> (DI-GDRQ-80567/T)
</p><p>
<b>H. Security Features Users Guide.</b> The contractor shall generate a
Users' Guide that documents the protection mechanisms provided by the system,
guidelines for their use, and how the protection mechanisms interact with
each other. The users guide may be published as either a common appendix
to the positional handbooks or a stand-alone document titled <em>Gonculator
Security Features Users' Guide</em>. (DI-MCCR-80019A/T)
</p><p>
<b>I. Trusted Facility Manual.</b> The contractor shall generate a manual
that documents cautions about functions and privileges that should be controlled
when running the secure facility in accordance with DOD-5200.28-STD. The
document shall be titled <em>Gonculator Trusted Facility Manual.</em>
(DI-MCCR-80019A/T)
</p><p>
  </p><hr>
<h3>
  B1 Class
</h3>
<p>
The B1 class secure computer system enforces a Mandatory Access Control (MAC)
policy and the associated labeling. B1 class systems are appropriate for
operation in the compartmented and multilevel modes of operation. Multilevel
mode operations should be carefully considered before use because there is
no protection from covert channel attacks.
</p><p>
There are a limited number of high level subjects and objects which are protected
by DAC. Propagation of access rights is controlled. Access is controlled
at the granularity of named individual and/or group of named individuals.
</p><p>
The users are required to login and the system needs to be able to identify
individual users uniquely. While individuals are individuals, group access
rights are still allowed.
</p><p>
Reuse of storage objects (memory, disk space, buffers, etc.) is only allowed
after the object is cleared to disallow any access to the old data.
</p><p>
Audit is required to make users responsible for their actions. Half of the
theory behind audits is to allow for the security personnel to find wrongful
acts and identify the perpetrator; the other half of the theory is that an
advertised audit process will keep Honest people Honest. With labeling and
MAC, the security level is also recorded for objects being audited.
</p><p>
Labels are required for all subjects and storage objects controlled by the
TCB. These labels are used for MAC decisions which are also mandated for
all subjects and storage objects under TCB control. The basic requirements
are a simple translation of the standard "Paper-style" requirements onto
the computer so the computer will mark and allow access properly.
</p><p>
The Trusted Computing Base (TCB) is required to protect itself (software)
for outside interference and tampering and to be able to validate the operations
of the TCB hardware and firmware.
</p><p>
<b>B1 Class Requirements</b>
</p><blockquote>
  10.1 Discretionary Access Control (DAC)
  <blockquote>
    10.1.1 The TCB shall control access between named users and named objects.
    <p>
    10.1.2 The TCB shall protect all named objects from unauthorized access.
    </p><p>
    10.1.3 The TCB shall allow for the inclusion or exclusion of access to named
    objects at the level of the single user.
    </p><p>
    10.1.4 The TCB shall allow authorized users to specify and control sharing
    of objects by named individuals or groups of individuals or both.
    </p><p>
    10.1.5 The TCB shall provide controls to limit propagation of access rights.
  </p></blockquote>
  <p>
  10.2 The TCB shall clear all memory objects before allocation to a new subject.
  </p><p>
  10.3 Identification and Authentication
  </p><blockquote>
    10.3.1 The TCB shall require users to uniquely identify themselves before
    performing any other actions on behalf of that user.
    <p>
    10.3.2 The TCB shall authenticate the user's unique identity before performing
    any other actions on behalf of that user.
    </p><p>
    10.3.3 The TCB shall ensure that the user's login security level and
    authorizations are dominated by the user's clearance and authorizations.
    </p><p>
    10.3.4 The TCB shall ensure that the security level and authorizations of
    subjects external to the TCB which are created on behalf of the user are
    dominated by the user's clearance and authorizations.
    </p><p>
    10.3.5 The TCB shall protect authentication data from unauthorized access.
    </p><p>
    10.3.6 The TCB shall associate the user's unique identity for all auditable
    actions taken by the user.
  </p></blockquote>
  <p>
  10.4 Audit
  </p><blockquote>
    10.4.1 The TCB shall be able to create an audit trail.
    <p>
    10.4.2 The TCB shall maintain the audit trail on-line for a minimum of thirty
    days.
    </p><p>
    10.4.3 The TCB shall protect the audit trail from modification or unauthorized
    access.
    </p><p>
    10.4.4 The TCB shall audit the following event types:
    </p><blockquote>
      a. Login.
      <p>
      b. Logout.
      </p><p>
      c. Access to objects.
      </p><p>
      d. Deletion of objects.
      </p><p>
      e. Override of human-readable output markings.
      </p><p>
      f. Labeling of imported unlabeled data.
      </p><p>
      g. Any change in the designation of single level and multilevel devices.
      </p><p>
      h. Any change in security level or levels associated with a subject or object.
      </p><p>
      i. Actions taken by system operators, administrators, and security officers.
    </p></blockquote>
    <p>
    10.4.5 The TCB shall include the following information in each audit trail
    record:
    </p><blockquote>
      a. Date and time of event.
      <p>
      b. User identity.
      </p><p>
      c. Event type.
      </p><p>
      d. Success or failure of action.
      </p><p>
      e. Security level of object, if any.
      </p><p>
      f. Name of object, if any.
    </p></blockquote>
    <p>
    10.4.6 The TCB shall selectively audit the actions of one or more users based
    on individual identity and/or object security level.
  </p></blockquote>
  <p>
  10.5 System Security Architecture
  </p><blockquote>
    10.5.1 The TCB shall protect itself from external interference and tampering.
    <p>
    10.5.2 The TCB shall isolate the resources to be protected by access controls
    and auditing.
    </p><p>
    10.5.3 The TCB shall maintain distinct address spaces for process isolation.
  </p></blockquote>
  <p>
  10.6 The TCB shall have the capability to validate the correct operations
  of the TCB's hardware and firmware.
  </p><p>
  10.7 Labels
  </p><blockquote>
    10.7.1 The TCB shall maintain the sensitivity label associated with each
    subject and object under TCB control.
    <p>
    10.7.2 The sensitivity label associated with a subject or an object shall
    correctly represent the security level of the subject or object.
    </p><p>
    10.7.3 The TCB shall use the sensitivity labels as the basis for mandatory
    access control decisions.
    </p><p>
    10.7.4 The TCB shall request a label from an authorized user before importing
    unlabeled data.
    </p><p>
    10.7.5 The TCB shall associate an accurate and unambiguous sensitivity label
    exported information.
    </p><p>
    10.7.6 The TCB shall designate each I/O device and communications channel
    as a single level or multilevel device.
    </p><p>
    10.7.7 Any change in the designation of single level or multilevel shall
    be performed manually.
    </p><p>
    10.7.8 The TCB shall associate with each object exported over a multilevel
    device the sensitivity level in the same form as the data and physically
    residing with the data.
    </p><p>
    10.7.9 The communications protocol used for each multilevel communications
    port shall provide for the unambiguous pairing of the data and its associated
    sensitivity label.
    </p><p>
    10.7.10 The TCB shall allow an authorized user to designate the single security
    level of information imported or exported via a single level communications
    port or I/O device.
    </p><p>
    10.7.11 The TCB shall allow the System Administrator to specify the printable
    label names associated with exported sensitivity labels.
    </p><p>
    10.7.12 The TCB shall mark the top and bottom of all human readable output
    with human readable sensitivity labels that properly represent the sensitivity
    of the output.
  </p></blockquote>
  <p>
  10.8 Mandatory Access Control (MAC)
  </p><blockquote>
    10.8.1 The TCB shall enforce mandatory access control for all subjects and
    storage objects under its control.
    <p>
    10.8.2 A subject shall be allowed read access only if the hierarchical
    classification in the subject's security level is greater than or equal to
    the hierarchical classification in the object's security level and the
    non-hierarchical categories in the subject's security level include all of
    the non-hierarchical categories in the object's security level.
    </p><p>
    10.8.3 A subject shall be allowed write access only if the hierarchical
    classification in the subject's security level is less than or equal to the
    hierarchical classification in the object's security level and all of the
    non-hierarchical categories in the subject's security level are included
    in the non-hierarchical categories in the object's security level.
  </p></blockquote>
</blockquote>
<p>
<b>B1 Class SOW Tasking</b>
</p><p>
<b>A. Gonculator Accreditation Working Group.</b> The contractor shall support
the Gonculator Accreditation Working Group (GAWG) through attendance at meetings
as needed, presenting current program data as requested, acting upon assigned
and accepted Action Items, and preparing minutes of the GAWG meetings. At
a minimum, the GAWG will meet twice a year. At a minimum, support at the
meetings shall include representatives from program management, configuration
management, system engineering, and security engineering. (DI-A-7089/T)
</p><p>
<b>B. Data Accession List.</b> The contractor shall maintain a complete list
of all data generated as a result of this contract. The contractor shall
list the data by title, date, and subject. The list shall include all memos,
letters, meeting minutes, phone logs, etc. All data not required by the CDRL
shall be considered contractor format. The document shall be titled
<em>Gonculator Data Accession List.</em> (DI-A-3027A/T)
</p><p>
<b>C. System Description.</b> The contractor shall prepare separately published
common appendices which describes the system for use with the system
documentation. These appendices shall be prepared in an Unclassified version,
if possible, and such classified versions that are required for a full
description of the Gonculator System. The contractor shall use the common
appendices in place of the system description within the bodies of the
documentation. The descriptions shall be titled <em>Gonculator System Description
Appendix, </em> (Appropriate Classification)<strong><em>
</em></strong>Version. (DI-GDRQ-80567/T)
</p><p>
<b>D. System Security Management Program.</b> The contractor shall conduct
a System Security Management Program in accordance with the approved System
Security Management Plan.
</p><p>
<b>E. System Security Management Plan.</b> The contractor shall develop a
system security management plan describing the contractor's security engineering
and management approach. The plan should include all aspects of system security,
including computer security. The document shall be titled <em>Gonculator
System Security Management Plan.</em> (DI-MISC-80839/T)
</p><p>
<b>F. Computer Security Management Program.</b> The contractor shall conduct
a Computer Security Management Program in accordance with the approved Computer
Security Management Plan.
</p><p>
<b>G. Computer Security Management Plan.</b> The contractor shall generate
a computer security management plan. The Plan shall include the methods used
to manage the computer security engineering program, program schedule, and
the steps to be taken to ensure the proper incorporation of the computer
security requirements into the system. The document shall be titled
<em>Gonculator Computer Security Management Plan.</em> (DI-MISC-80839/T)
</p><p>
<b>H. Security Vulnerability Analysis.</b> The contractor shall conduct a
security vulnerability analysis and document the results. The study shall
include identification of logical security vulnerabilities of the system,
defining functional requirements which may secure the system from exploitation,
and choosing safeguards to reduce identified vulnerabilities. The document
shall be titled <em>Gonculator Security Vulnerability Analysis.</em>
(DI-MISC-80841/T)
</p><p>
<b>I. Computer Security Policy.</b> The contractor shall prepare a document
that defines the security policy enforced by the computer system. The document
shall be titled <em>Gonculator Computer Security Policy.</em> (DI-GDRQ-80567/T)
</p><p>
<b>J. Computer Security Policy Model.</b> The contractor shall develop and
document a model of the security policy enforced by the system. The model
description shall include the specific protection mechanisms and an explanation
showing that they satisfy the model and will enforce the security policy.
The document shall be titled <em>Gonculator Computer Security Policy Model.
</em> (DI-GDRQ-80567/T)
</p><p>
<b>K. Security Architecture Study.</b> The contractor shall conduct a study
of the security architecture of the system and document the results of the
study. The study shall include partitioning of the system, cost/benefit analysis
for the architectural alternatives, and the required Class of system for
each alternative and for each partitioned subsystem. The report shall detail
the recommended architecture for the system. The document shall be titled
<em>Gonculator Security Architecture Study.</em> (DI-GDRQ-80567/T)
</p><p>
<b>L. System Security Concept of Operations.</b> The contractor shall generate
a system security concept of operations that documents the security concept
for the system including the incorporation of the protection philosophy into
the system. The document shall be titled <em>Gonculator System Security Concept
Of Operations.</em> (DI-MISC-80840/T)
</p><p>
<b>M. Computer Security Audit Analysis.</b> The contractor shall analyze
the audit schema for the system including events to be audited, audit record
structures, throughput requirements, storage needs, and archival storage
techniques. The document shall be titled <em>Gonculator Computer Security
Audit Analysis.</em> (DI-GDRQ-80567/T)
</p><p>
<b>N. Security Features Users Guide.</b> The contractor shall generate a
Users' Guide that documents the protection mechanisms provided by the system,
guidelines for their use, and how the protection mechanisms interact with
each other. The users guide may be published as either a common appendix
to the positional handbooks or a stand-alone document titled <em>Gonculator
Security Features Users' Guide</em>. (DI-MCCR-80019A/T)
</p><p>
<b>O. Trusted Facility Manual.</b> The contractor shall generate a manual
that documents cautions about functions and privileges that should be controlled
when running the secure facility in accordance with DOD-5200.28-STD. The
document shall be titled <em>Gonculator Trusted Facility Manual.</em>
(DI-MCCR-80019A/T)
</p><p>
<b>P. Security Test.</b> The contractor shall conduct a separate security
test in conjunction with the system acceptance test. The security test shall
show that all security mechanisms function as defined in the system documentation
and that the system is resistant to penetration. The security test shall
include an ad hoc, loosely structured test by the government test team. The
contractor shall train the government test team in the operation of the system
before the start of the test. The government test team will consist of six
people drawn from the developing, supporting, using, and accrediting communities.
</p><p>
<b>Q. Security Test Plan.</b> The contractor shall develop a test plan for
the security testing to be performed. The document shall be titled
<em>Gonculator Security Test Plan. </em> (DI-MCCR-80014A/T)
</p><p>
<b>R. Security Test Description.</b> The contractor shall develop test procedures
to implement the approved Gonculator<em> </em>Security Test Plan. The document
shall be titled <em>Gonculator Security Test Description.</em> (DI-MCCR-80015A/T)
</p><p>
<b>S. Security Test Report.</b> The contractor shall document the results
of the security test. The document shall be titled <em>Gonculator Security
Test Report</em>. (DI-MCCR-80017A/T)
</p><p>
  </p><hr>
<h3>
  B2 Class
</h3>
<p>
The B2 class secure computer system is based on clearly defined security
policy and model of the policy. B2 class systems are appropriate for operation
in the compartmented and multilevel modes of operation. Multilevel mode
operations should be carefully considered before use because there is limited
protection from covert channel attacks.
</p><p>
There are a limited number of high level subjects and objects which are protected
by DAC. Propagation of access rights is controlled. Access is controlled
at the granularity of named individual and/or group of named individuals.
</p><p>
The users are required to login and the system needs to be able to identify
individual users uniquely. While individuals are individuals, group access
rights are still allowed.
</p><p>
Reuse of storage objects (memory, disk space, buffers, etc.) is only allowed
after the object is cleared to disallow any access to the old data.
</p><p>
Audit is required to make users responsible for their actions. Half of the
theory behind audits is to allow for the security personnel to find wrongful
acts and identify the perpetrator; the other half of the theory is that an
advertised audit process will keep Honest people Honest. With labeling and
MAC, the security level is also recorded for objects being audited.
</p><p>
Labels are required for all system resources. These labels are used for MAC
decisions which are also mandated for all subjects and storage objects under
TCB control. The basic requirements are a simple translation of the standard
"Paper-style" requirements onto the computer so the computer will mark and
allow access properly.
</p><p>
The Trusted Computing Base (TCB) is required to protect itself (software)
from outside interference and tampering and to be able to validate the operations
of the TCB hardware and firmware.
</p><p>
<b>B2 Class Requirements</b>
</p><blockquote>
  10.1 Discretionary Access Control (DAC)
  <blockquote>
    10.1.1 The TCB shall control access between named users and named objects.
    <p>
    10.1.2 The TCB shall protect all named objects from unauthorized access.
    </p><p>
    10.1.3 The TCB shall allow for the inclusion or exclusion of access to named
    objects at the level of the single user.
    </p><p>
    10.1.4 The TCB shall allow authorized users to specify and control sharing
    of objects by named individuals or groups of individuals or both.
    </p><p>
    10.1.5 The TCB shall provide controls to limit propagation of access rights.
  </p></blockquote>
  <p>
  10.2 The TCB shall clear all memory objects before allocation to a new subject.
  </p><p>
  10.3 Identification and Authentication
  </p><blockquote>
    10.3.1 The TCB shall require users to uniquely identify themselves before
    performing any other actions on behalf of that user.
    <p>
    10.3.2 The TCB shall authenticate the user's unique identity before performing
    any other actions on behalf of that user.
    </p><p>
    10.3.3 The TCB shall ensure that the user's login security level and
    authorizations are dominated by the user's clearance and authorizations.
    </p><p>
    10.3.4 The TCB shall ensure that the security level and authorizations of
    subjects external to the TCB which are created on behalf of the user are
    dominated by the user's clearance and authorizations.
    </p><p>
    10.3.5 The TCB shall protect authentication data from unauthorized access.
    </p><p>
    10.3.6 The TCB shall associate the user's unique identity for all auditable
    actions taken by the user.
    </p><p>
    10.3.7 The TCB shall support a trusted communication path between the TCB
    and a user, initiated exclusively by the user, for initial login and
    authentication.
  </p></blockquote>
  <p>
  10.4 Audit
  </p><blockquote>
    10.4.1 The TCB shall be able to create an audit trail.
    <p>
    10.4.2 The TCB shall maintain the audit trail on-line for a minimum of thirty
    days.
    </p><p>
    10.4.3 The TCB shall protect the audit trail from modification or unauthorized
    access.
    </p><p>
    10.4.4 The TCB shall audit the following event types:
    </p><blockquote>
      a. Login.
      <p>
      b. Logout.
      </p><p>
      c. Access to objects.
      </p><p>
      d. Deletion of objects.
      </p><p>
      e. Override of human-readable output markings.
      </p><p>
      f. Labeling of imported unlabeled data.
      </p><p>
      g. Any change in the designation of single level and multilevel devices.
      </p><p>
      h. Any change in security level or levels associated with a subject or object.
      </p><p>
      i. Identified covert storage channel exploitation events.
      </p><p>
      j. Actions taken by system operators, administrators, and security officers.
    </p></blockquote>
    <p>
    10.4.5 The TCB shall include the following information in each audit trail
    record:
    </p><blockquote>
      a. Date and time of event.
      <p>
      b. User identity.
      </p><p>
      c. Event type.
      </p><p>
      d. Success or failure of action.
      </p><p>
      e. Security level of object, if any.
      </p><p>
      f. Name of object, if any.
    </p></blockquote>
    <p>
    10.4.6 The TCB shall selectively audit the actions of one or more users based
    on individual identity and/or object security level.
  </p></blockquote>
  <p>
  10.5 System Security Architecture
  </p><blockquote>
    10.5.1 The TCB shall maintain a domain of its own execution that protects
    it from external interference and tampering.
    <p>
    10.5.2 The TCB shall isolate the resources to be protected by access controls
    and auditing.
    </p><p>
    10.5.3 The TCB shall maintain distinct address spaces for process isolation.
    </p><p>
    10.5.4 The TCB shall be structured modularly.
    </p><p>
    10.5.5 The user interface to the TCB and all TCB elements shall be completely
    defined.
  </p></blockquote>
  <p>
  10.6 The TCB shall have the capability to validate the correct operations
  of the TCB's hardware and firmware.
  </p><p>
  10.7 Labels
  </p><blockquote>
    10.7.1 The TCB shall maintain the sensitivity label associated with each
    system resources accessible by subjects external to the TCB.
    <p>
    10.7.2 The sensitivity label associated with a subject or an object shall
    correctly represent the security level of the subject or object.
    </p><p>
    10.7.3 The TCB shall notify a terminal user of each change in the user's
    security level during a session.
    </p><p>
    10.7.4 The TCB shall support the assignment of minimum and maximum security
    levels for all attached devices.
    </p><p>
    10.7.5 The TCB shall use the sensitivity labels as the basis for mandatory
    access control decisions.
    </p><p>
    10.7.6 The TCB shall request a label from an authorized user before importing
    unlabeled data.
    </p><p>
    10.7.7 The TCB shall associate an accurate and unambiguous sensitivity label
    with all exported information.
    </p><p>
    10.7.8 The TCB shall designate each I/O device and communications channel
    as a single level or multilevel device.
    </p><p>
    10.7.9 Any change in the designation of single level or multilevel shall
    be performed manually.
    </p><p>
    10.7.10 The TCB shall associate with each object exported over a multilevel
    device the sensitivity level in the same form as the data and physically
    residing with the data.
    </p><p>
    10.7.11 The communications protocol used for each multilevel communications
    port shall provide for the unambiguous pairing of the data and its associated
    sensitivity label.
    </p><p>
    10.7.12 The TCB shall allow an authorized user to designate the single security
    level of information imported or exported via a single level communications
    port or I/O device.
    </p><p>
    10.7.13 The TCB shall allow the System Administrator to specify the printable
    label names associated with exported sensitivity labels.
    </p><p>
    10.7.14 The TCB shall mark the top and bottom of all human readable output
    with human readable sensitivity labels that properly represent the sensitivity
    of the output.
  </p></blockquote>
  <p>
  10.8 Mandatory Access Control (MAC)
  </p><blockquote>
    10.8.1 The TCB shall enforce mandatory access control over all subjects and
    objects accessible to subjects external to the TCB.
    <p>
    10.8.2 A subject shall be allowed read access only if the hierarchical
    classification in the subject's security level is greater than or equal to
    the hierarchical classification in the object's security level and the
    non-hierarchical categories in the subject's security level include all of
    the non-hierarchical categories in the object's security level.
    </p><p>
    10.8.3 A subject shall be allowed write access only if the hierarchical
    classification in the subject's security level is less than or equal to the
    hierarchical classification in the object's security level and all of the
    non-hierarchical categories in the subject's security level are included
    in the non-hierarchical categories in the object's security level.
  </p></blockquote>
</blockquote>
<p>
<b>B2 Class SOW Tasking</b>
</p><p>
<b>A. Gonculator Accreditation Working Group.</b> The contractor shall support
the Gonculator Accreditation Working Group (GAWG) through attendance at meetings
as needed, presenting current program data as requested, acting upon assigned
and accepted Action Items, and preparing minutes of the GAWG meetings. At
a minimum, the GAWG will meet twice a year. At a minimum, support at the
meetings shall include representatives from program management, configuration
management, system engineering, and security engineering. (DI-A-7089/T)
</p><p>
<b>B. Data Accession List.</b> The contractor shall maintain a complete list
of all data generated as a result of this contract. The contractor shall
list the data by title, date, and subject. The list shall include all memos,
letters, meeting minutes, phone logs, etc. All data not required by the CDRL
shall be considered contractor format. The document shall be titled
<em>Gonculator Data Accession List.</em> (DI-A-3027A/T)
</p><p>
<b>C. System Description.</b> The contractor shall prepare separately published
common appendices which describes the system for use with the system
documentation. These appendices shall be prepared in an Unclassified version,
if possible, and such classified versions that are required for a full
description of the Gonculator System. The contractor shall use the common
appendices in place of the system description within the bodies of the
documentation. The descriptions shall be titled <em>Gonculator System Description
Appendix, </em> (Appropriate Classification)<strong><em>
</em></strong>Version. (DI-GDRQ-80567/T)
</p><p>
<b>D. System Security Management Program.</b> The contractor shall conduct
a System Security Management Program in accordance with the approved System
Security Management Plan.
</p><p>
<b>E. System Security Management Plan.</b> The contractor shall develop a
system security management plan describing the contractor's security engineering
and management approach. The plan should include all aspects of system security,
including computer security. The document shall be titled <em>Gonculator
System Security Management Plan.</em> (DI-MISC-80839/T)
</p><p>
<b>F. Computer Security Management Program.</b> The contractor shall conduct
a Computer Security Management Program in accordance with the approved Computer
Security Management Plan.
</p><p>
<b>G. Computer Security Management Plan.</b> The contractor shall generate
a computer security management plan. The Plan shall include the methods used
to manage the computer security engineering program, program schedule, and
the steps to be taken to ensure the proper incorporation of the computer
security requirements into the system. The document shall be titled
<em>Gonculator Computer Security Management Plan.</em> (DI-MISC-80839/T)
</p><p>
<b>H. Security Vulnerability Analysis.</b> The contractor shall conduct a
security vulnerability analysis and document the results. The study shall
include identification of logical security vulnerabilities of the system,
defining functional requirements which may secure the system from exploitation,
and choosing safeguards to reduce identified vulnerabilities. The document
shall be titled <em>Gonculator Security Vulnerability Analysis.</em>
(DI-MISC-80841/T)
</p><p>
<b>I. Security Architecture Study.</b> The contractor shall conduct a study
of the security architecture of the system and document the results of the
study. The study shall include partitioning of the system, cost/benefit analysis
for the architectural alternatives, and the required Class of system for
each alternative and for each partitioned subsystem. The report shall detail
the recommended architecture for the system. The document shall be titled
<em>Gonculator Security Architecture Study.</em> (DI-GDRQ-80567/T)
</p><p>
<b>J. System Security Concept of Operations.</b> The contractor shall generate
a system security concept of operations that documents the security concept
for the system including the incorporation of the protection philosophy into
the system. The document shall be titled <em>Gonculator System Security Concept
Of Operations.</em> (DI-MISC-80840/T)
</p><p>
<b>K. Computer Security Policy.</b> The contractor shall prepare a document
that defines the security policy enforced by the computer system. The document
shall be titled <em>Gonculator Computer Security Policy.</em> (DI-GDRQ-80567/T)
</p><p>
<b>L. Computer Security Policy Model.</b> The contractor shall develop and
document a formal model of the security policy enforced by the system. The
model description shall include the specific protection mechanisms and an
explanation showing that they satisfy the model and will enforce the security
policy. The document shall be titled <em>Gonculator Computer Security Policy
Model. </em> (DI-GDRQ-80567/T)
</p><p>
<b>M. Computer Security Audit Analysis.</b> The contractor shall analyze
the audit schema for the system including events to be audited, audit record
structures, throughput requirements, storage needs, and archival storage
techniques. The document shall be titled <em>Gonculator Computer Security
Audit Analysis.</em> (DI-GDRQ-80567/T)
</p><p>
<b>N. Covert Channel Analysis.</b> The contractor shall conduct a thorough
search for covert storage channels and make a determination of the maximum
bandwidth of each identified channel. The contractor shall generate a covert
channel analysis report that documents the results of the covert channel
analysis. The document shall be titled <em>Gonculator Covert Storage Channel
Analysis Report. </em> (DI-GDRQ-80567/T)
</p><p>
<b>O. Descriptive Top Level Specification.</b> The contractor shall generate
a descriptive top level specification that completely and accurately describes
the TCB in terms of exceptions, error messages, effects, and interfaces.
The document shall be titled <em>Gonculator Trusted Computing Base Descriptive
Top Level Specification.</em> (DI-GDRQ-80567/T)
</p><p>
<b>P. Security Features Users Guide.</b> The contractor shall generate a
Users' Guide that documents the protection mechanisms provided by the system,
guidelines for their use, and how the protection mechanisms interact with
each other. The users guide may be published as either a common appendix
to the positional handbooks or a stand-alone document titled <em>Gonculator
Security Features Users' Guide</em>. (DI-MCCR-80019A/T)
</p><p>
<b>Q. Trusted Facility Manual.</b> The contractor shall generate a manual
that documents cautions about functions and privileges that should be controlled
when running the secure facility in accordance with DOD-5200.28-STD. The
document shall be titled <em>Gonculator Trusted Facility Manual.</em>
(DI-MCCR-80019A/T)
</p><p>
<b>R. Security Test.</b> The contractor shall conduct a separate security
test in conjunction with the system acceptance test. The security test shall
show that all security mechanisms function as defined in the system documentation
and that the system is resistant to penetration. The security test shall
include an ad hoc, loosely structured test by the government test team. The
contractor shall train the government test team in the operation of the system
before the start of the test. The government test team will consist of six
people drawn from the developing, supporting, using, and accrediting communities.
</p><p>
<b>S. Security Test Plan.</b> The contractor shall develop a test plan for
the security testing to be performed. The document shall be titled
<em>Gonculator Security Test Plan. </em> (DI-MCCR-80014A/T)
</p><p>
<b>T. Security TEST DESCRIPTION.</b> The contractor shall develop test procedures
to implement the approved Gonculator<em> </em>Security Test Plan. The document
shall be titled <em>Gonculator Security Test Description.</em> (DI-MCCR-80015A/T)
</p><p>
<b>U. Security Test Report.</b> The contractor shall document the results
of the security test. The document shall be titled <em>Gonculator Security
Test Report</em>. (DI-MCCR-80017A/T)
</p><p>
  </p><hr>
<h3>
  B3 Class
</h3>
<p>
The B3 class secure computer system is based on clearly defined security
policy and model of the policy. B3 class systems are appropriate for operation
in the compartmented and multilevel modes of operation.
</p><p>
Subjects and objects which are protected by DAC. Propagation of access rights
is controlled. Access is controlled at the granularity of named individual
and/or group of named individuals. The TCB is able to list the groups and
individuals with access to given objects including modes of access allowed
and those individuals and groups with no access allowed to an object. (This
implies, but does not explicitly require, Access Control Lists (ACL).)
</p><p>
The users are required to login and the system needs to be able to identify
individual users uniquely. While individuals are individuals, group access
rights are still allowed.
</p><p>
Reuse of storage objects (memory, disk space, buffers, etc.) is only allowed
after the object is cleared to disallow any access to the old data.
</p><p>
Audit is required to make users responsible for their actions. Half of the
theory behind audits is to allow for the security personnel to find wrongful
acts and identify the perpetrator; the other half of the theory is that an
advertised audit process will keep Honest people Honest. With labeling and
MAC, the security level is also recorded for objects being audited.
</p><p>
Labels are required for all system resources. These labels are used for MAC
decisions which are also mandated for all subjects and storage objects under
TCB control. The basic requirements are a simple translation of the standard
"Paper-style" requirements onto the computer so the computer will mark and
allow access properly.
</p><p>
The Trusted Computing Base (TCB) is required to protect itself (software)
for outside interference and tampering and to be able to validate the operations
of the TCB hardware and firmware. In addition, the TCB monitors the audit
events to determine if the activity indicates imminent security violations
and alerts the security officer upon occurrence.
</p><p>
<b>B3 Class Requirements</b>
</p><blockquote>
  10.1 Discretionary Access Control (DAC)
  <blockquote>
    10.1.1 The TCB shall control access between named users and named objects.
    <p>
    10.1.2 The TCB shall protect all named objects from unauthorized access.
    </p><p>
    10.1.3 The TCB shall allow for the inclusion or exclusion of access to named
    objects at the level of the single user.
    </p><p>
    10.1.4 The TCB shall allow authorized users to specify and control sharing
    of objects by named individuals or groups of individuals or both.
    </p><p>
    10.1.5 The TCB shall provide controls to limit propagation of access rights.
    </p><p>
    10.1.6 The TCB shall shall be capable of specifying a list of individuals
    and groups with access to the object including allowed access modes.
  </p></blockquote>
  <p>
  10.2 The TCB shall clear all memory objects before allocation to a new subject.
  </p><p>
  10.3 Identification and Authentication
  </p><blockquote>
    10.3.1 The TCB shall require users to uniquely identify themselves before
    performing any other actions on behalf of that user.
    <p>
    10.3.2 The TCB shall authenticate the user's unique identity before performing
    any other actions on behalf of that user.
    </p><p>
    10.3.3 The TCB shall ensure that the user's login security level and
    authorizations are dominated by the user's clearance and authorizations.
    </p><p>
    10.3.4 The TCB shall ensure that the security level and authorizations of
    subjects external to the TCB which are created on behalf of the user are
    dominated by the user's clearance and authorizations.
    </p><p>
    10.3.5 The TCB shall protect authentication data from unauthorized access.
    </p><p>
    10.3.6 The TCB shall associate the user's unique identity for all auditable
    actions taken by the user.
    </p><p>
    10.3.7 The TCB shall support a trusted communication path between the TCB
    and a user, initiated exclusively by the user or the TCB, for use when positive
    TCB-to-user connection is needed.
  </p></blockquote>
  <p>
  10.4 Audit
  </p><blockquote>
    10.4.1 The TCB shall be able to create an audit trail.
    <p>
    10.4.2 The TCB shall maintain the audit trail on-line for a minimum of thirty
    days.
    </p><p>
    10.4.3 The TCB shall protect the audit trail from modification or unauthorized
    access.
    </p><p>
    10.4.4 The TCB shall audit the following event types:
    </p><blockquote>
      a. Login.
      <p>
      b. Logout.
      </p><p>
      c. Access to objects.
      </p><p>
      d. Deletion of objects.
      </p><p>
      e. Override of human-readable output markings.
      </p><p>
      f. Labeling of imported unlabeled data.
      </p><p>
      g. Any change in the designation of single level and multilevel devices.
      </p><p>
      h. Any change in security level or levels associated with a subject or object.
      </p><p>
      i. Identified covert channel exploitation events.
      </p><p>
      j. Actions taken by system operators, administrators, and security officers.
    </p></blockquote>
    <p>
    10.4.5 The TCB shall include the following information in each audit trail
    record:
    </p><blockquote>
      a. Date and time of event.
      <p>
      b. User identity.
      </p><p>
      c. Event type.
      </p><p>
      d. Success or failure of action.
      </p><p>
      e. Security level of object, if any.
      </p><p>
      f. Name of object, if any.
    </p></blockquote>
    <p>
    10.4.6 The TCB shall selectively audit the actions of one or more users based
    on individual identity and/or object security level.
    </p><p>
    10.4.7 The TCB shall monitor the occurrence and accumulation of security
    audit events and identify imminent security violations.
    </p><p>
    10.4.8 The TCB shall alert the security officer of identified imminent security
    violations and take action to terminate continuing violations.
  </p></blockquote>
  <p>
  10.5 System Security Architecture
  </p><blockquote>
    10.5.1 The TCB shall maintain a domain of its own execution that protects
    it from external interference and tampering.
    <p>
    10.5.2 The TCB shall isolate the resources to be protected by access controls
    and auditing.
    </p><p>
    10.5.3 The TCB shall maintain distinct address spaces for process isolation.
    </p><p>
    10.5.4 The TCB shall be structured modularly.
    </p><p>
    10.5.5 The user interface to the TCB and all TCB elements shall be completely
    defined.
  </p></blockquote>
  <p>
  10.6 The TCB shall have the capability to validate the correct operations
  of the TCB's hardware and firmware.
  </p><p>
  10.7 Labels
  </p><blockquote>
    10.7.1 The TCB shall maintain the sensitivity label associated with each
    system resources accessible by subjects external to the TCB.
    <p>
    10.7.2 The sensitivity label associated with a subject or an object shall
    correctly represent the security level of the subject or object.
    </p><p>
    10.7.3 The TCB shall notify a terminal user of each change in the user's
    security level during a session.
    </p><p>
    10.7.4 The TCB shall support the assignment of minimum and maximum security
    levels for all attached devices.
    </p><p>
    10.7.5 The TCB shall use the sensitivity labels as the basis for mandatory
    access control decisions.
    </p><p>
    10.7.6 The TCB shall request a label from an authorized user before importing
    unlabeled data.
    </p><p>
    10.7.7 The TCB shall associate an accurate and unambiguous sensitivity label
    with all exported information.
    </p><p>
    10.7.8 The TCB shall designate each I/O device and communications channel
    as a single level or multilevel device.
    </p><p>
    10.7.9 Any change in the designation of single level or multilevel shall
    be performed manually.
    </p><p>
    10.7.10 The TCB shall associate with each object exported over a multilevel
    device the sensitivity level in the same form as the data and physically
    residing with the data.
    </p><p>
    10.7.11 The communications protocol used for each multilevel communications
    port shall provide for the unambiguous pairing of the data and its associated
    sensitivity label.
    </p><p>
    10.7.12 The TCB shall allow an authorized user to designate the single security
    level of information imported or exported via a single level communications
    port or I/O device.
    </p><p>
    10.7.13 The TCB shall allow the System Administrator to specify the printable
    label names associated with exported sensitivity labels.
    </p><p>
    10.7.14 The TCB shall mark the top and bottom of all human readable output
    with human readable sensitivity labels that properly represent the sensitivity
    of the output.
  </p></blockquote>
  <p>
  10.8 Mandatory Access Control (MAC)
  </p><blockquote>
    10.8.1 The TCB shall enforce mandatory access control over all subjects and
    objects accessible to subjects external to the TCB.
    <p>
    10.8.2 A subject shall be allowed read access only if the hierarchical
    classification in the subject's security level is greater than or equal to
    the hierarchical classification in the object's security level and the
    non-hierarchical categories in the subject's security level include all of
    the non-hierarchical categories in the object's security level.
    </p><p>
    10.8.3 A subject shall be allowed write access only if the hierarchical
    classification in the subject's security level is less than or equal to the
    hierarchical classification in the object's security level and all of the
    non-hierarchical categories in the subject's security level are included
    in the non-hierarchical categories in the object's security level.
  </p></blockquote>
</blockquote>
<p>
<b>B3 Class SOW Tasking</b>
</p><p>
<b>A. Gonculator Accreditation Working Group.</b> The contractor shall support
the Gonculator Accreditation Working Group (GAWG) through attendance at meetings
as needed, presenting current program data as requested, acting upon assigned
and accepted Action Items, and preparing minutes of the GAWG meetings. At
a minimum, the GAWG will meet twice a year. At a minimum, support at the
meetings shall include representatives from program management, configuration
management, system engineering, and security engineering. (DI-A-7089/T)
</p><p>
<b>B. Data Accession List.</b> The contractor shall maintain a complete list
of all data generated as a result of this contract. The contractor shall
list the data by title, date, and subject. The list shall include all memos,
letters, meeting minutes, phone logs, etc. All data not required by the CDRL
shall be considered contractor format. The document shall be titled
<em>Gonculator Data Accession List.</em> (DI-A-3027A/T)
</p><p>
<b>C. System Description.</b> The contractor shall prepare separately published
common appendices which describes the system for use with the system
documentation. These appendices shall be prepared in an Unclassified version,
if possible, and such classified versions that are required for a full
description of the Gonculator System. The contractor shall use the common
appendices in place of the system description within the bodies of the
documentation. The descriptions shall be titled <em>Gonculator System Description
Appendix, </em> (Appropriate Classification)<strong><em>
</em></strong>Version. (DI-GDRQ-80567/T)
</p><p>
<b>D. System Security Management Program.</b> The contractor shall conduct
a System Security Management Program in accordance with the approved System
Security Management Plan.
</p><p>
<b>E. System Security Management Plan.</b> The contractor shall develop a
system security management plan describing the contractor's security engineering
and management approach. The plan should include all aspects of system security,
including computer security. The document shall be titled <em>Gonculator
System Security Management Plan.</em> (DI-MISC-80839/T)
</p><p>
<b>F. Computer Security Management Program.</b> The contractor shall conduct
a Computer Security Management Program in accordance with the approved Computer
Security Management Plan.
</p><p>
<b>G. Computer Security Management Plan.</b> The contractor shall generate
a computer security management plan. The Plan shall include the methods used
to manage the computer security engineering program, program schedule, and
the steps to be taken to ensure the proper incorporation of the computer
security requirements into the system. The document shall be titled
<em>Gonculator Computer Security Management Plan.</em> (DI-MISC-80839/T)
</p><p>
<b>H. Security Vulnerability Analysis.</b> The contractor shall conduct a
security vulnerability analysis and document the results. The study shall
include identification of logical security vulnerabilities of the system,
defining functional requirements which may secure the system from exploitation,
and choosing safeguards to reduce identified vulnerabilities. The document
shall be titled <em>Gonculator Security Vulnerability Analysis.</em>
(DI-MISC-80841/T)
</p><p>
<b>I. Security Architecture Study.</b> The contractor shall conduct a study
of the security architecture of the system and document the results of the
study. The study shall include partitioning of the system, cost/benefit analysis
for the architectural alternatives, and the required Class of system for
each alternative and for each partitioned subsystem. The report shall detail
the recommended architecture for the system. The document shall be titled
<em>Gonculator Security Architecture Study.</em> (DI-GDRQ-80567/T)
</p><p>
<b>J. System Security Concept of Operations.</b> The contractor shall generate
a system security concept of operations that documents the security concept
for the system including the incorporation of the protection philosophy into
the system. The document shall be titled <em>Gonculator System Security Concept
Of Operations.</em> (DI-MISC-80840/T)
</p><p>
<b>K. Computer Security Policy.</b> The contractor shall prepare a document
that defines the security policy enforced by the computer system. The document
shall be titled <em>Gonculator Computer Security Policy.</em> (DI-GDRQ-80567/T)
</p><p>
<b>L. Computer Security Policy Model.</b> The contractor shall develop and
document a formal model of the security policy enforced by the system. The
model description shall include the specific protection mechanisms and an
explanation showing that they satisfy the model and will enforce the security
policy. The document shall be titled <em>Gonculator Computer Security Policy
Model. </em> (DI-GDRQ-80567/T)
</p><p>
<b>M. Computer Security Audit Analysis.</b> The contractor shall analyze
the audit schema for the system including events to be audited, audit record
structures, throughput requirements, storage needs, and archival storage
techniques. The document shall be titled <em>Gonculator Computer Security
Audit Analysis.</em> (DI-GDRQ-80567/T)
</p><p>
<b>N. Covert Channel Analysis.</b> The contractor shall conduct a thorough
search for covert channels and make a determination of the maximum bandwidth
of each identified channel. The contractor shall generate a covert channel
analysis report that documents the results of the covert channel analysis.
The document shall be titled <em>Gonculator Covert Storage Channel Analysis
Report. </em> (DI-GDRQ-80567/T)
</p><p>
<b>O. Descriptive Top Level Specification.</b> The contractor shall generate
a descriptive top level specification that completely and accurately describes
the TCB in terms of exceptions, error messages, effects, and interfaces.
The document shall be titled <em>Gonculator Trusted Computing Base Descriptive
Top Level Specification.</em> (DI-GDRQ-80567/T)
</p><p>
<b>P. Security Features Users Guide.</b> The contractor shall generate a
Users' Guide that documents the protection mechanisms provided by the system,
guidelines for their use, and how the protection mechanisms interact with
each other. The users guide may be published as either a common appendix
to the positional handbooks or a stand-alone document titled <em>Gonculator
Security Features Users' Guide</em>. (DI-MCCR-80019A/T)
</p><p>
<b>Q. Trusted Facility Manual.</b> The contractor shall generate a manual
that documents cautions about functions and privileges that should be controlled
when running the secure facility in accordance with DOD-5200.28-STD. The
document shall be titled <em>Gonculator Trusted Facility Manual.</em>
(DI-MCCR-80019A/T)
</p><p>
<b>R. Security Test.</b> The contractor shall conduct a separate security
test in conjunction with the system acceptance test. The security test shall
show that all security mechanisms function as defined in the system documentation
and that the system is resistant to penetration. The security test shall
include an ad hoc, loosely structured test by the government test team. The
contractor shall train the government test team in the operation of the system
before the start of the test. The government test team will consist of six
people drawn from the developing, supporting, using, and accrediting communities.
</p><p>
<b>S. Security Test Plan.</b> The contractor shall develop a test plan for
the security testing to be performed. The document shall be titled
<em>Gonculator Security Test Plan. </em> (DI-MCCR-80014A/T)
</p><p>
<b>T. Security TEST DESCRIPTION.</b> The contractor shall develop test procedures
to implement the approved Gonculator<em> </em>Security Test Plan. The document
shall be titled <em>Gonculator Security Test Description.</em> (DI-MCCR-80015A/T)
</p><p>
<b>U. Security Test Report.</b> The contractor shall document the results
of the security test. The document shall be titled <em>Gonculator Security
Test Report</em>. (DI-MCCR-80017A/T)
</p><p>
  </p><hr>
<h3>
  A1 Class
</h3>
<p>
The A1 class secure computer system is based on clearly defined security
policy and model of the policy. A1 class systems are appropriate for operation
in the multilevel mode of operation. The functional requirements for A1 are
identical to the requirements for the B3 class system. The increased protection
offered by A1 systems is through increased assurance measures.
</p><p>
Subjects and objects which are protected by DAC. Propagation of access rights
is controlled. Access is controlled at the granularity of named individual
and/or group of named individuals. The TCB is able to list the groups and
individuals with access to given objects including modes of access allowed
and those individuals and groups with no access allowed to an object. (This
implies, but does not explicitly require, Access Control Lists (ACL).)
</p><p>
The users are required to login and the system needs to be able to identify
individual users uniquely. While individuals are individuals, group access
rights are still allowed.
</p><p>
Reuse of storage objects (memory, disk space, buffers, etc.) is only allowed
after the object is cleared to disallow any access to the old data.
</p><p>
Audit is required to make users responsible for their actions. Half of the
theory behind audits is to allow for the security personnel to find wrongful
acts and identify the perpetrator; the other half of the theory is that an
advertised audit process will keep Honest people Honest. With labeling and
MAC, the security level is also recorded for objects being audited.
</p><p>
Labels are required for all system resources. These labels are used for MAC
decisions which are also mandated for all subjects and storage objects under
TCB control. The basic requirements are a simple translation of the standard
"Paper-style" requirements onto the computer so the computer will mark and
allow access properly.
</p><p>
The Trusted Computing Base (TCB) is required to protect itself (software)
for outside interference and tampering and to be able to validate the operations
of the TCB hardware and firmware. In addition, the TCB monitors the audit
events to determine if the activity indicates imminent security violations
and alerts the security officer upon occurrence.
</p><p>
<b>A1 Class Requirements</b>
</p><blockquote>
  10.1 Discretionary Access Control (DAC)
  <blockquote>
    10.1.1 The TCB shall control access between named users and named objects.
    <p>
    10.1.2 The TCB shall protect all named objects from unauthorized access.
    </p><p>
    10.1.3 The TCB shall allow for the inclusion or exclusion of access to named
    objects at the level of the single user.
    </p><p>
    10.1.4 The TCB shall allow authorized users to specify and control sharing
    of objects by named individuals or groups of individuals or both.
    </p><p>
    10.1.5 The TCB shall provide controls to limit propagation of access rights.
    </p><p>
    10.1.6 The TCB shall shall be capable of specifying a list of individuals
    and groups with access to the object including allowed access modes.
  </p></blockquote>
  <p>
  10.2 The TCB shall clear all memory objects before allocation to a new subject.
  </p><p>
  10.3 Identification and Authentication
  </p><blockquote>
    10.3.1 The TCB shall require users to uniquely identify themselves before
    performing any other actions on behalf of that user.
    <p>
    10.3.2 The TCB shall authenticate the user's unique identity before performing
    any other actions on behalf of that user.
    </p><p>
    10.3.3 The TCB shall ensure that the user's login security level and
    authorizations are dominated by the user's clearance and authorizations.
    </p><p>
    10.3.4 The TCB shall ensure that the security level and authorizations of
    subjects external to the TCB which are created on behalf of the user are
    dominated by the user's clearance and authorizations.
    </p><p>
    10.3.5 The TCB shall protect authentication data from unauthorized access.
    </p><p>
    10.3.6 The TCB shall associate the user's unique identity for all auditable
    actions taken by the user.
    </p><p>
    10.3.7 The TCB shall support a trusted communication path between the TCB
    and a user, initiated exclusively by the user or the TCB, for use when positive
    TCB-to-user connection is needed.
  </p></blockquote>
  <p>
  10.4 Audit
  </p><blockquote>
    10.4.1 The TCB shall be able to create an audit trail.
    <p>
    10.4.2 The TCB shall maintain the audit trail on-line for a minimum of thirty
    days.
    </p><p>
    10.4.3 The TCB shall protect the audit trail from modification or unauthorized
    access.
    </p><p>
    10.4.4 The TCB shall audit the following event types:
    </p><blockquote>
      a. Login.
      <p>
      b. Logout.
      </p><p>
      c. Access to objects.
      </p><p>
      d. Deletion of objects.
      </p><p>
      e. Override of human-readable output markings.
      </p><p>
      f. Labeling of imported unlabeled data.
      </p><p>
      g. Any change in the designation of single level and multilevel devices.
      </p><p>
      h. Any change in security level or levels associated with a subject or object.
      </p><p>
      i. Identified covert channel exploitation events.
      </p><p>
      j. Actions taken by system operators, administrators, and security officers.
    </p></blockquote>
    <p>
    10.4.5 The TCB shall include the following information in each audit trail
    record:
    </p><blockquote>
      a. Date and time of event.
      <p>
      b. User identity.
      </p><p>
      c. Event type.
      </p><p>
      d. Success or failure of action.
      </p><p>
      e. Security level of object, if any.
      </p><p>
      f. Name of object, if any.
    </p></blockquote>
    <p>
    10.4.6 The TCB shall selectively audit the actions of one or more users based
    on individual identity and/or object security level.
    </p><p>
    10.4.7 The TCB shall monitor the occurrence and accumulation of security
    audit events and identify imminent security violations.
    </p><p>
    10.4.8 The TCB shall alert the security officer of identified imminent security
    violations and take action to terminate continuing violations.
  </p></blockquote>
  <p>
  10.5 System Security Architecture
  </p><blockquote>
    10.5.1 The TCB shall maintain a domain of its own execution that protects
    it from external interference and tampering.
    <p>
    10.5.2 The TCB shall isolate the resources to be protected by access controls
    and auditing.
    </p><p>
    10.5.3 The TCB shall maintain distinct address spaces for process isolation.
    </p><p>
    10.5.4 The TCB shall be structured modularly.
    </p><p>
    10.5.5 The user interface to the TCB and all TCB elements shall be completely
    defined.
  </p></blockquote>
  <p>
  10.6 The TCB shall have the capability to validate the correct operations
  of the TCB's hardware and firmware.
  </p><p>
  10.7 Labels
  </p><blockquote>
    10.7.1 The TCB shall maintain the sensitivity label associated with each
    system resources accessible by subjects external to the TCB.
    <p>
    10.7.2 The sensitivity label associated with a subject or an object shall
    correctly represent the security level of the subject or object.
    </p><p>
    10.7.3 The TCB shall notify a terminal user of each change in the user's
    security level during a session.
    </p><p>
    10.7.4 The TCB shall support the assignment of minimum and maximum security
    levels for all attached devices.
    </p><p>
    10.7.5 The TCB shall use the sensitivity labels as the basis for mandatory
    access control decisions.
    </p><p>
    10.7.6 The TCB shall request a label from an authorized user before importing
    unlabeled data.
    </p><p>
    10.7.7 The TCB shall associate an accurate and unambiguous sensitivity label
    with all exported information.
    </p><p>
    10.7.8 The TCB shall designate each I/O device and communications channel
    as a single level or multilevel device.
    </p><p>
    10.7.9 Any change in the designation of single level or multilevel shall
    be performed manually.
    </p><p>
    10.7.10 The TCB shall associate with each object exported over a multilevel
    device the sensitivity level in the same form as the data and physically
    residing with the data.
    </p><p>
    10.7.11 The communications protocol used for each multilevel communications
    port shall provide for the unambiguous pairing of the data and its associated
    sensitivity label.
    </p><p>
    10.7.12 The TCB shall allow an authorized user to designate the single security
    level of information imported or exported via a single level communications
    port or I/O device.
    </p><p>
    10.7.13 The TCB shall allow the System Administrator to specify the printable
    label names associated with exported sensitivity labels.
    </p><p>
    10.7.14 The TCB shall mark the top and bottom of all human readable output
    with human readable sensitivity labels that properly represent the sensitivity
    of the output.
  </p></blockquote>
  <p>
  10.8 Mandatory Access Control (MAC)
  </p><blockquote>
    10.8.1 The TCB shall enforce mandatory access control over all subjects and
    objects accessible to subjects external to the TCB.
    <p>
    10.8.2 A subject shall be allowed read access only if the hierarchical
    classification in the subject's security level is greater than or equal to
    the hierarchical classification in the object's security level and the
    non-hierarchical categories in the subject's security level include all of
    the non-hierarchical categories in the object's security level.
    </p><p>
    10.8.3 A subject shall be allowed write access only if the hierarchical
    classification in the subject's security level is less than or equal to the
    hierarchical classification in the object's security level and all of the
    non-hierarchical categories in the subject's security level are included
    in the non-hierarchical categories in the object's security level.
  </p></blockquote>
</blockquote>
<p>
<b>A1 Class SOW Tasking</b>
</p><p>
<b>A. Gonculator Accreditation Working Group.</b> The contractor shall support
the Gonculator Accreditation Working Group (GAWG) through attendance at meetings
as needed, presenting current program data as requested, acting upon assigned
and accepted Action Items, and preparing minutes of the GAWG meetings. At
a minimum, the GAWG will meet twice a year. At a minimum, support at the
meetings shall include representatives from program management, configuration
management, system engineering, and security engineering. (DI-A-7089/T)
</p><p>
<b>B. Data Accession List.</b> The contractor shall maintain a complete list
of all data generated as a result of this contract. The contractor shall
list the data by title, date, and subject. The list shall include all memos,
letters, meeting minutes, phone logs, etc. All data not required by the CDRL
shall be considered contractor format. The document shall be titled
<em>Gonculator Data Accession List.</em> (DI-A-3027A/T)
</p><p>
<b>C. System Description.</b> The contractor shall prepare separately published
common appendices which describes the system for use with the system
documentation. These appendices shall be prepared in an Unclassified version,
if possible, and such classified versions that are required for a full
description of the Gonculator System. The contractor shall use the common
appendices in place of the system description within the bodies of the
documentation. The descriptions shall be titled <em>Gonculator System Description
Appendix, </em> (Appropriate Classification)<strong><em>
</em></strong>Version. (DI-GDRQ-80567/T)
</p><p>
<b>D. System Security Management Program.</b> The contractor shall conduct
a System Security Management Program in accordance with the approved System
Security Management Plan.
</p><p>
<b>E. System Security Management Plan.</b> The contractor shall develop a
system security management plan describing the contractor's security engineering
and management approach. The plan should include all aspects of system security,
including computer security. The document shall be titled <em>Gonculator
System Security Management Plan.</em> (DI-MISC-80839/T)
</p><p>
<b>F. Computer Security Management Program.</b> The contractor shall conduct
a Computer Security Management Program in accordance with the approved Computer
Security Management Plan.
</p><p>
<b>G. Computer Security Management Plan.</b> The contractor shall generate
a computer security management plan. The Plan shall include the methods used
to manage the computer security engineering program, program schedule, and
the steps to be taken to ensure the proper incorporation of the computer
security requirements into the system. The document shall be titled
<em>Gonculator Computer Security Management Plan.</em> (DI-MISC-80839/T)
</p><p>
<b>H. Security Vulnerability Analysis.</b> The contractor shall conduct a
security vulnerability analysis and document the results. The study shall
include identification of logical security vulnerabilities of the system,
defining functional requirements which may secure the system from exploitation,
and choosing safeguards to reduce identified vulnerabilities. The document
shall be titled <em>Gonculator Security Vulnerability Analysis.</em>
(DI-MISC-80841/T)
</p><p>
<b>I. Security Architecture Study.</b> The contractor shall conduct a study
of the security architecture of the system and document the results of the
study. The study shall include partitioning of the system, cost/benefit analysis
for the architectural alternatives, and the required Class of system for
each alternative and for each partitioned subsystem. The report shall detail
the recommended architecture for the system. The document shall be titled
<em>Gonculator Security Architecture Study.</em> (DI-GDRQ-80567/T)
</p><p>
<b>J. System Security Concept of Operations.</b> The contractor shall generate
a system security concept of operations that documents the security concept
for the system including the incorporation of the protection philosophy into
the system. The document shall be titled <em>Gonculator System Security Concept
Of Operations.</em> (DI-MISC-80840/T)
</p><p>
<b>K. Computer Security Policy.</b> The contractor shall prepare a document
that defines the security policy enforced by the computer system. The document
shall be titled <em>Gonculator Computer Security Policy.</em> (DI-GDRQ-80567/T)
</p><p>
<b>L. Computer Security Policy Model.</b> The contractor shall develop and
document a formal model of the security policy enforced by the system. The
model description shall include the specific protection mechanisms and an
explanation showing that they satisfy the model and will enforce the security
policy. The document shall be titled <em>Gonculator Computer Security Policy
Model. </em> (DI-GDRQ-80567/T)
</p><p>
<b>M. Computer Security Audit Analysis.</b> The contractor shall analyze
the audit schema for the system including events to be audited, audit record
structures, throughput requirements, storage needs, and archival storage
techniques. The document shall be titled <em>Gonculator Computer Security
Audit Analysis.</em> (DI-GDRQ-80567/T)
</p><p>
<b>N. Covert Channel Analysis.</b> The contractor shall use formal methods
to conduct a thorough search for covert channels and make a determination
of the maximum bandwidth of each identified channel. The contractor shall
generate a covert channel analysis report that documents the results of the
covert channel analysis. The document shall be titled <em>Gonculator Covert
Storage Channel Analysis Report. </em> (DI-GDRQ-80567/T)
</p><p>
<b>O. Descriptive Top Level Specification.</b> The contractor shall generate
a descriptive top level specification that completely and accurately describes
the TCB in terms of exceptions, error messages, effects, and interfaces.
The document shall be titled <em>Gonculator Trusted Computing Base Descriptive
Top Level Specification.</em> (DI-GDRQ-80567/T)
</p><p>
<b>P. Formal Top Level Specification.</b> The contractor shall develop a
Formal Top Level Specification that accurately describes the TCB in terms
of exceptions, error messages, and effects. The FTLS shall be developed with
the use of an NCSC-endosed formal specification and verification system.
The document shall be titled <em>Gonculator Trusted Computing Base Formal
Top Level Specification.</em> (DI-GDRQ-80567/T)
</p><p>
<b>Q. Security Features Users Guide.</b> The contractor shall generate a
Users' Guide that documents the protection mechanisms provided by the system,
guidelines for their use, and how the protection mechanisms interact with
each other. The users guide may be published as either a common appendix
to the positional handbooks or a stand-alone document titled <em>Gonculator
Security Features Users' Guide</em>. (DI-MCCR-80019A/T)
</p><p>
<b>R. Trusted Facility Manual.</b> The contractor shall generate a manual
that documents cautions about functions and privileges that should be controlled
when running the secure facility in accordance with DOD-5200.28-STD. The
document shall be titled <em>Gonculator Trusted Facility Manual.</em>
(DI-MCCR-80019A/T)
</p><p>
<b>S. Security Test.</b> The contractor shall conduct a separate security
test in conjunction with the system acceptance test. The security test shall
show that all security mechanisms function as defined in the system documentation
and that the system is resistant to penetration. The security test shall
include an ad hoc, loosely structured test by the government test team. The
contractor shall train the government test team in the operation of the system
before the start of the test. The government test team will consist of six
people drawn from the developing, supporting, using, and accrediting communities.
</p><p>
<b>T. Security Test Plan.</b> The contractor shall develop a test plan for
the security testing to be performed. The document shall be titled
<em>Gonculator Security Test Plan. </em> (DI-MCCR-80014A/T)
</p><p>
<b>U. Security TEST DESCRIPTION.</b> The contractor shall develop test procedures
to implement the approved Gonculator<em> </em>Security Test Plan. The document
shall be titled <em>Gonculator Security Test Description.</em> (DI-MCCR-80015A/T)
</p><p>
<b>V. Security Test Report.</b> The contractor shall document the results
of the security test. The document shall be titled <em>Gonculator Security
Test Report</em>. (DI-MCCR-80017A/T)
</p><p>
  </p><hr>
<h3>
  Contract Data Requirements List Inputs
</h3>
<p>
1. Gonculator Accreditation Working Group Meeting Minutes
</p><blockquote>
  DI-A-7089 Meeting Minutes.
  <p>
  Due 5 Days after each GAWG Meeting.
  </p><p>
  Distribution to all GAWG Members and Attenders.
  </p><p>
  Justification: Data is needed to document the results of the GAWG.
  </p><p>
  Contractor format acceptable.
</p></blockquote>
<p>
2. Data Accession List
</p><blockquote>
  DI-A-3027A Data Accession List
  <p>
  Due monthly.
  </p><p>
  Justification: Data is needed to monitor contractor work in progress.
  </p><p>
  Contractor format acceptable.
  </p><p>
  NOTE: This is a DID on contract for most programs. The reason it it included
  in this list is the generally insufficient level of detail found on a DAL.
  Since the DAL is based almost entirely on the tasking, there is a SOW paragraph
  calling for the proper level of detail included in the SOW Tasking for each
  Class.
</p></blockquote>
<p>
3. System Description Appendix
</p><blockquote>
  DI-GDRQ-80567 Subsystem Design Analysis Report
  <p>
  Due 90DAC with Updates as the design of the system develops sufficiently
  to invalidate the
  </p><p>
  previous version, but not later than each major review.
  </p><p>
  Direct distribution is limited to the Program Office, Program Engineering,
  and Configuration
  </p><p>
  Management. The document will also be distributed as an appendix to all other
  documents which need a system description.
  </p><p>
  Justification: This data is needed to form a unified view of the system as
  it progresses.
  </p><p>
  Contractor format acceptable.
</p></blockquote>
<p>
4. System Security Management Plan
</p><blockquote>
  DI-MISC-80839 System Security Management Plan
  <p>
  Due 90DAC with revisions for each new major phase of the program.
  </p><p>
  Distribution to the Program Office, Program Engineering, and Accreditor.
  </p><p>
  Justification: This data is needed to establish a viable System Security
  Management
  </p><p>
  Program (SSMP). The approved plan is the direction to the contractor for
  the implementation of the SSMP.
  </p><p>
  Contractor format acceptable. Delete 10.6.2 through 10.6.7
</p></blockquote>
<p>
5. Computer Security Management Plan
</p><blockquote>
  DI-MISC-80839 System Security Management Plan
  <p>
  Due 90DAC with revisions for each new major phase of the program.
  </p><p>
  Distribution to the Program Office, Program Engineering, and Accreditor.
  </p><p>
  Justification: This data is needed to establish a viable Computer Security
  Management
  </p><p>
  Program (CSMP). The approved plan is the direction to the contractor for
  the implementation of the CSMP.
  </p><p>
  Contractor format acceptable. Delete 10.6.2 through 10.6.7
</p></blockquote>
<p>
6. Security Vulnerability Analysis
</p><blockquote>
  DI-MISC-80841 Security Vulnerability Analysis
  <p>
  Preliminary version due 30DAC. Final due SRR-30 (or 90DAC if no SRR).
  </p><p>
  Distribution to the Program Office, Program Engineering, and Accreditor.
  </p><p>
  Justification: This data is needed to validate the sufficiency of the security
  requirements levied on the system to avoid designed-in security breaches.
  </p><p>
  Contractor format acceptable.
</p></blockquote>
<p>
7. Security Architecture Study
</p><blockquote>
  DI-GDRQ-80567 Subsystem Design Analysis Report
  <p>
  Preliminary version due 90DAC. Final due SDR-30.
  </p><p>
  Distribution to the Program Office, Program Engineering, and Accreditor.
  </p><p>
  Justification: This data is needed to validate the sufficiency of the security
  requirements levied on the system to avoid designed-in security breaches.
  </p><p>
  Contractor format acceptable.
</p></blockquote>
<p>
8. System Security Concept of Operations
</p><blockquote>
  DI-MISC-80840 Preliminary System Security Concept
  <p>
  Preliminary version due 90DAC. Final due SDR-30.
  </p><p>
  Distribution to the Program Office, Program Engineering, Users, and Accreditor.
  </p><p>
  Justification: This data is needed to validate the sufficiency of the security
  requirements levied on the system to avoid designed-in security breaches
  and to ensure the operational workability of the design concept.
  </p><p>
  Contractor format acceptable.
</p></blockquote>
<p>
9. Computer Security Policy
</p><blockquote>
  DI-GDRQ-80567 Subsystem Design Analysis Report
  <p>
  Preliminary version due 30DAC. Final SRR-30. Revisions as needed by changes
  to system security policy.
  </p><p>
  Distribution to the Program Office, Program Engineering, Users, and Accreditor.
  </p><p>
  Justification: This data is needed to establish the baseline for the security
  policy to be enforced by the system.
  </p><p>
  Contractor format acceptable.
</p></blockquote>
<p>
10. Computer Security Policy Model
</p><blockquote>
  DI-GDRQ-80567 Subsystem Design Analysis Report
  <p>
  Preliminary version due SDR-30. Final due PDR-30. Revisions as needed.
  </p><p>
  Distribution to the Program Office, Program Engineering, and Accreditor.
  </p><p>
  Justification: This data is needed to validate the model of the policy for
  sufficiency and completeness.
  </p><p>
  Contractor format acceptable.
</p></blockquote>
<p>
11. Computer Security Audit Analysis
</p><blockquote>
  DI-GDRQ-80567 Subsystem Design Analysis Report
  <p>
  Due SDR-30. Quarterly submittals after approval.
  </p><p>
  Distribution to the Program Office and Program Engineering.
  </p><p>
  Justification: This data is needed to evaluate the contractor design and
  implementation of the audit requirements and related performance issues.
  </p><p>
  Contractor format acceptable.
</p></blockquote>
<p>
12. Covert Channel Analysis
</p><blockquote>
  DI-GDRQ-80567 Subsystem Design Analysis Report
  <p>
  Preliminary version due SDR-30. Final due PDR-30. Revisions as needed.
  </p><p>
  Distribution to the Program Office, Program Engineering, and Accreditor.
  </p><p>
  Justification: This data is needed to evaluate the security of the contractor's
  deign and implementation with regards to covert channels.
  </p><p>
  Contractor format acceptable.
</p></blockquote>
<p>
13. Descriptive Top Level Specification
</p><blockquote>
  DI-GDRQ-80567 Subsystem Design Analysis Report
  <p>
  Preliminary version due SDR-30. Final due PDR-30. Revisions as needed.
  </p><p>
  Distribution to the Program Office, Program Engineering, and Accreditor.
  </p><p>
  Justification: This data is needed to validate the contractor's design for
  the Trusted Computing Base (TCB).
  </p><p>
  Contractor format acceptable.
</p></blockquote>
<p>
14. Formal Top Level Specification
</p><blockquote>
  DI-GDRQ-80567 Subsystem Design Analysis Report
  <p>
  Preliminary version due SDR-30. Final due PDR-30. Revisions as needed.
  </p><p>
  Distribution to the Program Office, Program Engineering, and Accreditor.
  </p><p>
  Justification: This data is needed to formally validate the contractor's
  design for the Trusted Computing Base (TCB).
  </p><p>
  Contractor format acceptable.
</p></blockquote>
<p>
15. Security Features Users Guide
</p><blockquote>
  DI-MCCR-80019A Software User's Manual
  <p>
  Preliminary due CDR-30. Final due 30 days before test.
  </p><p>
  Distribution to the Program Office, Program Engineering, Users, and Accreditor.
  </p><p>
  Justification: This data is needed to guide the users in the use of the security
  features.
  </p><p>
  Contractor format acceptable.
</p></blockquote>
<p>
16. Trusted Facility Manual
</p><blockquote>
  DI-MCCR-80019A Software User's Manual
  <p>
  Preliminary due CDR-30. Final due 30 days before test.
  </p><p>
  Distribution to the Program Office, Program Engineering, Users, and Accreditor.
  </p><p>
  Justification: This data is needed to guide the security personnel in the
  use of the security safeguards.
  </p><p>
  Contractor format acceptable.
</p></blockquote>
<p>
17. Security Test Plan
</p><blockquote>
  DI-MCCR-80014A Software Test Plan
  <p>
  Preliminary due CDR-30. Final due CDR+90.
  </p><p>
  Distribution to the Program Office, Program Engineering, Users, and Accreditor.
  </p><p>
  Justification: This data is needed to determine the sufficiency of the security
  safeguards in the completed system.
  </p><p>
  Contractor format acceptable.
</p></blockquote>
<p>
18. Security Test Description
</p><blockquote>
  DI-MCCR-80015A Software Test Description
  <p>
  Preliminary version due 90 days before test. Final due 30 days before test.
  </p><p>
  Distribution to the Program Office and Program Engineering.
  </p><p>
  Justification: This data is needed to establish the procedures to be used
  during the system security test.
  </p><p>
  Contractor format acceptable.
</p></blockquote>
<p>
19. Security Test Report
</p><blockquote>
  DI-MCCR-80017A Software Test Report
  <p>
  Due 30 days after security test completion.
  </p><p>
  Distribution to the Program Office, Program Engineering, Users, and Accreditor.
  </p><p>
  Justification: This data is needed to determine the sufficiency of the security
  safeguards in the completed system.
  </p><p>
  Contractor format acceptable.
</p></blockquote>
<p>
<table cellpadding="12">
  <tbody><tr>
    <td>Gonculator Accreditation Working Group</td>
    <td></td>
    <td></td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Gonculator Accreditation Working Group &nbsp; &nbsp;</td>
    <td></td>
    <td></td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Data Accession List</td>
    <td>C1</td>
    <td>C2</td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>System Description</td>
    <td>C1</td>
    <td>C2</td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>System Security Management Program</td>
    <td>C1</td>
    <td>C2</td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>System Security Management Plan</td>
    <td>C1</td>
    <td>C2</td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Computer Security Management Program</td>
    <td></td>
    <td></td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Computer Security Management Plan</td>
    <td></td>
    <td></td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Security Vulnerability Analysis</td>
    <td>C1</td>
    <td>C2</td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Security Architecture Study</td>
    <td></td>
    <td></td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>System Security Concept of Operations</td>
    <td></td>
    <td></td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Computer Security Policy</td>
    <td>C1</td>
    <td>C2</td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Computer Security Policy Model</td>
    <td></td>
    <td></td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Computer Security Audit Analysis</td>
    <td></td>
    <td>C2</td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Covert Channel Analysis</td>
    <td></td>
    <td></td>
    <td></td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Descriptive Top Level Specification</td>
    <td></td>
    <td></td>
    <td></td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Formal Top Level Specification</td>
    <td></td>
    <td></td>
    <td></td>
    <td></td>
    <td></td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Security Features Users Guide</td>
    <td>C1</td>
    <td>C2</td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Trusted Facility Manual</td>
    <td>C1</td>
    <td>C2</td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Security Test</td>
    <td></td>
    <td></td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Security Test Plan</td>
    <td></td>
    <td></td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Security Test Description B1 B2 B3 A1</td>
    <td></td>
    <td></td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
  <tr>
    <td>Security Test Report</td>
    <td></td>
    <td></td>
    <td>B1</td>
    <td>B2</td>
    <td>B3</td>
    <td>A1</td>
  </tr>
</tbody></table>
</p><p>
  </p><hr>
<h3>
  Data Item Descriptions (DIDs)
</h3>
<p>
Because some of the DIDs mentioned in the SOW Tasking and CDRL Inputs portions
of this section may be unfamiliar to some, and difficult to find for all,
this portion of the section is dedicated to the DIDs themselves. Each of
the major DIDs is included in its entirety. The DIDs contained here are:
</p><blockquote>
  DI-GDRQ-80567 Subsystem Design Analysis Report: This DID is a relatively
  generic DID which is useful for the production of the out-of-the-norm documents.
  In particular, the following documents use this DID:
  <blockquote>
    Covert Channel Analysis Report
    <p>
    Descriptive Top Level Specification
    </p><p>
    Formal Top Level Specification
    </p><p>
    Computer Security Audit Analysis
    </p><p>
    Computer Security Policy
    </p><p>
    Computer Security Policy Model
    </p><p>
    Security Architecture Study
    </p><p>
    System Description Appendix
  </p></blockquote>
  <p>
  DI-MISC-80839 System Security Management Plan: This DID is useful for both
  the System Security Management Plan and the Computer Security Management
  Plan.
  </p><p>
  DI-MISC-80840 Preliminary System Security Concept: This DID is useful for
  the System Security Concept of Operations.
  </p><p>
  DI-MISC-80841 Security Vulnerability Analysis: This DID is useful for the
  Security Vulnerability Analysis. (Oddly enough.)
  </p><p>
  DI-IPSC-80690 System/Subsystem Specification (SS) Document for Automated
  Information Systems (AIS): As the system's security functionality increases
  as a proportion of the total system functionality this DID becomes increasingly
  useful. In particular, if the system has security operations as its primary
  function (as in a security add-on subsystem) this is the DID which should
  be used.
  </p><p>
  DI-MISC-80842 Adversary Mission Analysis: This DID is a non-CompuSec portion
  of the standard System Security Engineering Management Program.
  </p><p>
  DI-S-1817 Logistical Support Plan: This DID is a non-CompuSec portion of
  the standard System Security Engineering Management Program.
</p></blockquote>
<p>
  </p><hr>
<p>
<i>[Note: The following HTML versions of DIDs may be replaced with correctly
formatted DIDs 1817, 80016, 80017, 80567, 80690, 80839, 80840, 80841 and
80841 available in Word 7.0 files in a single Zip-compressed file:
<a href="http://jya.com/ntob-did.zip">http://jya.com/ntob-did.zip</a>
&nbsp;(51K) ]</i>
</p><p>
  </p><hr>
<p>
<strong>Data Item Description </strong>
</p><p>
1. TITLE Subsystem Design Analysis Report
</p><p>
2. Identification Number DI-GDRQ-80567
</p><p>
3. Description/Purpose
</p><blockquote>
  3.1 This report is used to evaluate the design approach for the configuration
  item or subsystem and to provide visibility to the government. The data may
  also be used to formulate additional technical direction to the design activity.
</blockquote>
<p>
4. Approval Date 880415
</p><p>
5. OPR F/AD/ALX
</p><p>
6a. DTIC Applicable X
</p><p>
6b. GDEP Applicable
</p><p>
7. Application/Interrelationship
</p><blockquote>
  7.1 This data item description (DID) contains the format and content preparation
  instructions for the data product generated by the specific and discrete
  task requirements as delineated in the contract.
  <p>
  7.2 This report is normally prepared during the analysis effort for each
  configuration item or subsystem during system acquisition. It may also be
  applicable to other development efforts.
  </p><p>
  7.3 Specific requirements of MIL-STD-847 should be stated in the contract
  data requirements list.
  </p><p>
  7.4 This report should be considered for submission to the Defense Technical
  Information Center, Cameron Station, Alexandria VA under the provisions of
  AFR 80-40.
  </p><p>
  7.5 This DID supersedes DI-S-3581.
</p></blockquote>
<p>
8. Approval Limitation
</p><p>
9a. Applicable Forms
</p><p>
9b. AMSC Number F4380
</p><p>
10. Preparation Instructions (Continued on Page 2)
</p><p>
11. Distribution Statement DISTRIBUTION STATEMENT A: Approved for public
release; distribution is unlimited.
</p><p>
Page <u>1 </u> of <u>2 </u> Pages
</p><p>
  </p><hr>
<p>
Block 10. Preparation Instructions (Continued)
</p><blockquote>
  10.1 <u>Reference Documents.</u> The applicable issue cited herein, including
  their approval dates and dates of any applicable amendments, notices, and
  revisions shall be specified in the contract.
  <p>
  10.2 <u>Format.</u> The report shall be structured to separately cover each
  of the major subsections of the design analysis task. The analysis report
  shall correlate the design requirements with the system requirement and any
  specified requirement for the subsystem or configuration item. The report
  shall include or reference all related data (sketches, preliminary drawings,
  schematics, functional diagrams) necessary for portrayal of the analysis
  or to aid in an understanding of the analysis.
  </p><blockquote>
    10.2.1 The report shall be generally written to MIL-STD-847 format. Specific
    requirements of MIL-STD-847 will be stated in the contract.
  </blockquote>
  <p>
  10.3 <u>Content.</u> The report shall include the following:
  </p><p>
  10.3.1 Objective of the analysis.
  </p><p>
  10.3.2 Description of the items involved, including adequate drawings,
  schematics, and computer print-outs to support the analysis.
  </p><p>
  10.3.3 Specification of design constraints and assumptions imposed on the
  analysis.
  </p><p>
  10.3.4 Discussion of the evaluation and analysis procedure, method, or technique
  used, and its probable accuracy, explained by sample calculations.
  </p><p>
  10.3.5 Identification of source material used in the analysis.
  </p><p>
  10.3.6 Results of the analysis to include such aspects as:
  </p><blockquote>
    a. Predicted performance related to requirements.
    <p>
    b. Design impact and any constraints which influence other subsystems or
    configuration items.
    </p><p>
    c. Producibility considerations.
    </p><p>
    d. Problems encountered or revealed and suggested solutions.
  </p></blockquote>
  <p>
  10.3.7 Conclusions.
</p></blockquote>
<p>
Page <u>2 </u> of <u>2 </u> Pages
</p><p>
  </p><hr>
<p>
<strong>Data Item Description </strong>
</p><p>
1. TITLE System Security Management plan
</p><p>
2. Identification Number DI-MISC-80839
</p><p>
3. Description/Purpose 3.1 Outlines and defines the contractor System Security
Management Program. The SSMP describes the methods used to (1) identify security
requirements, (2) synthesize and evaluate proposed solutions, and (3) provide
security inputs to the system acquisition process.
</p><p>
4. Approval Date 890605
</p><p>
5. OPR AF 10
</p><p>
6a. DTIC Applicable x
</p><p>
6b. GDEP Applicable
</p><p>
7. Application/Interrelationship 7.1 This Data Item Description contains
the format and content preparation instructions for data resulting from the
work task described by 5.3.1.1 of MIL-STD-1785. 7.2 Security Vulnerability
Analysis, DI-MISC-80841, is used with this Data Item Description when paragraphs
10.1.6.2 through 10.1.6.7 are cited. 7.3 This Data Item description supersedes
DI-R-3527/S-112-1. 7.4 Defense Technical Information Center, Cameron Station,
Alexandria VA 22314-6100.
</p><p>
8. Approval Limitation 9a. Applicable Forms 9b. AMSC Number F4730
</p><p>
10. Preparation Instructions (Continued on Page 2)
</p><p>
11. Distribution Statement DISTRIBUTION STATEMENT A: Approved for public
release; distribution is unlimited.
</p><p>
Page <u>1</u> of <u>3</u> Pages
</p><p>
  </p><hr>
<p>
Block 10. Preparation Instructions (Continued)
</p><p>
10.1 The System Security Management Plan (SSMP) shall include the following:
</p><blockquote>
  10.1.1 <u>Applicable Documents.</u> A list of documents which apply as directives
  or guidance during the execution of the SSMP. The list shall include pertinent
  legal, regulatory, and other published or draft contract requirements applicable
  to the system under development. System security requirements and objectives
  are drawn from these documents.
  <p>
  10.1.2 <u>Purpose.</u> State the approach to the System Security Engineering
  Program (SSEP) and the principles which will be applied.
  </p><p>
  10.1.3 <u>Organization.</u> Describe the organizational placement and manning
  of the contractor's security engineering management organization. Use charts
  and diagrams to show organizational and functional relationships.
  </p><p>
  10.1.4 <u>System Security Engineering Management Program.</u> Describe the
  activities planned to satisfy System Security engineering program objectives.
  Use charts or diagrams to illustrate the program's functional interfaces,
  engineering and design requirements, activity milestones, management process,
  and levels of effort for each program phase.
  </p><p>
  10.1.5 <u>Program Data Flow.</u> Illustrate the manner in which basic program
  data flows, indicating how the system security engineering organization will
  monitor all program efforts and make inputs to decision processes.
  </p><p>
  10.1.6 <u>System Security Engineering Functions.</u> Describe the principal
  functions and specific tasks to be performed as given in the Statement of
  Work. Describe the assignment of these functions and tasks within the system
  security engineering organization. Include the following:
  </p><blockquote>
    10.1.6.1 <u>Establishing the Security Requirements and Objectives Baseline.</u>
    Describe how the SSMP will address the following security concerns: Personnel,
    industrial, operations, product, communications, and physical security;
    survivability, antiterrorism and counterintelligence aspects. Describe how
    the security regulations and other program guidance will be identified and
    synthesized into a set of security requirements and objectives. Illustrate
    how these requirements and objectives will be used to measure the effectiveness
    of security system arrangements and how required policy revisions to government
    security programs will be processed.
    <p>
    10.1.6.2 <u>Threat Analysis.</u> Describe how the threat analysis will be
    evaluated and integrated along with adversary mission objectives.
    </p><p>
    10.1.6.3 <u>Conducting the Adversary Mission Analysis and Constructing the
    Preliminary Threat Logic Tree.</u> Describe the technical and analytical
    methods used to identify criteria for success in adversary mission objectives
    and to synthesize threat models. Delineate the system security technology
    research tasks and explain how this research will be documented.
    </p><p>
    10.1.6.4 <u>Applying Threat Rejection Logic and Documenting the Results.</u>
    Describe how qualitative and quantitative values will be established for
    threats and countermeasures and the method to document threat rejection logic.
  </p></blockquote>
</blockquote>
<p>
(Continued on Page 3)
</p><p>
Page <u>2 </u> of <u>3 </u> Pages
</p><p>
  </p><hr>
<p>
Block 10. Preparation Instructions (Continued)
</p><blockquote>
  <blockquote>
    10.1.6.5 <u>Synthesizing Countermeasures.</u> Describe the process by which
    countermeasures will be synthesized. Explain how this activity and the security
    system synthesis and evaluation tasks will be coordinated.
    <p>
    10.1.6.6 <u>Adversary Vulnerability Measurement.</u> Describe fully the method
    used to identify and conduct quantitative and qualitative analysis for risks
    associated with each adversary mission objective. Include the application
    of candidate countermeasures and the manner in which preferred countermeasures
    will be selected and documented.
    </p><p>
    10.1.6.7 <u>Computing and Constructing a Summary Threat Matrix.</u> Describe
    how the completed Threat logic Tree will be analyzed and system security
    effectiveness will be computed. Include the method used to document the results.
    </p><p>
    10.1.6.8 <u>Integrating Security Functions with the System Engineering
    Process.</u> Describe the process by which security inputs will be applied
    to system functional design, requirements allocation, trade-off study, and
    communications, electronic, and interface (CEI) design specification processes.
    </p><p>
    10.1.6.9 <u>Security System Synthesis and Evaluation.</u> Describe the method
    by which security system hardware, facilities, procedures, and personnel
    subsystems will be synthesized and evaluated. Specify the scope and type
    of research to be conducted of existing material. Include techniques to evaluate
    their applicability to security requirements.
    </p><p>
    10.1.6.10 <u>Test and Evaluation.</u> Describe the process use to identify
    security test requirements and proposed test methods.
    </p><p>
    10.1.6.11 <u>Configuration Control.</u> Describe the manner in which system
    security engineering efforts will be integrated with system configuration
    control activities. Explain how the proposed changes to the system will affect
    security efforts.
    </p><p>
    10.1.6.12 <u>Relationships with Other Contractors.</u> Outline the methods
    by which system security engineering efforts of associate system contractors,
    subcontractors, and vendors will be integrated within the System Security
    Engineering Program.
    </p><p>
    10.1.6.13 <u>System Installation and Checkout.</u> Describe how the System
    Security Engineering and Industrial and Product Security efforts will be
    coordinated to ensure no security vulnerability is created during system
    installation and checkout.
    </p><p>
    10.1.6.14 <u>Product Security.</u> Describe how the major system
    components/products will be secured at the contractor's assembly plants.
    Explain the security manpower, facilities, equipment, and procedures to be
    used. Include the security interface with associate contractors, subcontractors,
    and vendors.
  </p></blockquote>
</blockquote>
<p>
Page <u>3</u> of <u>3</u> Pages
</p><p>
  </p><hr>
<p>
<strong>Data Item Description </strong>
</p><p>
1. TITLE Preliminary System Security Concept
</p><p>
2. Identification Number DI-MISC-80840
</p><p>
3. Description/Purpose
</p><blockquote>
  3.1 This Data Item Description outlines the format and content of the PSSC.
  The PSSC is a document which cites security concepts and requirements relative
  to a particular system. It is prepared by the contractor to provide the
  Government with preliminary description of security requirements and resources.
</blockquote>
<p>
4. Approval Date 890605
</p><p>
5. OPR AF 10
</p><p>
6a. DTIC Applicable x
</p><p>
6b. GDEP Applicable
</p><p>
7. Application/Interrelationship
</p><blockquote>
  7.1 This Data Item Description contains the format and content preparation
  instructions for data resulting from the work task described by 5.3.1.3 of
  MIL-STD-1785.
  <p>
  7.2 Security Vulnerability Analysis, DID DI-MISC-80841, is used with this
  Data Item Description when paragraphs 10.1.5.1 through 10.1.5.5 are cited.
  </p><p>
  7.3 Defense Technical Information Center (DTIC), Cameron Station, Alexandria
  VA 22314-6100.
</p></blockquote>
<p>
8. Approval Limitation
</p><p>
9a. Applicable Forms
</p><p>
9b. AMSC Number F4371
</p><p>
10. Preparation Instructions (Continued on Page 2)
</p><p>
11. Distribution Statement DISTRIBUTION STATEMENT A: Approved for public
release; distribution is unlimited.
</p><p>
Page <u>1</u> of <u>5</u> Pages
</p><p>
  </p><hr>
<p>
Block 10. Preparation Instructions (Continued)
</p><blockquote>
  10.1 The Preliminary System Security Concept (PSSC) shall include the following:
  <blockquote>
    10.1.1 <u>Program Data.</u>
    <blockquote>
      10.1.1.1 <u>Title.</u> Include the complete PSSC title.
      <p>
      10.1.1.2 <u>Submitting Agency.</u> List the name and address of the contract
      agency submitting the report and the name and telephone number of a project
      officer or point of contact.
      </p><p>
      10.1.1.3 <u>Contract Citation.</u> Identify the contract number and date
      as listed by the government.
      </p><p>
      10.1.1.4 <u>Security Tasks.</u> Briefly describe major security tasks cited
      in the statement of work and related contract documents.
      </p><p>
      10.1.1.5 <u>Distribution.</u> List the names and addresses of Government
      and contract agencies receiving copies of this concept. If necessary, list
      them in an appendix and make reference to it here.
    </p></blockquote>
    <p>
    10.1.2 <u>System Concept.</u>
    </p><blockquote>
      10.1.2.1 <u>Description.</u> Briefly describe the system and its major
      components. Cite separate configurations for Initial Operational Capability
      (IOC) and Full Operational Capability (FOC), if different.
      <p>
      10.1.2.2 <u>Performance requirements.</u> Cite the major performance and
      deployment criteria in the applicable statements of work and other related
      contract documents which affect security.
      </p><p>
      10.1.2.3 <u>Reliability and maintainability.</u> Identify security issues
      affecting system reliability, logistics reliability, availability, and
      maintainability.
      </p><p>
      10.1.2.4 <u>System Survivability.</u> Show self-protection capabilities or
      subsystem designs which may enhance security. (examples include devices against
      tampering and spoofing, chemical or biological radiation hardness, nuclear
      hardness, nuclear or non-nuclear electromagnetic pulse hardness, and the
      use of passive detection technology.)
      </p><p>
      10.1.2.5 <u>Preplanned Product Improvements (P</u>3<u>I).</u> Describe provisions
      or security implications for subsystem growth or improvements such as
      modifications and upgrades.
    </p></blockquote>
    <p>
    10.1.3 <u>Security Subsystem Employment Data.</u>
    </p><blockquote>
      10.1.3.1 <u>General employment description.</u> Describe how, where, when,
      and what security subsystems will be used and how they will be integrated
      with the system(s) they support.
      <p>
      10.1.3.2 <u>Command and control structure.</u> Describe the command and control
      data that must be exchanged. Explain how security subsystems will it integrated
      into the command and control structure projected to exist when it is deployed.
    </p></blockquote>
  </blockquote>
</blockquote>
<p align="Left">
(Continued on Page 3)
</p><p>
Page <u>2 </u> of <u>5 </u> Pages
</p><p>
  </p><hr>
<p>
Block 10. Preparation Instructions (Continued)
</p><blockquote>
  <blockquote>
    <blockquote>
      10.1.3.3. <u>Information systems.</u> Identify the information that must
      be exchanged between this subsystem other systems, subsystems, or components.
      Cite the expected length of each communications link, anticipated flow rate
      across each link, required availability of each link, etc.
      <p>
      10.1.3.4 <u>Security subsystem standardization, interoperability, and
      commonalty.</u> Describe requirements for joint service interface, NATO
      cross-servicing and interoperability with existing systems and subsystems.
      Identify procedural and technical interface standards incorporated in subsystem
      design.
      </p><p>
      10.1.3.5 <u>Operational environment.</u> Describe climatic and atmospheric
      environmental effects and considerations. If applicable, define the chemical
      and biological environment in which equipment must function.
    </p></blockquote>
    <p>
    10.1.4 <u>Security Subsystem Support.</u>
    </p><blockquote>
      10.1.4.1 <u>Maintenance planning.</u> Outline the actions, support, and
      documentation necessary to establish maintenance concepts and requirements.
      Include maintenance tasks to be accomplished for on- and off-equipment
      maintenance; interservice, organic, and contractor mix, workloads, and time
      phasing for depot maintenance. Explain the management strategies for selecting
      and integrating contractor and government furnished equipment.
      <p>
      10.1.4.2 <u>Manpower and personnel.</u> Outline the projected manpower
      requirements envisioned to support this subsystem(s). Include type of specialty
      codes and skill levels required, time phased reporting, etc.
      </p><p>
      10.1.4.3 <u>Supply Support.</u> Show the proposed approach for provisioning
      initial support and acquiring, distributing, and replenishing inventory spares
      and repair parts.
      </p><p>
      10.1.4.4 <u>Support equipment.</u> Identify equipment required to support
      this subsystem(s). Include ground handling and maintenance equipment, tools,
      metrology and calibration equipment, and related computer hardware and software.
      </p><p>
      10.1.4.5 <u>Training and training devices.</u> Describe the training support
      concept from security subsystem design through deployment. Identify the command
      or agency responsible for developing and conducting each phase of training.
      Show inventory items and training devices by projected type, number, use,
      and locations required. Outline initial and recurring training requirements
      by location, type, specialty, and fiscal year.
      </p><p>
      10.1.4.6 <u>Computer resources support.</u> Define special computer program
      documentation, related software, source data, facilities, hardware, etc.
      required for subsystem support.
      </p><p>
      10.1.4.7 <u>Facilities.</u> Specify facility, shelter, and housing external
      to system-designed survivability features.
      </p><p>
      10.1.4.8 <u>Packaging, handling, storage, and transportation</u>. Describe
      the requirements, resources, processes, procedures, design considerations,
      and methods to ensure security subsystems are properly preserved, packaged,
      handled, and transported.
    </p></blockquote>
  </blockquote>
</blockquote>
<p align="Left">
(Continued on Page 4)
</p><p>
Page <u>3 </u> of <u>5 </u> Pages
</p><p>
  </p><hr>
<p>
Block 10. Preparation Instructions (Continued)
</p><blockquote>
  <blockquote>
    <blockquote>
      10.1.4.9 <u>Related support factors.</u> Describe the pertinent support factors,
      considerations, or requirements not covered elsewhere, but deemed important
      to the effectiveness of the security subsystem.
    </blockquote>
    <p>
    10.1.5 <u>General Provisions for System Security.</u> Address the following
    security issues relative to overall system deployment and operation.
    </p><blockquote>
      10.1.5.1 <u>Threat Assessment.</u> Address security threats to the system
      for design, development, production, at IOC, and throughout its projected
      life. Include foreign government capabilities, peaces and wartime ground
      threats, and system-unique vulnerabilities. Make reference to government
      threat documents. In addition, cite requirements for threat analysis and
      security vulnerability assessments.
      <p>
      10.1.5.2 <u>Procedural requirements.</u> Cite security force and procedural
      requirements which apply to pre-, trans-, and post-attack operation in support
      of the Air Force Physical Security Program.
      </p><p>
      10.1.5.3 <u>Security resources.</u> Cite security manpower, facility, and
      equipment requirements in the quantities, type and configuration necessary
      to support the system when deployed.
      </p><p>
      10.1.5.4 <u>Security response planning.</u> Address emergency security response
      planning, which reflects the general design of the security forces posture
      calculated to produce the greatest invulnerability to terrorism, sabotage,
      overt, and covert attack. It is supported by the threat and vulnerability
      assessments cited in 10.1.5.1. In addition, briefly describe how a security
      reporting and alerting system will be implemented.
      </p><p>
      10.1.5.5 <u>Security priorities for all applicable systems and components.</u>
      Include security priorities for all operational phases, including maintenance.
      For example, aircraft system priorities would include nuclear alert, nonnuclear
      alert, mission capable and non-alert. In addition, explain how waivers,
      exceptions, and variance to security criteria will be identified, submitted,
      approved, and corrected.
      </p><p>
      10.1.5.6 <u>Security requirements from related security disciplines.</u>
      Include applicable information security, physical security, computer security,
      personnel security, product security, industrial security, operations security,
      communications security, electronic security, survivability, antiterrorism,
      and counter-intelligence aspects.
    </p></blockquote>
  </blockquote>
</blockquote>
<p align="Left">
(Continued on Page 5)
</p><p>
Page <u>4 </u> of <u>5 </u> Pages
</p><p>
  </p><hr>
<p>
Block 10. Preparation Instructions (Continued)
</p><blockquote>
  <blockquote>
    <blockquote>
      10.1.5.7 <u>Facility and equipment requirements.</u> Facility and equipment
      requirements which are incorporated into the system to support system security
      requirements. These requirements include:
      <blockquote>
	a. The Central Security Control Facility, Master Surveillance and Control
	Facility, Security Force Response Facility, entry control facilities, etc.
	<p>
	b. Barrier systems and warning signs.
	</p><p>
	c. Alarm annunciation and display equipment.
	</p><p>
	d. Security force armament and duty equipment.
	</p><p>
	e. Security force communications. Include fixed, portable, and landline
	requirements by type and number.
	</p><p>
	f. Interior and exterior intrusion detection systems.
      </p></blockquote>
      <p>
      10.1.5.8 <u>Manpower standards.</u> Identify security force post and patrol
      requirements for normal operations.
      </p><p>
      10.1.5.9 <u>Security force logistics.</u> Cite security force logistics and
      materiel requirements including vehicles and associated equipment, training
      aids, tool kits, new armament, etc.
      </p><p>
      10.1.5.10 <u>Entry access controls.</u> Include system entry control requirements
      for all restricted areas including:
      </p><blockquote>
	a. General criteria and unique requirements for entry control. Include the
	rate at which individuals must be processed during normal operations, alert
	operations, and periods of advanced readiness.
	<p>
	b. Qualification requirements for the various categories of people who must
	enter.
	</p><p>
	c. Personnel clearance and investigative requirements.
	</p><p>
	d. Special training or briefing and debriefing requirements.
	</p><p>
	e. Authentication and duress code techniques and procedures.
	</p><p>
	f. Dispatch control procedures for unattended or minimally staffed sites.
	</p><p>
	g. Description of the badge system, emergency procedures, and personnel escort
	requirements, including the number of individual names maintained in the
	entry data files.
      </p></blockquote>
    </blockquote>
  </blockquote>
</blockquote>
<p>
</p><p>
Page <u>5 </u> of <u>5 </u> Pages
</p><p>
  </p><hr>
<p>
<strong>Data Item Description </strong>
</p><p>
1. TITLE Security Vulnerability Analysis
</p><p>
2. Identification Number DI-MISC-80841
</p><p>
3. Description/Purpose
</p><blockquote>
  3.1 The Security Vulnerability Analysis provides the result of the contractor's
  efforts to quantitatively and qualitatively define system security functional
  requirements and residual clandestine vulnerabilities. It will be classified
  no lower than SECRET NOFORN or SECRET Restricted Data, as applicable. This
  analysis contributes to the security vulnerability analysis.
</blockquote>
<p>
4. Approval Date 890605
</p><p>
5. OPR AF 10
</p><p>
6a. DTIC Applicable x
</p><p>
6b. GDEP Applicable
</p><p>
7. Application/Interrelationship
</p><blockquote>
  7.1 This Data Item Description contains the format and content preparation
  instructions for data resulting from the work task described in 5.3.1.9 of
  MIL-STD-1785.
  <p>
  7.2 This Data Item Description supersedes DI-R-3528/S-113-1.
  </p><p>
  7.3 This Data Item Description is used in conjunction with the System Security
  Management Plan (SSMP), DI-MISC-80839.
  </p><p>
  7.4 Defense Technical Information Center, Cameron Station, Alexandria VA
  22314-6100.
</p></blockquote>
<p>
8. Approval Limitation
</p><p>
9a. Applicable Forms
</p><p>
9b. AMSC Number F4371
</p><p>
10. Preparation Instructions
</p><blockquote>
  10.1 The Security Vulnerability Analysis shall include:
  <blockquote>
    a. A preface with narrative description of the system. Information concerning
    each form of external overt or covert method of attack against the system
    considered during system development.
    <p>
    b. Threat models in Threat Logic Tree format showing their transition from
    preliminary to initial Threat Logic Trees and thence into Summary Threat
    Logic Trees.
    </p><p>
    c. Rationale used for threat rejection in developing the initial Threat Logic
    Trees.
    </p><p>
    d. An evaluation of the conditional probabilities for achieving each adversary
    mission objective.
    </p><p>
    e. An assessment of security vulnerabilities related to information security,
    personnel security, industrial security, operations security, communications
    security, physical security, computer security, product security, and TEMPEST.
  </p></blockquote>
</blockquote>
<p>
11. Distribution Statement DISTRIBUTION STATEMENT A: Approved for public
release; distribution is unlimited.
</p><p>
Page <u>1</u> of <u>1</u> Pages
</p><p>
  </p><hr>
<p>
<strong>Data Item Description </strong>
</p><p>
1. TITLE System/Subsystem Specification (SS) Document for Automated Information
Systems (AIS)
</p><p>
2. Identification Number DI-IPSC-80690
</p><p>
3. Description/Purpose The SS provides a detailed definition of the
system/subsystem functions. It documents details of the on-going analysis
between the user's operational personnel and the appropriate development
personnel. It defines in detail the interfaces with other systems and subsystems
and the facilities to be utilized for accomplishing the interfaces.
</p><p>
4. Approval Date 881031
</p><p>
5. OPR SC 6a. DTIC Applicable
</p><p>
6b. GDEP Applicable
</p><p>
7. Application/Interrelationship
</p><blockquote>
  7.1 This DID contains the format and content preparation instructions for
  the data resulting from the work task described in 5.2 of DOD-STD-7935A.
  <p>
  7.2 This DID supersedes DI-S-30551B.
</p></blockquote>
<p>
8. Approval Limitation
</p><p>
9a. Applicable Forms
</p><p>
9b. AMSC Number A4551
</p><p>
10. Preparation Instructions
</p><blockquote>
  10.1 <u>Reference documents.</u> The applicable issue of the documents cited
  herein, including their approval dates and dates of any applicable amendments,
  notices, and revisions, shall be specified in the contract.
  <p>
  10.2 <u>Format.</u> This document shall be prepared on 8 1/2 by 11 inch white
  paper (hardcopy) or a form of electronic media. Margins of hardcopy shall
  be sufficiently large to permit looseleaf binding even if some other form
  of binding is specified in the contract for hardcopy items.
  </p><blockquote>
    10.2.1 <u>Tailoring instructions.</u> All paragraph and subparagraph numbers
    and titles identified in the standard shall be included in the document.
    In the event that a paragraph or subparagraph is tailored out, an indication
    to that effect should be added directly following the title.
  </blockquote>
</blockquote>
<p>
(Continued on Page 2)
</p><p>
11. Distribution Statement DISTRIBUTION STATEMENT A: Approved for public
release; distribution is unlimited.
</p><p>
Page <u>1</u> of <u>2</u> Pages
</p><p>
  </p><hr>
<p>
Block 10. Preparation Instructions (Continued)
</p><blockquote>
  <blockquote>
    10.2.2 <u>Use of alternate presentation styles.</u> When the information
    required by the paragraphs and subparagraphs of this DID can be made more
    readable by the use of charts, tables, matrices, and other presentation styles,
    the contractor is encouraged to incorporates such styles. Such presentation
    styles shall not incorporate continuous tone photographs, multiple color
    printing, oversize foldout sheets, or other techniques that cannot readily
    be reimaged from the original using office copiers or microforms.
    <p>
    10.2.3 <u>Multiple paragraphs and subparagraphs.</u> Any paragraph or
    subparagraph in this DID starting with the phrase "This paragraph shall"
    or "This subparagraph shall" may be written as multiple paragraphs or
    subparagraphs to enhance readability.
    </p><p>
    10.2.4 <u>Document reference numbers.</u> All pages of this document shall
    contain the document reference number near the top of the page. If the document
    is classified, the classification indicator shall not obscure the document
    reference number. Document reference numbers will be assigned by the government
    issuing organization. If the government does not specify the document reference
    number to be used, the contractor shall assign an identification code which
    is unique for each document (and for each part or volume of a document published
    in multiple parts) and which is unique among versions or revisions of the
    document to insure that unambiguous reference can be made to the proper version.
    </p><p>
    10.2.5 <u>Document structure.</u> The document shall contain the components
    discussed in the following paragraphs.
    </p><blockquote>
      10.2.5.1 <u>Title page.</u> This page shall contain the document control
      number centered at the top of the page. Also included shall be the name and
      any abbreviation or acronym of the system, name of the sponsoring or issuing
      organization, document type name, contract number, name of contractor, and
      publication date, as well as any necessary security markings or other
      restrictions on the handling of the document. If only a portion of the system
      is being documented, the name and any abbreviation or acronym of that portion
      of the system will also be included. If a front cover or a report documentation
      page is provided, information on the cover or report document must be consistent
      with that shown on this page. If a document is published in multiple parts
      or volumes, each part or volume shall have its own title page that shall
      include a subtitle describing the contents of the particular part or volume.
      <p>
      10.2.5.2 <u>Table of contents.</u> The document shall contain a table of
      contents listing the title and starting page number of all paragraphs and
      subparagraphs that have numbers and titles. The table of contents shall also
      list the numbers, titles, and staring page numbers of all figures, tables,
      and appendices.
    </p></blockquote>
  </blockquote>
  <p>
  10.3 <u>Content.</u> The content of the document shall conform with the
  requirements of 5.2 of DOD-STD-7935.
</p></blockquote>
<p>
Page <u>2</u> of <u>2</u> Pages
</p><p>
  </p><hr>
<p>
<strong>Data Item Description </strong>
</p><p>
1. TITLE Adversary Mission Analysis
</p><p>
2. Identification Number DI-MISC-80842
</p><p>
3. Description/Purpose
</p><blockquote>
  3.1 This Data Item Description is used by the contractor to quantitatively
  describe how potential adversaries may attack the system. It will be classified
  no lower than SECRET NOFORN or SECRET Restricted Data, as applicable.
</blockquote>
<p>
4. Approval Date 890605
</p><p>
5. OPR AF 10
</p><p>
6a. DTIC Applicable x
</p><p>
6b. GDEP Applicable
</p><p>
7. Application/Interrelationship
</p><blockquote>
  7.1 This Data Item Description contains the format and content preparation
  instructions for the data resulting from the work task described in 5.3.2.1
  of MIL-STD-1785.
  <p>
  7.2 Defense Technical Information Center (DTIC), Cameron Station, Alexandria
  VA 22314-6100.
</p></blockquote>
<p>
8. Approval Limitation
</p><p>
9a. Applicable Forms
</p><p>
9b. AMSC Number F4373
</p><p>
10. Preparation Instructions
</p><blockquote>
  10.1 The Adversary Mission Analysis shall include:
  <blockquote>
    a. Descriptions of the adversary mission scenarios developed. Information
    resulting from the threat analysis (conceptual phase) will be used as the
    basis for the scenarios.
    <p>
    b. Estimates of adversary success criteria developed. These estimates will
    be prerequisites for system vulnerabilities.
  </p></blockquote>
</blockquote>
<p>
11. Distribution Statement DISTRIBUTION STATEMENT A: Approved for public
release; distribution is unlimited.
</p><p>
Page <u>1</u> of <u>1</u> Pages
</p><p>
  </p><hr>
<p>
<strong>Data Item Description </strong>
</p><p>
1. TITLE Logistical Support Plan
</p><p>
2. Identification Number DI-S-1817
</p><p>
3. Description/Purpose
</p><blockquote>
  3.1 The Logistical Support Plan provides information and data to major field
  commanders for support of complex items or systems.
</blockquote>
<p>
4. Approval Date
</p><p>
5. OPR USAMC
</p><p>
6a. DTIC Applicable x
</p><p>
6b. GDEP Applicable
</p><p>
7. Application/Interrelationship
</p><blockquote>
  7.1 This Data Item Description contains the format and content preparation
  instructions for data resulting from the work task described by 5.3.1.6 of
  MIL-STD-1785.
  <p>
  7.2 This data item is related to DI-S-1813, Maintenance Support Plan, and
  DI-S-1819, Contractor Recommended Support Plan.
  </p><p>
  7.3 Defense Technical Information Center (DTIC), Cameron Station, Alexandria
  VA 22314-6100.
</p></blockquote>
<p>
8. Approval Limitation
</p><p>
9a. Applicable Forms
</p><p>
9b. AMSC Number
</p><p>
10. Preparation Instructions
</p><blockquote>
  10.1 The <u>Logistical Support Plan</u> shall include logistical planning
  data and information as specified in AR 750-6, Appendix III.
  <p>
  10.2 The requiring activity will provide the following input in preparation
  of the Logistical Support plan:
  </p><blockquote>
    a. Modification or expansion of the support plan outline as required to meet
    special requirements.
    <p>
    b. Data to be inserted in the support plan.
  </p></blockquote>
  <p>
  10.3 The Logistical Support Plan will summarize information contained in
  the Maintenance Support plan.
</p></blockquote>
<p>
11. Distribution Statement DISTRIBUTION STATEMENT A: Approved for public
release; distribution is unlimited.
</p><p>
Page <u>1</u> of <u>1</u> Pages
</p><p>
  </p><hr>
<p>
</p><h1 align="center">
  <strong><strong>Section <a name="III">III</a>:</strong><br wp="br2">
  Rainbow Readers' Digest</strong>
</h1>
<h2 align="center">
  <strong>III: Rainbow Readers' Digest</strong>
</h2>
<p>
The National Computer Security Center (NCSC) has produced a series of documents
dealing with various aspects of computer security development and operations.
Because the covers of these documents are color-coded, the documents have
come to be known as the
<a href="http://www.radium.ncsc.mil/tpep/library/rainbow/">Rainbow Series</a>.
This Section contains digests of each of the documents which have been published
so far. In addition, there are a few related documents digested which are
not Members of the Rainbow Series but are of the same genre. The documents
in this digest are as follows.
</p><blockquote>
  <b>DOD 5200.28-STD DoD Trusted Computer System Evaluation Criteria: </b>This
  is the keynote document of the series. It covers Fundamental Computer Security
  Requirements, Divisions and Classes of Systems, Testing Guidelines, Commercial
  Product Evaluation, and the Requirements by Class. (Also known as the Orange
  book.)
  <p>
  <b>CSC-STD-002-85 DoD Password Management Guideline: </b>Topics covered include
  Individual Password, Password Change, Password Protection, and Password Length.
  </p><p>
  <b>CSC-STD-003-85 Computer Security Requirements and CSC-STD-004-85 Rationale
  Behind Computer Security Requirements: </b>These two documents help you calculate
  the appropriate level of Computer Security Requirements for your system.
  The treatment given in each is slightly different, but the answers given
  are essentially the same. Topics covered include Minimum User Clearance (RMin
  ), Maximum Data Sensitivity (RMax ), Risk Index, and Computer Security
  Requirements Class.
  </p><p>
  <b>CSC-STD-005-85 DoD Magnetic Remanence Security Guideline:</b> (Superseded
  by NCSC-TG-025) The topics covered include Declassification and Clearing,
  Declassification Permission, Properly Functioning Media, Non-functional Media,
  and Destruction. This standard appears to have fallen on hard times as the
  media industry has made such great advances. The basic concepts involved
  are still valid.
  </p><p>
  <b>NCSC-TG-001 A Guide to Understanding Audit:</b> Topics covered include
  Audit Requirements Overview, Audited Events, and Selective Audit. (TG stands
  for Tech Guide.)
  </p><p>
  <b>NCSC-TG-002 Trusted Product Evaluations A Guide for Vendors:</b> This
  document acclimates the vendor to the evaluation procedures of the NCSC.
  Specific topics include phasing of the evaluation process, technical product
  description, and the legal agreement between NSA and the vendor.
  </p><p>
  <b>NCSC-TG-003 A Guide to Understanding Discretionary Access Control:</b>
  This document covers the ticklish topic of DAC. Specific sub-topics include
  Implementation Methodologies, Control Permission and Access Modes, and
  Requirements.
  </p><p>
  <b>NCSC-TG-004 Glossary of Computer Security Terms</b>
  </p><p>
  <b>NCSC-TG-005 Trusted Network Interpretation:</b> This document takes a
  look at the Orange Book (which was written in terms of a monolithic computer)
  and "Interprets" the requirements for the network type environment. Topics
  include Security Policy, New Evaluation Areas, Network Components, and Cascading
  </p><p>
  <b>NCSC-TG-006 A Guide to Understanding Configuration Management:</b> In
  this day and age of viruses and worms there is an even greater need for CM
  than before. The actual CM requirements are not much different than those
  of the typical DoD development. The primary emphasis of this guide was for
  the commercial vendor whose CM practices are often non-existent. Topics include
  Configuration Management (CM) Use, CM Requirements, and CM Tasks.
  </p><p>
  <b>NCSC-TG-007 A Guide to Understanding Design Documentation:</b> This document
  covers the design documentation requirements for each of the classes from
  C1 through A1.
  </p><p>
  <b>NCSC-TG-008 A Guide to Understanding Trusted Distribution:</b> CM covers
  the protection of the system when in the hands of the developers and the
  users. This document covers the protection of the system between them. Topics
  include Trusted Distribution (TD) Assurances, Post-Production Protection,
  and Transit Protection.
  </p><p>
  <b>NCSC-TG-009 Computer Security Subsystem Interpretation:</b> This
  interpretation is for the add-on systems which lend security to a basically
  insecure system. Topics include Required Features, Assurance Requirements,
  and Documentation Requirements.
  </p><p>
  <b>NCSC-TG-011 Trusted Network Interpretation Environments Guideline:</b>
  It is the first of a series of off-shoots of NCSC-TG-005. Topics include
  Network Security Architecture and Design (NSAD), Risk Assessment, and Network
  Security Services.
  </p><p>
  <b>NCSC-TG-013 Rating Maintenance Phase Program (RAMP) Document:</b> The
  current setup for evaluation lists a particular hardware configuration with
  a particular operating system as a particular class. RAMP seeks to extend
  the evaluation listing to future versions of the system. Topics include
  Preevaluation Phase, Vendor Assistance Phase/Design Analysis Phase, Evaluation
  Phase, and Rating Maintenance Phase.
  </p><p>
  <b>NCSC-TG-014 Guidelines for Formal Verification Systems:</b> Topics include
  Endorsement And ETL Listing, Technical factors, Features, Assurance, and
  Required Documentation. Of little interest for most systems.
  </p><p>
  <b>NCSC-TG-015 A Guide to Understanding Trusted Facility Management:</b>
  This is a good background document for gaining an understanding of the basic
  concept for setting up a system. Roles discussed include Security Administrator,
  Secure Operator, Account Administrator, and Auditor.
  </p><p>
  <b>NCSC-TG-017 A Guide to Understanding Identification and Authentication
  in Trusted Systems:</b> This document covers the requirements for I&amp;A
  by class and discusses methods and implementations to meet the requirements.
  </p><p>
  <b>NCSC-TG-019 Trusted Product Evaluation Questionnaire:</b> This document
  serves as a good guide to help the developer ensure that all of the "bases
  are covered". The questionnaire covers the entire gamut of CompuSec issues
  for a system.
  </p><p>
  <b>NCSC-TG-020 Access Control List (ACL) Features for UNIX:</b> The requirement
  to be able to list users with access or not for an object tends to point
  toward ACLs for the DAC implementation. This Guide was written specifically
  for UNIX system developers implementing ACLs, but the though processes and
  rationales involved are of wider validity.
  </p><p>
  <b>NCSC-TG-021 Trusted Database Management System Interpretation of the Trusted
  Computer System Evaluation Criteria:</b> This document covers a broad range
  of topics which have some relation to trusted databases. The total effect
  is close to being a rewrite of the Orange Book while not officially attempting
  to do so.
  </p><p>
  <b>NCSC-TG-025 A Guide to Understanding Data Remanence in Automated Information
  Systems:</b> This document explores each method of clearing and/or purging
  data from media and lists DoD approved methods for each major media type.
  </p><p>
  <b>NCSC-TG-026 A Guide to Writing the Security Features User's Guide for
  Trusted Systems:</b> This document covers presentation, packaging, and content
  for the SFUG and gives two outline examples of acceptable SFUG styles.
  </p><p>
  <b>C Technical Report 79-91 Integrity in Automated Information Systems:</b>
  This document addresses the "other half" of COMPUSEC. Along with removing
  the chance for compromise of sensitive data we must also protect the data
  from damage. This is not a full member of the Rainbow Series but instead
  is a Tech Report from the NCSC. Integrity itself plus integrity models,
  implementations, and principles are discussed.
  </p><p>
  <b>NTISSAM COMPUSEC/1-87 Advisory Memorandum on Office Automation Security:</b>
  This document covers User Responsibilities and Security Officer Responsibilities
  in the office PC-type environment.
  </p><p>
  <b>MIL-STD 1785 System Security Engineering Program Management:</b> This
  MIL-STD covers the entirety of security engineering and is helpful for the
  phasing aspects and the associated DIDs. The Phases covered include Concept
  Exploration, Demonstration and Validation, Full-Scale Development, Production
  and Deployment.
  </p><p>
  <b>DRS-2600-5502-86 System High and Compartmented Mode Workstations:</b>
  This is a DIA document from their secure workstation contract. It takes a
  few turns not taken by NCSC. It contains separate sections for the System
  High Requirements and the Compartmented Mode Requirements.
</p></blockquote>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> DOD 5200.28-STD (Formerly: CSC-STD-001-83)
</p><p>
<strong>Title:</strong> DoD Trusted Computer System Evaluation Criteria
</p><p>
<strong>Color:</strong> Orange Book
</p><p>
<strong>Date:</strong> December 1985
</p><p>
<strong>Highlights:</strong> "The provisions of this document apply to DoD
components. This document is mandatory for 'all DoD components in activities
applicable to the processing and storage of classified information'."
</p><p>
1. Fundamental Computer Security Requirements
</p><blockquote>
  a. Policy
  <blockquote>
    1) Security Policy: There must be an explicit and well-defined security policy
    enforced by the system.
    <blockquote>
      a) Mandatory Security Control Objective: The security policy must include
      provisions for enforcing mandatory access control rules based on the
      classification of the information and the user's clearance.
      <p>
      b) Discretionary Security Control Objective: The security policy must include
      provisions for the enforcement of discretionary access control rules based
      on the user's need-to-know for the information.
    </p></blockquote>
    <p>
    2) Marking: Access control labels must be associated with objects.
    </p><blockquote>
      c) Marking Control Objective: The system must store and preserve the integrity
      of labels for all information. Labels exported from the system must be an
      accurate representation of the internal labels being exported.
    </blockquote>
  </blockquote>
  <p>
  b. Accountability
  </p><blockquote>
    d) Accountability Control Objective: The system must ensure individual
    accountability with data usable by a competent agent in a reasonable time
    without undue difficulty.
    <blockquote>
      3) Identification: Individual subjects must be identified.
      <p>
      4) Accountability: Audit information must be selectively kept and protected
      so that actions affecting security can be traced to the responsible party.
    </p></blockquote>
  </blockquote>
  <p>
  c. Assurance
  </p><blockquote>
    e) Assurance Control Objective: The system must accurately implement the
    policy, without distorting the policy's intent, throughout the system's life.
    <blockquote>
      5) Assurance: The computer system must contain hardware/software mechanisms
      that can be independently evaluated to provide sufficient assurance that
      the system enforces requirements 1 through 4 above.
      <p>
      6) Continuous Protection: The trusted mechanisms that enforce these basic
      requirements must be continuously protected against tampering and/or unauthorized
      changes.
    </p></blockquote>
  </blockquote>
</blockquote>
<p>
2. Divisions and Classes of Systems
</p><blockquote>
  a. Division D: Minimal Protection - Reserved for those systems which have
  been evaluated but that fail to meet the requirements of a higher evaluation
  class.
  <p>
  b. Division C: Discretionary Protection - Provide for discretionary
  (need-to-know) protection and for accountability of subjects and the actions
  they initiate.
  </p><blockquote>
    1) Class C1: Discretionary Security Protection - Incorporate discretionary
    access controls capable of enforcing access limitations on an individual
    basis.
    <p>
    2) Class C2: Controlled Access Protection - More finely grained discretionary
    access control with individual user accountability through login, audit,
    and isolation.
  </p></blockquote>
  <p>
  c. Division B: Mandatory Protection - Enforce mandatory access control rules,
  carry sensitivity labels with major data structures, implement the reference
  monitor concept, and have a Trusted Computing Base (TCB) which implements
  the security policy model.
  </p><blockquote>
    1) Class B1: Labelled Security Protection - In addition to C2 features, provide
    informal model, data labeling, mandatory access control, accurate export
    labeling.
    <p>
    2) Class B2: Structured Protection - Provide formal security policy model
    that requires access controls for all subjects and all objects, address covert
    channels, structured into critical and non-critical elements, provide for
    trusted facility management and configuration management.
    </p><p>
    3) Class B3: Security Domains - Mediate all accesses of subjects to objects,
    have tamperproof TCB which is small enough for analysis and test, provide
    security administrator support, signal security relevant events, securely
    recover the system.
  </p></blockquote>
  <p>
  d. Division A: Verified Protection - Use formal security verification methods
  to assure that the mandatory and discretionary access controls can effectively
  protect the information stored and/or processed. Extensive documentation
  is required to demonstrate the meeting of security requirements in design,
  development, and implementation.
  </p><blockquote>
    1) Class A1: Verified Design - {No additional features (over B3).} The system
    has formal design specification, formal verification techniques, formal model
    of the security policy, Formal Top Level Specification, more stringent
    configuration management, and secure distribution of the system to sites.
  </blockquote>
</blockquote>
<p>
3. Testing Guidelines
</p><blockquote>
  a. Division C Personnel:
  <blockquote>
    1) Two members with BSCS or equivalent.
    <p>
    2) Able to follow developer test plans and suggest additions.
    </p><p>
    3) Have knowledge of system and completed developers internals course.
  </p></blockquote>
  <p>
  b. Division C Testing:
  </p><blockquote>
    1) Independently run the developers test suite.
    <p>
    2) Independently design at least five system-specific tests.
    </p><p>
    3) At least one month and not exceeding three months.
    </p><p>
    4) No fewer than twenty hands-on hours for testing.
  </p></blockquote>
  <p>
  c. Division B Personnel:
  </p><blockquote>
    1) Two members with BSCS or equivalent and at least one MSCS.
    <p>
    2) Able to follow developer test plans and suggest additions.
    </p><p>
    3) Be fluent in the TCB implementation language(s).
    </p><p>
    4) Have knowledge of system and completed developers internals course.
    </p><p>
    5) One member has previously completed a security test on a system.
  </p></blockquote>
  <p>
  d. Division B Testing:
  </p><blockquote>
    1) Independently run the developers test suite.
    <p>
    2) Independently design at least fifteen system-specific tests.
    </p><p>
    3) At least two month and not exceeding four months.
    </p><p>
    4) No fewer than thirty hands-on hours for testing per team member.
  </p></blockquote>
  <p>
  e. Division A Personnel:
  </p><blockquote>
    1) One member with BSCS or equivalent and at least two MSCSs.
    <p>
    2) Able to follow developer test plans and suggest additions.
    </p><p>
    3) Be fluent in the TCB implementation language(s).
    </p><p>
    4) Have knowledge of system and completed developers internals course.
    </p><p>
    5) One member understand the hardware diagnostics and documentation.
    </p><p>
    6) Two members have previously completed a security test on a system.
    </p><p>
    7) One member has system programming competence for the system.
  </p></blockquote>
  <p>
  f. Division A Testing:
  </p><blockquote>
    1) Independently run the developers test suite.
    <p>
    2) Independently design at least twenty-five system-specific tests.
    </p><p>
    3) At least three month and not exceeding six months.
    </p><p>
    4) No fewer than fifty hands-on hours for testing per team member.
  </p></blockquote>
</blockquote>
<p>
4. Covert Channels:
</p><blockquote>
  a. Any communications channel that can transfer information in violation
  of the system security policy.
  <p>
  b. Covert storage channels include all methods that allow direct or indirect
  writing of a location by one process and direct or indirect reading of the
  location by another process.
  </p><p>
  c. Covert timing channels allow one process to signal another process by
  modulating its use of system resources.
  </p><p>
  d. Covert Channel Bandwidth:
  </p><blockquote>
    1) 100 bits per sec (bps) is unacceptably high.
    <p>
    2) ~1 bps is acceptable.
    </p><p>
    3) ~0.1 bps should be audited.
  </p></blockquote>
</blockquote>
<p>
5. MAC Features: To support transportability and commonalty it is recommended
that:
</p><blockquote>
  a. Sixteen (16) or more hierarchical classifications be supported.
  <p>
  b. Sixty-four (64) or more non-hierarchical classifications be supported.
</p></blockquote>
<p>
6. Commercial Product Evaluation:
</p><blockquote>
  a. This evaluation process is keyed to Commercial Off The Shelf (COTS) systems.
  It serves as an input to computer system security approval/accreditation.
  A complete approval/accreditation study considers:
  <blockquote>
    1) Mode of Operation.
    <p>
    2) Specific users.
    </p><p>
    3) Applications.
    </p><p>
    4) Data sensitivity.
    </p><p>
    5) Physical security.
    </p><p>
    6) Personnel security.
    </p><p>
    7) Administrative security.
    </p><p>
    8) Procedural security.
    </p><p>
    9) TEMPEST.
    </p><p>
    10) Communications security.
  </p></blockquote>
  <p>
  b. The NCSC evaluation has three distinct elements:
  </p><blockquote>
    1) Preliminary Product Evaluation - Informal dialogue to gain common
    understanding of vendor's target evaluation class and NCSC expectations for
    the class.
    <p>
    2) Formal Product Evaluation - A formal evaluation by NCSC with the result
    being the product and its rating being placed on the Evaluated Product List.
    </p><p>
    3) Evaluated Product List (EPL) - A list of products that have been formally
    evaluated and their assigned ratings.
  </p></blockquote>
</blockquote>
<p>
7. Requirements
</p><blockquote>
  a. Audit
  <blockquote>
    C2: TCB must protect, perform, and maintain an audit trail with the system
    administrator able to selectively audit by UserID.
    <p>
    B1: Audit must include security level, actions upon the security level, and
    bannering overrides and allow for selective audit by security level.
    </p><p>
    B2: Audit must include covert channels.
    </p><p>
    B3: Audit must include threshold values for imminent security violations
    and alert the security administrator when the thresholds are passed.
  </p></blockquote>
  <p>
  b. Configuration Management
  </p><blockquote>
    B2: Use configuration management on all design and implementation documentation,
    code, and test fixtures during development and maintenance.
    <p>
    A1: Use configuration management on all documentation, code, security-relevant
    hardware, and test fixtures during the entire lifecycle. Provide for trusted
    distribution.
  </p></blockquote>
  <p>
  c. Covert Channel Analysis
  </p><blockquote>
    B2: Search for covert storage channels and determine maximum bandwidth of
    each.
    <p>
    B3: Search for covert channels and determine maximum bandwidth of each.
    </p><p>
    A1: Formal methods must be used for covert channel analysis.
  </p></blockquote>
  <p>
  d. Design Documentation
  </p><blockquote>
    C1: Documentation must discuss the philosophy of protection and its translation
    into the TCB along with the interfaces between TCB modules.
    <p>
    B1: Documentation must include an informal/formal security policy model and
    identify the specific mechanisms which implement the model.
    </p><p>
    B2: Documentation must include a formal security policy model proven to satisfy
    the policy, a Descriptive Top-Level Specification (DTLS) which describes
    the TCB interfaces, discussions of the TCB structure, and data on the covert
    channel analysis including indicative auditable events.
    </p><p>
    B3: Documentation must show that the TCB implementation is consistent with
    the DTLS.
    </p><p>
    A1: Documentation must show that the TCB implementation is consistent with
    the Formal Top-Level Specification (FTLS). Mechanisms not dealt with by the
    FTLS must be fully described.
  </p></blockquote>
  <p>
  e. Design Specification And Verification
  </p><blockquote>
    B1: Internally consistent formal/informal security policy model.
    <p>
    B2: Proven internally consistent formal security policy model and a DTLS.
    </p><p>
    B3: Convincing argument that the DTLS and model agree.
    </p><p>
    A1: FTLS (shown to be an accurate description of all interfaces) and a
    combination of formal and informal techniques to show that the FTLS and the
    model agree.
  </p></blockquote>
  <p>
  f. Device Labels
  </p><blockquote>
    B2: All attached physical devices must be assigned minimum and maximum security
    levels and these labels must be used to enforce constraints imposed upon
    the devices.
  </blockquote>
  <p>
  g. Discretionary Access Control
  </p><blockquote>
    C1: Access control must be in place between named users and named objects
    with sharing by defined groups and/or individual users.
    <p>
    C2: Access control must be in place between named users and named objects
    with sharing by defined groups of individuals and/or individual users.
    Propagation of access rights must be controlled.
    </p><p>
    B3: For each named object, there must be a method for specifying a list of
    named individuals and their modes of access including NULL access.
  </p></blockquote>
  <p>
  h. Exportation of Labelled Information
  </p><blockquote>
    B1: Each communications channel and I/O device must be designated either
    single level or multilevel. Any change to the designation or the security
    level must be audited.
  </blockquote>
  <p>
  i. Exportation to Multilevel Devices
  </p><blockquote>
    B1: Objects exported over a multilevel port must have the sensitivity label
    exported in the same form as the object. All objects imported or exported
    over a multilevel port must allow for unambiguous pairing between the object
    and its sensitivity label.
  </blockquote>
  <p>
  j. Exportation to Single Level Devices
  </p><blockquote>
    B1: Single level ports must have a mechanism to set the single security level
    at which they operate.
  </blockquote>
  <p>
  k. Identification and Authentication
  </p><blockquote>
    C1: Login with password is required along with protection of the authentication
    data.
    <p>
    C2: Login with password and unique UserID is required.
    </p><p>
    B1: Authentication data must include clearance and authorization data for
    the user.
  </p></blockquote>
  <p>
  l. Label Integrity
  </p><blockquote>
    B1: Sensitivity labels must accurately represent the security levels of the
    associated subjects and objects in the system and when exported.
  </blockquote>
  <p>
  m. Labeling Human Readable Output
  </p><blockquote>
    B1: Administrator must be able to specify the printable label names which
    must be printed top and bottom of all output. Labeling changes and overrides
    must be audited.
  </blockquote>
  <p>
  n. Labels
  </p><blockquote>
    B1: TCB must maintain labels for each subject and object and use them for
    MAC decisions. Unlabeled imported data requires human intervention for labeling.
    <p>
    B2: TCB must maintain labels for each system resource accessible by subjects
    external to the TCB.
  </p></blockquote>
  <p>
  o. Mandatory Access Control
  </p><blockquote>
    B1: TCB must enforce MAC over all subjects and objects under its control.
    <p>
    B2: TCB must enforce MAC over each system resource accessible by subjects
    external to the TCB.
  </p></blockquote>
  <p>
  p. Object Reuse
  </p><blockquote>
    C2: No information from the previous subject can be available in a storage
    object allocated to the next subject.
  </blockquote>
  <p>
  q. Security Features User's Guide
  </p><blockquote>
    C1: A single source must be made available to describe the protection mechanisms
    of the TCB, their use, and interactions.
  </blockquote>
  <p>
  r. Security Testing
  </p><blockquote>
    C1: System must work as claimed and have no obvious way to bypass security.
    <p>
    C2: Search for obvious flaws which would allow violation of resource isolation
    or access to audit and authentication data.
    </p><p>
    B1: Testing must include design documentation, source code, and object code.
    All flaws must be removed or neutralized and the system retested.
    </p><p>
    B2: All flaws must be corrected and the system retested. The system must
    be relatively resistant to penetration and must be consistent with the DTLS.
    </p><p>
    B3: There must be no design flaws and few implementation flaws. The system
    must be resistant to penetration.
    </p><p>
    A1: TCB implementation must be consistent with the FTLS.
  </p></blockquote>
  <p>
  s. Subject Sensitivity Labels
  </p><blockquote>
    B2: TCB must notify a user of changes to his security level during a session
    or on request.
  </blockquote>
  <p>
  t. System Architecture
  </p><blockquote>
    C1: TCB must protect itself from interference and tampering.
    <p>
    C2: Resource isolation must be used for access control and auditing.
    </p><p>
    B1: Process isolation must be provided through separate address spaces.
    </p><p>
    B2: TCB must be modular and use least privilege principle with clearly defines
    user interfaces and all portions of the TCB identified.
    </p><p>
    B3: TCB must be built around a simple protection mechanism and use sound
    engineering principles in its implementation. Keep It Simple Stupid (KISS).
  </p></blockquote>
  <p>
  u. System Integrity
  </p><blockquote>
    C1: Features must be provided to revalidate correct operation of the TCB.
  </blockquote>
  <p>
  v. Test Documentation
  </p><blockquote>
    C1: Developer must provide test plan, procedures, and report.
    <p>
    B2: Documentation must include effectiveness testing of the covert channel
    bandwidth reduction measures.
    </p><p>
    A1: Documentation must include the results of the FTLS to Source Code mapping.
  </p></blockquote>
  <p>
  w. Trusted Distribution
  </p><blockquote>
    A1: There must be a trusted control and distribution facility with procedures
    for trusted distribution.
  </blockquote>
  <p>
  x. Trusted Facility Management
  </p><blockquote>
    B2: TCB must support separate operator and administrator functions.
    <p>
    B3: The security administrator must take auditable actions to "Put On" his
    security administrator hat.
  </p></blockquote>
  <p>
  y. Trusted Facility Manual
  </p><blockquote>
    C1: TFM shall cover cautions regarding privileges and functions that should
    be controlled.
    <p>
    C2: TFM shall cover procedures for using the audit trail, including record
    structure for event types.
    </p><p>
    B1: TFM shall cover operator and administrator functions and the interactions
    within the TCB.
    </p><p>
    B2: TFM shall cover reference validation mechanisms with their locations
    and the procedures for generating a new TCB from source code.
    </p><p>
    B3: TFM shall cover starting/resuming operations in a secure state.
  </p></blockquote>
  <p>
  z. Trusted Path
  </p><blockquote>
    B2: Must be a trusted communication path between the TCB and the user for
    initial login and authentication initiated by the user.
    <p>
    B3: Must be a trusted communication path between the TCB and the user for
    positive TCB-to-user connection activated by the user and distinct from other
    paths.
  </p></blockquote>
  <p>
  aa. Trusted Recovery
  </p><blockquote>
    B3: Provisions for system recovery without compromise must be provided.
  </blockquote>
</blockquote>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> CSC-STD-002-85
</p><p>
<strong>Title:</strong> DoD Password Management Guideline
</p><p>
<strong>Color: </strong>Green<strong></strong>
</p><p>
<strong>Date:</strong> 12 APR 85
</p><p>
<strong>Highlights</strong>
</p><p>
1. Passwords must be used in conjunction with the UserID for Authenticated
Personal Identification for use in access control and auditing.
</p><p>
2. GroupIDs are not allowed for authentication purposes (login).
</p><p>
3. Passwords should be computer generated.
</p><p>
4. Initial passwords should be dispersed without exposure to the ISSO or
as "expired passwords." (Select from computer real-time-generated list, sealed
carbon paper envelopes, etc.)
</p><p>
5. User password change should include entering old password to authenticate
the User.
</p><p>
6. SSO must be able to change anyone's password.
</p><p>
7. Passwords should be classified at the level of exposure allowed by release
of the password.
</p><p>
8. Access across networks should be authenticated by 1) Trusted Identification
Forwarding by the "Home" host or 2) UserID and Password to the remote host.
</p><p>
9. Passwords should be encrypted or DACed or both.
</p><p>
10. Encryption should include the UserID with the password.
</p><p>
11. Password guess rate should be limited to approximately one per minute
after a failure on an access port and/or UserID basis.
</p><p>
12. Failed passwords should have an adjustable alert level to the SSO (about
5).
</p><p>
13. On successful login the User should be told date and time of last login,
location of last login, and number of unsuccessful attempts since last login.
</p><p>
14. Password length should be at least:
</p><blockquote>
  <u>Log( Password Life x Available Try Rate / Probability of Guess During
  Lifetime)</u>
  <p>
  Log( "Alphabet" Size)
  </p><blockquote>
    a. Probability of Guess should be .000001 or lower. More restrictive values
    should be selected for more restrictive environments.
    <p>
    b. Typical Alphabet sizes
    </p><blockquote>
      1) English letters = 26
      <p>
      2) English letters and numbers = 36
      </p><p>
      3) English 4, 5, and 6 letter words = 23300
    </p></blockquote>
  </blockquote>
</blockquote>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> CSC-STD-003-85
</p><p>
<strong>Title:</strong> Computer Security Requirements
</p><p>
<strong>Color:</strong> Yellow I
</p><p>
<strong>Date:</strong> 25 JUN 85
</p><p>
<strong>Highlights</strong>
</p><p>
1. Minimum User Clearance Rating (R<sub>Min </sub>)
</p><pre> <b> Minimum User Clearance Rating                               (R<sub>Min</sub> )</b>
<b>  ___________________________________________________________________</b>

<b>  Uncleared (U)                                                 0</b>
<b>  Authorized Sensitive but Unclassified Information (N)         1</b>
<b>  Confidential (C)                                              2</b>
<b>  Secret (S)                                                    3</b>
<b>  Top Secret/Current Background Investigation (TS BI)           4</b>
<b>  Top Secret/Current Special Background Investigation (TS SBI)  5</b>
<b>  One Category (1C)                                             6</b>
<b>  Multiple Categories (MC)                                      7</b>
<b>  ___________________________________________________________________</b>


</pre>
<p>
2. Maximum Data Sensitivity Rating (R<sub>Max</sub> )
</p><pre>  <b>Maximum Data Sensitivity Rating                             (R<sub>Max</sub> )</b>
<b>  ___________________________________________________________________</b>

<b>  U                                                             0</b>
<b>  N                                                             1</b>
<b>  N with one or more categories                                 2</b>
<b>  C                                                             2</b>
<b>  C with one or more categories                                 3</b>
<b>  S                                                             3</b>
<b>  S with one or more categories                                 4</b>
<b>  S with two or more categories containing Secret data          5</b>
<b>  TS                                                            5</b>
<b>  TS with one or more categories                                6</b>
<b>  TS with two or more categories containing S or TS data        7</b>
<b>  ___________________________________________________________________</b>

  <b>** A category is only to be counted if a user does not have access</b>
<b>     to the category **</b>


</pre>
<p>
3. The Risk Index is computed by one of the following algorithms:
</p><blockquote>
  a. If RMin &lt; RMax then Risk Index = RMax<strong> </strong>- RMin
  <p align="center">
  ** If RMin = (TS BI) and RMax = TS without categories then use algorithm
  b. **
  </p><p>
  b. If RMin &gt;= RMax then
  </p><blockquote>
    If there are categories on the system to which any user is not authorized
    access then
    <p>
    Risk Index = 1
    </p><p>
    Else
    </p><p>
    Risk Index = 0
  </p></blockquote>
</blockquote>
<p>
4. Computer Security Requirements
</p><pre><b><u>Risk Index</u>  <u>Security Operating Mode</u>  <u>Open Environments</u>  <u>Closed Environments</u></b>
<b>___________________________________________________________________________</b>

<b>0		Dedicated		C1 or less		C1 or less</b>
<b>0		System High		C2			C2</b>
<b>1		Limited Access		B1			B1</b>
<b>		Controlled</b>
<b>		Compartmented</b>
<b>		Multilevel</b>
<b>2		Limited Access		B2			B2</b>
<b>		Controlled</b>
<b>		Compartmented</b>
<b>		Multilevel</b>
<b>3		Controlled		B3			B2</b>
<b>		Multilevel</b>
<b>4		Multilevel		A1			B3</b>
<b>5		Multilevel		*			A1</b>
<b>6		Multilevel		*			*</b>
<b>7		Multilevel		*			*</b>
<b>___________________________________________________________________________</b>


</pre>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> CSC-STD-004-85
</p><p>
<strong>Title:</strong> Rationale Behind Computer Security Requirements
</p><p>
<strong>Color:</strong> Yellow II
</p><p>
<strong>Date:</strong> 25 JUN 85
</p><p>
<strong>Highlights</strong>
</p><p>
1. Minimum User Clearance Rating (R<sub>Min</sub> )
</p><pre>  <b>Minimum User Clearance Rating                                (R<sub>Min</sub> )</b>
<b>  ___________________________________________________________________</b>

<b>  Uncleared (U)                                                  0</b>
<b>  Authorized Sensitive but Unclassified Information (N)          1</b>
<b>  Confidential (C)                                               2</b>
<b>  Secret (S)                                                     3</b>
<b>  Top Secret/Current Background Investigation (TS BI)            4</b>
<b>  Top Secret/Current Special Background Investigation (TS SBI)   5</b>
<b>  One Category (1C)                                              6</b>
<b>  Multiple Categories (MC)                                       7</b>
<b>  ___________________________________________________________________</b>


</pre>
<p>
2. Maximum Data Sensitivity Rating (R<sub>Max </sub>)
</p><pre>  <b>Maximum Data Sensitivity Rating                              (R<sub>Max</sub> )</b>
<b>  ___________________________________________________________________</b>

<b>  U                                                              0</b>
<b>  N                                                              1</b>
<b>  N with one or more categories                                  2</b>
<b>  C                                                              2</b>
<b>  C with one or more categories                                  3</b>
<b>  S                                                              3</b>
<b>  S with one or more categories                                  4</b>
<b>  S with two or more categories containing Secret data           5</b>
<b>  TS                                                             5</b>
<b>  TS with one or more categories                                 6</b>
<b>  TS with two or more categories containing S or TS data         7</b>
<b>  ___________________________________________________________________</b>

<b>  ** A category is only to be counted if a user does not have access to the</b>
<b>     category **</b>

</pre>
<p>
3. The Risk Index is computed by one of the following algorithms:
</p><blockquote>
  a. If RMin &lt; RMax then Risk Index = RMax<strong> </strong>-<strong>
  </strong>RMin
  <p align="center">
  ** If RMin = (TS BI) and RMax = TS without categories then use algorithm
  b. **
  </p><p>
  b. If RMin &gt;= RMax then
  </p><blockquote>
    If there are categories on the system to which any user is not authorized
    access then
    <p>
    Risk Index = 1
    </p><p>
    Else Risk Index = 0
  </p></blockquote>
</blockquote>
<p>
4. Computer Security Requirements
</p><pre><b><u>Risk Index</u>  <u>Security Operating Mode</u>  <u>Open Environments</u>  <u>Closed Environments</u></b>
<b>___________________________________________________________________________</b>

<b>  0        	Dedicated                   C1 or less        	C1 or less</b>
<b>  0        	System High                 C2                	C2</b>
<b>  1        	Compartmented,Multilevel    B1                	B1</b>
<b>  2        	Compartmented,Multilevel    B2                	B2</b>
<b>  3        	Multilevel                  B3                	B2</b>
<b>  4        	Multilevel                  A1                	B3</b>
<b>  5        	Multilevel                  *                 	A1</b>
<b>  6        	Multilevel                  *                 	*</b>
<b>  7        	Multilevel                  *                 	*</b>
<b>___________________________________________________________________________</b>


</pre>
<p>
5. Security Risk Index Matrix
</p><pre><b>                               Maximum Data Sensitivity</b>
<b>  ___________________________________________________________</b>

<b>                             U    N    C    S    TS   1C   MC</b>
<b>  ___________________________________________________________</b>

<b>  Minimum            U       0    1    2    3    5    6    7</b>
<b>  Clearance          N       0    0    1    2    4    5    6</b>
<b>  Or                 C       0    0    0    1    3    4    5</b>
<b>  Authorization      S       0    0    0    0    2    3    4</b>
<b>  of                 TS(BI)  0    0    0    0    0    2    3</b>
<b>  System             TS(SBI) 0    0    0    0    0    1    2</b>
<b>  Users              1C      0    0    0    0    0    0    1</b>
<b>                     MC      0    0    0    0    0    0    0 </b>
<b>  ___________________________________________________________</b>


</pre>
<p>
6. Security Index Matrix For Open Security Environments
</p><pre><b>                               Maximum Data Sensitivity</b>
<b>  ___________________________________________________________</b>

<b>                             U    N    C    S    TS   1C   MC</b>
<b>  ___________________________________________________________</b>

<b>  Minimum	     U	     C1	  B1   B2   B3   *    *    *</b>
<b>  Clearance	     N	     C1	  C2   B2   B2   A1   *    *</b>
<b>  Or	             C	     C1   C2   C2   B1   B3   A1   *	</b>
<b>  Authorization	     S       C1   C2   C2   C2   B2   B3   A1</b>
<b>  of	             TS(BI)  C1   C2   C2   C2   C2   B2   B3</b>
<b>  System	     TS(SBI) C1   C2   C2   C2   C2   B1   B2</b>
<b>  Users	             1C      C2   C2   C2   C2   C2   C2   B1</b>
<b>	             MC      C2   C2   C2   C2   C2   C2   C2</b>
<b>  ___________________________________________________________</b>


</pre>
<p>
7. Security Index Matrix For Closed Security Environments
</p><pre><b>                               Maximum Data Sensitivity</b>
<b>  ___________________________________________________________</b>

<b>                             U    N    C    S    TS   1C   MC</b>
<b>  ___________________________________________________________</b>

<b>  Minimum	     U       C1   B1   B2   B2   A1   *    *</b>
<b>  Clearance	     N       C1   C2   B1   B2   B3   A1   *</b>
<b>  Or	             C       C1   C2   C2   B1   B2   B3   A1	</b>
<b>  Authorization	     S       C1   C2   C2   C2   B2   B2   B3</b>
<b>  of	             TS(BI)  C1   C2   C2   C2   C2   B2   B2</b>
<b>  System	     TS(SBI) C1   C2   C2   C2   C2   B1   B2</b>
<b>  Users	             1C	     C2	  C2   C2   C2   C2   C2   B1</b>
<b>	             MC	     C2	  C2   C2   C2   C2   C2   C2</b>
<b>  ___________________________________________________________</b>


</pre>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> CSC-STD-005-85
</p><p>
<strong>Title:</strong> DoD Magnetic Remanence Security Guideline
</p><p>
<strong>Color:</strong> Dark Blue
</p><p>
<strong>Date:</strong> 15 NOV 85
</p><p>
<strong>Highlights: </strong>No longer in distribution, this document has
been superseded by NCSC-TG-25, A Guide to Understanding Data Remanence.
</p><p>
1. Declassification of magnetic media is the procedure which renders the
media unclassified and suitable for release. Clearing is the procedure which
removes the data from the media before being stored or rereleased within
a secure environment.
</p><p>
2. Declassification requires permission from the ISSO. This decision will
be based on:
</p><blockquote>
  a. The physical media.
  <p>
  b. The criticality of the data previously stored on the media.
  </p><p>
  c. The procedures performed.
  </p><p>
  d. A review of the audit of the declassification.
  </p><p>
  e. An analysis of the risk of incomplete declassification.
</p></blockquote>
<p>
3. For clearing of properly functioning media, one overwrite of each addressable
location with a bit pattern, followed by the pattern's complement is sufficient.
</p><p>
4. For declassification of properly functioning media, three overwrite cycles
are required. There will be the risk of partially malfunctioning equipment
to factor into the declassification decision.
</p><p>
5. Non-Destructive Declassification and Clearing of non-functional media
(including malfunctioning) must be accomplished by degaussing with an
NCSC-Approved Degausser.
</p><p>
6. Malfunctioning Winchester disk drives cannot be declassified for return
to vendor for repair in a non-destructive manner. An (expensive) alternative
is to courier the drive to the vendor and have the platters removed, in the
couriers view, and returned.
</p><p>
7. Destruction of soft media can be accomplished through incineration or
disintegration.
</p><p>
8. Destruction of drums and platters can be accomplished through removing
the magnetic media with an emery wheel or a disk sander.
</p><p>
9. Before release for destruction, the media should be cleared, when possible.
</p><p>
10. NCSC evaluates and approves degaussers. The latest list of approved
degaussers should be Reviewed before acquisition of new degaussers.
</p><p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-001 Version-2
</p><p>
<strong>Title:</strong> A Guide to Understanding Audit
</p><p>
<strong>Color: </strong>Tan <strong></strong>
</p><p>
<strong>Date:</strong> 1 JUN 88
</p><p>
<strong>Highlights</strong>
</p><p>
1. Audit must:
</p><blockquote>
  a. Provide data for individual accountability.
  <p>
  b. Allow review of user access patterns.
  </p><p>
  c. Allow discovery of attempts to bypass security.
  </p><p>
  d. Act as a deterrent against habitual attempts to bypass security. (Advertise
  the Audit.)
  </p><p>
  e. Supply assurance that attempts (successful or not) to bypass security
  will be discovered.
  </p><p>
  f. Be protected as a part of the TCB and at the sensitivity of the data on
  the system.
</p></blockquote>
<p>
2. C2 Audited Events:
</p><blockquote>
  a. Login.
  <p>
  b. Begin Access to Object.
  </p><p>
  c. End Access to Object.
  </p><p>
  d. Actions taken by the system operators, administrators, and/or security
  administrators.
  </p><p>
  e. Printed Output.
  </p><p>
  f. System specific security relevant events.
</p></blockquote>
<p>
3. Additional B1 Audited Events:
</p><blockquote>
  g. Override of hardcopy output markings.
  <p>
  h. Changes of single/multilevel port designators.
  </p><p>
  i. Changes of single level port sensitivity levels.
  </p><p>
  j. Changes of multilevel port sensitivity level ranges.
</p></blockquote>
<p>
4. Additional B2 Audited Events:
</p><blockquote>
  k. Covert storage channel events.
</blockquote>
<p>
5. Additional B3 Audited Events:
</p><blockquote>
  l. Events that may indicate imminent violation of the security policy.
</blockquote>
<p>
6. C2 Audited Information:
</p><blockquote>
  a. Date and Time.
  <p>
  b. UserID.
  </p><p>
  c. Event Type.
  </p><p>
  d. Success or Failure.
  </p><p>
  e. TerminalID.
  </p><p>
  f. ObjectID.
  </p><p>
  g. Description of modifications to security databases. (Security Administrator.)
</p></blockquote>
<p>
7. B1 Additional Audited Information:
</p><blockquote>
  h. Object SL.
  <p>
  i. Subject SL.
</p></blockquote>
<p>
8. B3 auditing includes notification of event thresholds which show "funny
business".
</p><p>
9. Selective collection of audit events saves time, space, and processor
but possibly doesn't collect all data that will be needed.
</p><p>
10. Selective reduction collects all of the data but performance suffers
and when storage is filled nothing is collected until corrective action is
taken.
</p><p>
11. Compression of the audit data to save space and processing is allowed
(in conjunction with "decompression").
</p><p>
12. Separate audit trails for separate formats (or audit event types) are
allowed with consistent Date-Time entries.
</p><p>
13. Archival storage capability for audit trail data is required.
</p><p>
14. Provisions must be made for the overflow conditions in physical storage.
</p><p>
15. Dedicated processor storage or write-once devices are good protection
for the data.
</p><p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-002 Version-1
</p><p>
<strong>Title:</strong> Trusted Product Evaluations A Guide for Vendors
</p><p>
<strong>Color:</strong> Blue
</p><p>
<strong>Date:</strong> 22 JUN 90
</p><p>
<strong>Highlights: </strong>This document gives the trusted product vendor
the background and requirements for evaluation by NCSC for inclusion on the
EPL. The concepts of "Shared Responsibility" and "Partnership with the Vendor"
are stressed.
</p><p>
1. Phases of the Trusted Product Evaluation Program
</p><blockquote>
  a. Proposal Review Phase
  <blockquote>
    1) Initial Contact
    <p>
    2) Certificate Pertaining to Foreign Interests
    </p><p>
    3) Proposal Package Review
    </p><p>
    4) Preliminary Technical Review
    </p><p>
    5) Program Decision
    </p><p>
    6) Legal Agreement
  </p></blockquote>
  <p>
  b. Vendor Assistance Phase
  </p><blockquote>
    1) Design
    <p>
    2) Documentation
    </p><p>
    3) Test Plan
    </p><p>
    4) Plan for Rating Maintenance
  </p></blockquote>
  <p>
  c. Design Analysis Phase
  </p><p>
  d. Evaluation Phase
  </p><p>
  e. Rating Maintenance Phase
</p></blockquote>
<p>
2. Technical Description of the Product: The Technical Description is discussed
in the document but a better organized and more concise listing of the required
information is found in NCSC-TG-019, Trusted Product Evaluation Questionnaire.
</p><p>
3. Legal Agreement: After acceptance for entry into the Vendor Assistance
Phase, a Legal Agreement is entered into which covers the following points:
</p><blockquote>
  a. NSA provides needed computer security information.
  <p>
  b. NSA protects proprietary information.
  </p><p>
  c. Vendor supplies information needed for the assessment.
  </p><p>
  d. Vendor follows the procedures.
  </p><p>
  e. NSA performs an evaluation with a rating and a final evaluation report.
  </p><p>
  f. Vendor provides ads and brochures before release.
  </p><p>
  g. Vendor prepares a report after each RAMP approval.
</p></blockquote>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-003 Version-1
</p><p>
<strong>Title:</strong> A Guide to Understanding Discretionary Access Control
</p><p>
<strong>Color:</strong> Tangerine I
</p><p>
<strong>Date:</strong> 30 SEP 87
</p><p>
<strong>Highlights</strong>
</p><p>
1. Discretionary Access Control (DAC) is a means of restricting access to
objects based on the identity of subjects and/or their group memberships.
</p><p>
2. DAC is intended to restrict (and allow) access based on need-to-know.
</p><p>
3. DAC is generally implemented using one (or more) of five methodologies:
</p><blockquote>
  a. Capabilities: Each user has (or has not) a "capability" to access a specific
  object in a specific mode (Read, Write, etc.). Capabilities can be passed
  to another subject but cannot be altered without TCB intervention. With
  capabilities, it is not possible to determine which users have access to
  specific objects. Group access and revocation of access are a major drawback.
  [User Possessed Token Scheme]
  <p>
  b. Profiles: Each user has a list of allowed objects associated with it.
  This can become a very large and cumbersome table. It is difficult to determine
  which users have access to specific objects. Group access and revocation
  of access are a major drawback. [List of User's Objects]
  </p><p>
  c. Access Control Lists: Each object to be protected has a list of allowed
  (and disallowed) users associated with it. This can also be implemented with
  groups. If implemented properly, ACLs can meet all classes' requirements.
  [List of Object's Users]
  </p><p>
  d. Protection Bits: Access is limited based on the access modes allowed for
  the Owner, Group, and World. Protection Bits do not readily support Multiple
  Groups and individual access control.
  </p><p>
  e. Passwords: The use of a password to gain access to an object can work
  in conjunction with other protections, but the proliferation of the passwords
  leads to unwieldy systems. Passwords are not sufficient protection, but as
  supplemental protection against Trojan Horses, passwords have merit.
</p></blockquote>
<p>
4. The heart of DAC rests with two distinct and preferably separate entities,
control permission and access modes:
</p><blockquote>
  a. Control permissions define which subjects have the ability to grant and
  revoke access permissions and change access modes.
  <blockquote>
    1) Control permissions can limit the control to grant/revoke permission on
    access modes for subjects (Control) or
    <p>
    2) Control permissions can include the passing of the control permission
    to another subject (Control With Passing).
  </p></blockquote>
  <p>
  b. Implementation of Control Models for DAC are based on the control permissions.
  </p><p>
  c. The four basic control models for DAC are:
  </p><blockquote>
    1) Hierarchical: For a simple example, the system administrator would have
    control with passing to all objects within the system. The system administrator
    would pass control of subsets to the applicable "department heads" who would
    then pass control of subsets to "project heads", etc. Controllers may not
    be the titular heads. Controllers also control their own access modes. (Can
    satisfy all classes.)
    <p>
    2) Ownership: Each object has an "Owner" who controls access to the object.
    Protection bits implement ownership. Administratively, ownership can be
    implemented by the system administrator not passing control permission to
    any subject but the Owner. (Can satisfy all classes.)
    </p><p>
    3) Laissez-faire: Each subject can pass whatever control permissions and
    accesses the subject has to any other subject, who can then pass them on
    to whoever they desire. Control permissions and access mode control should
    be separate. (Can satisfy all classes. If not separate, does not meet C2.)
    </p><p>
    4) Centralized: All control permissions rest with one user. Control permissions
    cannot be passed. Control is definite, but could lead to overwork and slowdown
    with large request quantities. (Can satisfy all classes.)
  </p></blockquote>
  <p>
  d. Access Modes control if and how a subject can use an object. Access modes
  include:
  </p><blockquote>
    1) Read: No change allowed.
    <p>
    2) Write-Append: Additions allowed, but no changes and no viewing.
    </p><p>
    3) Write: Allows modify, add, or delete, but no view.
    </p><p>
    4) Delete: Deletion, nothing else.
    </p><p>
    5) Execute: Run an executable object.
  </p></blockquote>
  <p>
  e. Access controls can be levied on directories and/or files.
</p></blockquote>
<p>
5. Requirements for C1:
</p><blockquote>
  a. Define and control access between named and objects named users (or named
  groups).
  <p>
  b. Must recognize and control individual objects.
</p></blockquote>
<p>
6. Requirements for C2 through B2:
</p><blockquote>
  a. Include/Exclude access to each object on a per user (or per group) basis.
  <p>
  b. Protection for all objects. (Protection by default for new objects.)
  </p><p>
  c. Control permissions separate from other access types.
  </p><p>
  d. Group members uniquely identified.
  </p><p>
  e. Groups are optional.
</p></blockquote>
<p>
7. Requirements for B3 through A1:
</p><blockquote>
  a. Different access modes are required. (Read, Write, etc.)
  <p>
  b. For each named object, be able to specify named users with access modes
  allowed.
  </p><p>
  c. For each named object, be able to specify groups with their membership
  and accesses.
  </p><p>
  d. For each named object, be able to specify named users and groups with
  no access.
</p></blockquote>
<p>
  </p><hr>
<p>
<i>[See also <a href="http://cryptome.org/jya/ntob.htm#V">Section V</a>]</i>
</p><p>
<strong>Document Number:</strong> NCSC-TG-004 Version 1
</p><p>
<strong>Title:</strong> Glossary of Computer Security Terms
</p><p>
<strong>Color:</strong> Aqua
</p><p>
<strong>Date:</strong> 21 OCT 88 <br wp="br1">
</p><blockquote>
  <b>AIS</b> Automated Information System
  <p>
  <b>COMPUSEC</b> Computer Security
  </p><p>
  <b>COMSEC</b> Communications Security
  </p><p>
  <b>DAA</b> Designated Approving Authority
  </p><p>
  <b>DAC</b> Discretionary Access Control
  </p><p>
  <b>EPL</b> Evaluated Product List
  </p><p>
  <b>ISSO</b> Information System Security Officer
  </p><p>
  <b>MAC</b> Mandatory Access Control
  </p><p>
  <b>NCSC</b> National Computer Security Center
  </p><p>
  <b>OPSEC</b> Operations Security
  </p><p>
  <b>SSO</b> System Security Officer
  </p><p>
  <b>TCB</b> Trusted Computing Base
  </p><p>
  <b>TCSEC</b> DoD Trusted Computer System Evaluation Criteria
</p></blockquote>
<p>
Access - A specific type of interaction between a subject and an object that
results in the flow of information from one to the other (e.g., Read, Write,
Execute, Append, Modify, Delete, or Create).
</p><p>
Access Control Mechanism - Hardware or software features, operating procedures,
and/or management procedures designed to detect and prevent unauthorized
access and to permit authorized access in an automated system.
</p><p>
Access Level - The hierarchical portion of the security level used to identify
the sensitivity of data and the clearance or authorization of users.
</p><p>
Access List - A list of users, programs, and/or processes and the specifications
of access categories to which each is assigned.
</p><p>
Accountability - The property that enables activities on a system to be traced
to individuals who may then be held responsible for their actions.
</p><p>
Accreditation - A formal declaration by the DAA that the AIS is approved
to operate in a particular security mode using a prescribed set of safeguards.
</p><p>
Administrative Security (Procedural Security) - The management constraints
and supplemental controls established to provide an acceptable level of
protection for data.
</p><p>
Assurance - The measure of confidence that the security features and architecture
of an AIS accurately mediate and enforce the security policy.
</p><p>
Attack - The act of trying to bypass controls on a system.
</p><p>
Audit Trail - A chronological record of system activities that is sufficient
to enable the reviewing of the sequence of environments and activities
surrounding or leading to an operation, a procedure, or an event in a transaction
from its inception to final results.
</p><p>
Authenticate - To verify the identity of a user, device, or other entity
in a computer system, often as a prerequisite to allowing access to resources
in a system.
</p><p>
Authorization - The granting of access rights to a user, program, or process.
</p><p>
Automated information System - An assembly of computer hardware, software,
and/or firmware configured to collect, create, communicate, compute, disseminate,
process, store, and/or control data or information.
</p><p>
Capability - A protected identifier that both identifies the object and specifies
the access rights to be allowed by the accessor who possesses the capability.
</p><p>
Category - A restrictive label that has been applied to classified or
unclassified data as a means of increasing the protection of the data and
further restricting access to the data.
</p><p>
Certification - The comprehensive evaluation of the technical and nontechnical
security features of an AIS and other safeguards, made in support of the
accreditation process, that establish the extent to which a design and
implementation meet a specified set of security requirements.
</p><p>
Closed Security Environment - Environment in which both of these conditions
occur:
</p><blockquote>
  a. Application developers (including maintainers) have sufficient clearances
  and authorizations to provide an acceptable presumption that they have not
  introduced malicious logic.
  <p>
  b. Configuration control procedures provide sufficient assurance that
  applications and the equipment are protected against the introduction of
  malicious logic prior to and during operations.
</p></blockquote>
<p>
Communications Security - Measures taken to deny unauthorized persons information
derived from telecommunications of the U.S. Government concerning national
security, and to ensure the authenticity of such communications. COMSEC includes
cryptosecurity, transmission security, emission security and physical security
of communications security material and information.
</p><p>
Compartment - A class of information that has need-to-know access controls
beyond those normally provided for access to Confidential, Secret, or Top
Secret information.
</p><p>
Compartmented Mode - The mode of operation where each user has a valid personnel
clearance for the most restrictive data and formal access and need-to-know
for the data to which he has access.
</p><p>
Compromise - A violation of the security policy of a system such that
unauthorized disclosure of sensitive information may have occurred.
</p><p>
Computer Security - Measures and controls that protect an AIS against denial
of service and unauthorized (accidental or intentional) disclosure, modification,
or destruction of AISs and data.
</p><p>
Configuration Control - The process of controlling modifications to the system's
hardware, firmware, software, and documentation that provides sufficient
assurance that the system is protected against the introduction of improper
modifications prior to, during, or after system implementation.
</p><p>
Configuration management - The management of security features and assurances
through the control of changes made to a system's hardware, software, firmware,
documentation, test, test fixtures, and test documentation throughout the
development and operational life of the system.
</p><p>
Confinement Property (*-Property) - Rule allowing a subject write access
to an object only if the security level of the object dominates the security
level of the subject. (Bell-LaPadula)
</p><p>
Cost-Risk Analysis - The assessment of the costs of providing data protection
for a system versus the cost of losing or compromising the data.
</p><p>
Covert Channel - A communications channel that allows two cooperating processes
to transfer information in a manner that violates the system's security policy.
</p><p>
Cryptosecurity - The security or protection resulting from the proper use
of technically sound cryptosystems.
</p><p>
Data Security - The protection of data from unauthorized (accidental or
intentional) modification, destruction, or disclosure.
</p><p>
Dedicated Mode - The mode of operation where each user has a valid personnel
clearance, formal access, and need-to-know for all of the information in
the system.
</p><p>
Denial of Service - Any action that prevents any part of a system from
functioning in accordance with its intended purpose.
</p><p>
Designated Approving Authority - The official who has the authority to decide
on accepting the security safeguards prescribed for an AIS or that official
who may be responsible for issuing an accreditation statement that records
the decision to accept those safeguards.
</p><p>
Discretionary Access Control - A means of restricting access to objects based
on the identity and need-to-know of the user, process, and/or groups to which
they belong.
</p><p>
Domain - The unique context (e.g., access control parameters) in which a
program is operating; in effect, the set of objects that a subject has the
ability to access.
</p><p>
Dominate - Security level S1 is said to dominate security level S2 if the
hierarchical classification of S1 is greater than or equal to that of S2
and the nonhierarchical categories of S1 include all those of S2 as a subset.
</p><p>
Embedded System - A system that performs or controls a function, either in
whole or in part, as an integral element of a larger system or subsystem.
</p><p>
Emission Security (EMSEC) - The protection resulting from all measures taken
to deny unauthorized persons information of value that might be derived from
intercept and from an analysis of compromising emanations from systems.
</p><p>
Environment - The aggregate of external procedures, conditions, and objects
that affect the development, operation and maintenance of a system.
</p><p>
Formal Access Approval - Documented approval by a data owner to allow access
to a particular category of information.
</p><p>
Granularity - An expression of the relative size of a data object; e.g.,
protection at the file level is considered coarse granularity, whereas protection
at the field level is considered to be of a finer granularity.
</p><p>
Identification - The process that enables recognition of an entity by a system,
generally by the use of unique machine readable user names.
</p><p>
Information System Security Officer - The person responsible to the DAA for
ensuring that security is provided for and implemented throughout the life
cycle of an AIS from the beginning of the concept development plan through
its design, development, operation, maintenance, and secure disposal.
</p><p>
Isolation - The containment of subjects and objects in a system in such a
way that they are separated from one another, as well as from the protection
controls of the operating system.
</p><p>
Least Privilege - The principle that requires that each subject be granted
the most restrictive set of privileges needed for the performance of authorized
tasks.
</p><p>
Least Use - The principle that requires that each subject use the least privilege
needed for the performance of authorized tasks.
</p><p>
List-Oriented - A computer protection system in which each protected object
has a list of all subjects authorized to access it.
</p><p>
Lock-and-Key Protection System - A protection system that involves matching
a key or password with a specific access requirement.
</p><p>
Mandatory Access Control - A means of restricting access to objects based
on the sensitivity (as represented by a label) of the information contained
in the objects and the formal authorization (i.e., clearance) of subjects
to access information of such sensitivity.
</p><p>
Modes Of Operation - A description of the conditions under which an AIS
functions, based on the sensitivity of data processed and the clearance levels
and authorizations of the users. Four modes of operation authorized are:
</p><blockquote>
  a. Dedicated Mode
  <p>
  b. System-High Mode
  </p><p>
  c. Compartmented Mode
  </p><p>
  d. Multilevel Mode
</p></blockquote>
<p>
Multilevel Mode - The mode of operation where some users do not have a valid
personnel clearance for the most restrictive information in the system, and
all have clearance, formal access, and need-to-know for the data to which
they have access.
</p><p>
Multilevel Secure - A class of system containing information with different
sensitivities that simultaneously permits access by users with different
security clearances and need-to-know, but prevents users from obtaining access
to information for which they lack authorization.
</p><p>
Multiuser Mode - A mode of operation designed for systems that process sensitive
unclassified information in which users may not have a need-to-know for all
information processed.
</p><p>
Need-To-Know - The necessity for access to, knowledge of, or possession of
specific information required to carry out official duties.
</p><p>
Object - A passive entity that contains or receives information. Examples:
records, blocks, pages, segments, files, bytes, fields, printers, network
nodes, etc.
</p><p>
Object Reuse - The reassignment and reuse of a storage medium that once contained
one or more objects. To be securely reused and assigned to a new subject,
storage media must contain no residual data from the object(s) previously
contained in the media.
</p><p>
Open Security Environment - An environment in which at least one of the following
conditions occur: a. Application developers (including maintainers) do not
have sufficient clearances or authorizations to provide an acceptable presumption
that they have not introduced malicious logic. b. Configuration control
procedures does not provide sufficient assurance that applications and the
equipment are protected against the introduction of malicious logic prior
to and during the operation of the system.
</p><p>
Operations Security - An analytical process by which the U.S.Government and
its supporting contractors can deny to potential adversaries information
about capabilities and intentions by identifying, controlling, and protecting
evidence of the planning and execution of sensitive activities and operations.
</p><p>
Partitioned Security Mode - A mode of operation wherein all personnel have
the clearance but not necessarily formal access approval and need-to-know
for all information in the system.
</p><p>
Password - A protected/private character string used to authenticate an identity.
</p><p>
Penetration - The successful act of bypassing the security mechanisms of
a system.
</p><p>
Periods Processing - The processing of various levels of sensitive information
at distinctly different times.
</p><p>
Personnel Security - The procedures established to ensure that all personnel
who have access to sensitive information have the required authority as well
as the appropriate clearances.
</p><p>
Physical Security - The application of physical barriers and control procedures
as preventative measures or countermeasures against threats to resources
and sensitive information.
</p><p>
Privileged Instructions - A set of instructions to control features that
are generally executable only when the automated system is operating in the
executive state.
</p><p>
Process - A program in execution.
</p><p>
Protection Philosophy - An informal description of the overall design of
a system that delineated each of the protection mechanisms employed. A
combination of formal and informal techniques is used to show that the mechanisms
are adequate to enforce the security policy.
</p><p>
Purge - The removal of sensitive data from an AIS, AIS storage device, or
peripheral device with storage capacity, at the end of a processing session.
</p><p>
Read - A fundamental operation that results in the flow of information from
an object to a subject.
</p><p>
Reference Monitor Concept - An access-control concept that refers to an abstract
machine that mediates all access to objects by subjects.
</p><p>
Residual Risk - The portion of risk that remains after security measures
have been applied.
</p><p>
Residue - Data left in storage after processing operations are complete.
</p><p>
Risk - The probability that a particular threat will exploit a particular
vulnerability of the system.
</p><p>
Secure State - A condition in which no subject can access any object in an
unauthorized manner.
</p><p>
Security Filter - A trusted subsystem that enforces a security policy on
the data that pass through it.
</p><p>
Security Label - A piece of information that represents the security level
of an object.
</p><p>
Security Level - The combination of a hierarchical classification and a set
of nonhierarchical categories that represents the sensitivity of information.
</p><p>
Security Policy - The set of laws, rules, and practices that regulates how
an organization manages, protects, and distributes sensitive information.
</p><p>
Security Policy Model - A formal representation of the security policy enforced
by the system. It must identify the set of rules and practices that regulate
how a system manages, protects, and distributes sensitive information.
</p><p>
Security Range - The highest and lowest security levels that are permitted
in or on a system, system component, subsystem, or network.
</p><p>
Security Requirements Baseline - A description of minimum requirements necessary
for a system to maintain an acceptable level of security.
</p><p>
Security Safeguards - The protective measures and controls that are prescribed
to meet the security requirements specified for a system. Those safeguards
may include but are not limited to: hardware and software security features,
operating procedures, accountability procedures, access and distribution
controls, management constraints, personnel security, and physical structures,
areas, and devices.
</p><p>
Security Specifications - A detailed description of the safeguards required
to protect a system.
</p><p>
Sensitivity Label - A piece of information that represents the security level
of an object. Sensitivity labels are used by the TCB as the basis for mandatory
access control decisions.
</p><p>
Simple Security Property - A security model rule allowing a subject read
access to an object only if the security level of the subject dominates the
security level of the object. (Bell-LaPadula)
</p><p>
Stand-alone, Shared System - A system that is physically and electrically
isolated from other systems and is intended to be used by more than one person
with data belonging to one user remaining available to the system while another
user is using the system.
</p><p>
Stand-Alone, Single-User System - A system that is physically and electrically
isolated from other systems and is intended to be used by one person at a
time with no data belonging to other users remaining in the system.
</p><p>
Storage Object - An object that supports both read and write accesses.
</p><p>
Subject - An active entity, generally in the form of a person, process, or
device, that causes information to flow among objects or changes the system
state.
</p><p>
Subject Security Level - A subject's security level is equal to the security
level of objects to which it has both read and write access. A subject's
security level must always be dominated by the clearance of the user with
which the subject is associated.
</p><p>
System High - The highest security level supported by a system at a particular
time or in a particular environment.
</p><p>
System High Mode - The mode of operation where each user has a valid personnel
clearance and formal access for the most restrictive information in the system
and need-to-know for some of the information in the system.
</p><p>
System Low - The lowest security level supported by a system at a particular
time or in a particular environment.
</p><p>
Technical Attack - An attack that can be perpetrated by circumventing or
nullifying hardware and software protection mechanisms, rather that by subverting
system personnel or other users.
</p><p>
Terminal Identification - The means to uniquely identify a terminal to a
system.
</p><p>
Threat - Any circumstance or event with the potential to cause harm to a
system in the form of destruction, disclosure, modification of data, and/or
denial of service.
</p><p>
Threat Analysis - The examination of all actions that might adversely affect
a system.
</p><p>
Threat Monitoring - The analysis, assessment, and review of audit trails
and other data collected for the purpose of searching out system events that
may constitute violations or attempted violations of system security.
</p><p>
Ticket-Oriented - A computer protection system in which each subject maintains
a list of unforgeable bit patterns, called tickets, one for each object the
subject is authorized to access.
</p><p>
Trusted Computing Base - The totality of protection mechanisms within a computer
system, including hardware, software, and firmware, the combination of which
is responsible for enforcing a security policy.
</p><p>
Trusted Distribution - A trusted method for distributing the TCB hardware,
software, and firmware components, both originals and updates, that provides
methods for protecting the TCB from modification during distribution and
for detection of any changes to the TCB that may occur.
</p><p>
Trusted Identification Forwarding - An identification method used in networks
whereby the sending host can verify that an authorized user on its system
is attempting a connection to another host.
</p><p>
Trusted Path - A mechanism by which a person at a terminal can communicate
directly with the TCB. This mechanism can only be activated by the person
or the TCB and cannot be imitated by untrusted software.
</p><p>
Trusted Process - A process whose incorrect or malicious execution is capable
of violating system security policy. Such a process is examined and evaluated
to ensure proper performance of the desired functionality.
</p><p>
Untrusted Process - A process that has not been evaluated or examined for
adherence to the security policy. Such a process is not allowed the ability
to violate the security policy.
</p><p>
User - Person or process accessing an AIS either by direct connection(i.e.,
via terminals) or indirect connections (i.e., prepare input data or receive
output that is not reviewed for content or classification by a responsible
individual).
</p><p>
User ID - A unique symbol or character string that is used by a system to
identify a specific user.
</p><p>
User Profile - Patterns of a user's activity that can be used to detect changes
in normal routines.
</p><p>
Vulnerability - A weakness in the system security procedures, system design,
implementation, internal controls, etc., that could be exploited to violate
system security policy.
</p><p>
Write - A fundamental operation that results in the flow of information from
a subject to an object.
</p><p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-005 Version-1
</p><p>
<strong>Title:</strong> Trusted Network Interpretation
</p><p>
<strong>Color:</strong> Red I
</p><p>
<strong>Date:</strong> 31 JUL 87
</p><p>
<strong>Highlights </strong>This book is a rehash of the Orange Book for
networks (in 278 pages). There are several new concepts brought out by the
Red Book; these new concepts are the heart of this Digest.
</p><p>
1. Security Policy: The network security policy needs two section, in addition
to the sections needed by a system:
</p><blockquote>
  a. Secrecy Policy: The Secrecy Policy defines the policy enforced by the
  network to protect the data on the network from improper exposure to unauthorized
  users.
  <p>
  b. Integrity Policy: The Integrity Policy defines the policy enforced to
  ensure the delivery of unmodified and uncorrupted data from the source to
  the destination.
</p></blockquote>
<p>
2. For networks, several new evaluation areas are brought forth. The criteria
for the evaluations fall into three main areas; Functionality, Strength of
Mechanism, and Assurance. the following is a listing of the new areas to
assess when determining the "Goodness" of a network which were not present
in the assessment of the stand-alone system:
</p><blockquote>
  a. Support Primitives:
  <blockquote>
    1) Encryption Mechanism.
    <p>
    2) Protocols.
  </p></blockquote>
  <p>
  b. Documentation (needing special attention for networks):
  </p><blockquote>
    1) Security Features User's Guide.
    <p>
    2) Trusted Facility Manual.
    </p><p>
    3) Test Documentation.
    </p><p>
    4) Design Documentation.
  </p></blockquote>
  <p>
  c. Communications Integrity:
  </p><blockquote>
    1) Authentication.
    <p>
    2) Communications Field Integrity.
    </p><p>
    3) Non-Repudiation (receipted, guaranteed delivery).
  </p></blockquote>
  <p>
  d. Denial of Service:
  </p><blockquote>
    1) Continuity of Operations.
    <p>
    2) Protocol Based Protection.
    </p><p>
    3) Network Management.
  </p></blockquote>
  <p>
  e. Compromise Protection:
  </p><blockquote>
    1) Data Confidentiality.
    <p>
    2) Traffic Confidentiality.
    </p><p>
    3) Selective Routing.
  </p></blockquote>
</blockquote>
<p>
3. Networks are composed of components. While each component need not possess
full security "Goodness", the whole must be able to be judged for overall
"Goodness". The method chosen for systematic evaluation of the components
was to judge each piece by the criteria of one or more slices of the total
security framework. The following is a listing of Component Types and their
Minimum and Maximum Classes:
</p><blockquote>
  <pre><b>M = MAC	</b>
<b>D = DAC	</b>
<b>I = Identification and Authentication	</b>
<b>A =</b>
<b>Audit</b>
</pre>
  <pre><b>Component Type	Min Class	Max Class</b>
<b>_________________________________________</b>

<b>M		B1		A1</b>
<b>D		C1		C2+</b>
<b>I		C1		C2</b>
<b>A 		C2		C2+</b>
<b>DI		C1		C2+</b>
<b>DA		C2		C2+</b>
<b>IA		C2		C2+</b>
<b>IAD		C2		C2+</b>
<b>MD		B1		A1</b>
<b>MA		B1		A1</b>
<b>MI		B1		A1</b>
<b>MDA		B1		A1</b>
<b>MDI		B1		A1</b>
<b>MIA		B1		A1</b>
<b>MIAD		B1		A1</b>
<b>_________________________________________</b>


</pre>
</blockquote>
<p>
4. Cascading is the situation where multilevel systems which operate at different
ranges are connected on a multilevel network. While each of the systems in
question have an allowably small range of operation (Confidential through
Secret, Secret through Top Secret, etc.) the network has a larger (and possibly
unacceptable) range of users (Confidential through Top Secret, by the example).
Even when the network only allows Secret transfers, there is the increased
chance that a Confidential who can worm up one level (to Secret) can now
run the net to the Secret-Top Secret system and worm up one more level.
</p><p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-006 Version-1
</p><p>
<strong>Title:</strong> A Guide to Understanding Configuration Management
</p><p>
<strong>Color: </strong>Tangerine II
</p><p>
<strong>Date:</strong> 28 MAR 88
</p><p>
<strong>Highlights</strong>
</p><p>
1. Configuration Management (CM) is a requirement for B2 through A1. (Multilevel
Mode)
</p><p>
2. CM should be used for all systems, regardless of level and mode.
</p><p>
3. CM has the duty of ensuring that the inevitable changes to the system
are performed properly and do not adversely effect the security and operations
of the system.
</p><p>
4. B2 CM Requirements:
</p><blockquote>
  1) CM system must be in place during the development and maintenance of the
  TCB to maintain control of changes to:
  <p>
  2) - Descriptive Top Level Specification (DTLS).
  </p><p>
  3) - Other Design Data.
  </p><p>
  4) - Implementation Documentation (User's Manuals, etc.).
  </p><p>
  5) - Source Code.
  </p><p>
  6) - Running Version of Object Code.
  </p><p>
  7) - Test Fixtures.
  </p><p>
  8) - Test Documentation.
  </p><p>
  9) CM System must assure consistent mapping across all documentation and
  code.
  </p><p>
  10) CM System must provide tools to generate a new version of the TCB.
  </p><p>
  11) CM system must provide tools to ensure the inclusion of only the desired
  changes to the TCB upon generation of a new version of the system.
</p></blockquote>
<p>
5. A1 CM Requirements:
</p><blockquote>
  12) CM System must be in place throughout the entire lifecycle (design,
  development, and maintenance). The CM System must maintain control of changes
  to the:
  <p>
  13) - TCB hardware.
  </p><p>
  14) - TCB software.
  </p><p>
  15) - TCB firmware.
  </p><p>
  16) - Formal Model.
  </p><p>
  17) - Formal Top Level Specification.
  </p><p>
  18) - CM Tools.
  </p><p>
  19) Prevent unauthorized modification or destruction of the masters of all
  material used to generate a new TCB.
</p></blockquote>
<p>
6. CM consists of four separate tasks:
</p><blockquote>
  a. Identification.
  <p>
  b. Control.
  </p><p>
  c. Status Accounting.
  </p><p>
  d. Auditing.
</p></blockquote>
<p>
7. CM Identification: Procedures to enable a person to identify the configuration
of the system at discrete points in time for systematic control of the
configuration and to maintain integrity and traceability throughout the system
life cycle.
</p><p>
8. CM Control: The systematic evaluation, coordination, approval or disapproval
of proposed changes to the design and construction of a configuration item
whose configuration has been formally approved.
</p><p>
9. CM Status Accounting: Records and reports which enable proper logistics
support to be established.
</p><p>
10. CM Audit: Checking CM Accounting information to ascertain that only the
authorized changes have been made in the code that will actually be used
as the new version of the TCB.
</p><p>
11. Classical Baselining is the recommended method for implementing CM.
</p><p>
12. Use of a Configuration Control Board is also recommended. Membership
should include the entire community.
</p><p>
13. UNIX SCCS (Source Code Control System) and VAX DEC/CMS (Code Management
System) are recommended tools for tracking code histories.
</p><p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-007 Version-1
</p><p>
<strong>Title:</strong> A Guide to Understanding Design Documentation
</p><p>
<strong>Color:</strong> Burgandy
</p><p>
<strong>Date:</strong> 2 OCT 88
</p><p>
<strong>Highlights</strong>
</p><p>
1. Design documentation should be written in an iterative manner with the
total lifecycle of the system in mind at all times.
</p><p>
2. C1 Design Documentation Requirements:
</p><blockquote>
  1) Describe the Philosophy of Protection (PoP).
  <p>
  2) Describe how the PoP is translated into the TCB.
  </p><p>
  3) Describe how the TCB is modularized (if modular).
  </p><p>
  4) Describe all interfaces between TCB modules (if modular).
  </p><p>
  5) Describe how the TCB protects itself.
  </p><p>
  6) Provide a statement of the system security policy.
</p></blockquote>
<p>
3. B1 Design Documentation Requirements:
</p><blockquote>
  7) Provide a description of the security policy model enforced by the TCB.
  <p>
  8) Explain the sufficiency of the security policy model to enforce the security
  policy.
  </p><p>
  9) Identify and describe the TCB protection mechanisms. [See 5)]
  </p><p>
  10) Explain how the TCB mechanisms satisfy the security policy model.
</p></blockquote>
<p>
4. B2 Design Documentation Requirements:
</p><blockquote>
  11) Describe how the TCB is modularized. [See 3)]
  <p>
  12) Describe all of the interfaces between TCB modules. [See 4)]
  </p><p>
  13) Provide a formal description of the security policy model.
  </p><p>
  14) Prove the sufficiency of the security policy model to enforce the security
  policy.
  </p><p>
  15) Show that the Descriptive Top-Level Specification (DTLS) is an accurate
  description of the TCB interface.
  </p><p>
  16) Describe how the TCB implements the Reference Monitor Concept.
  </p><p>
  17) Describe why the reference monitor is tamper resistant.
  </p><p>
  18) Describe why the reference monitor cannot be bypassed.
  </p><p>
  19) Describe why the reference monitor is correctly implemented.
  </p><p>
  20) Describe how the TCB is structured to facilitate testing.
  </p><p>
  21) Describe how the TCB is structured to enforce least privilege.
  </p><p>
  22) Present the results and methodology of the covert channel analysis.
  </p><p>
  23) Describe the tradeoffs involved in restricting covert channels.
  </p><p>
  24) Identify all auditable events that may be used in exploitation of known
  covert storage channels.
  </p><p>
  25) Provide the bandwidth of known covert storage channels whose use is not
  detectable by auditing mechanisms.
</p></blockquote>
<p>
5. B3 Design Documentation Requirements:
</p><blockquote>
  26) Identify all auditable events that may be used in exploitation of known
  covert timing channels.
  <p>
  27) Provide the bandwidth of known covert storage channels whose use is not
  detectable by auditing mechanisms.
  </p><p>
  28) Describe how the TCB complies with additional B3 system architecture
  requirements, e.g. minimal TCB and layering.
  </p><p>
  29) Informally show consistency of the TCB implementation with the DTLS.
  </p><p>
  30) Informally show correspondence between elements of the DTLS and elements
  of the TCB.
  </p><p>
  31) Informally show consistency of the DTLS with the model.
</p></blockquote>
<p>
6. A1 Design Documentation Requirements:
</p><blockquote>
  32) Informally show consistency of the TCB implementation with the Formal
  Top-Level Specification (FTLS).
  <p>
  33) Informally show correspondence between elements of the FTLS and elements
  of the TCB.
  </p><p>
  34) Clearly describe hardware, software, and firmware internal to the TCB
  that is not dealt with in the FTLS.
  </p><p>
  35) Informally or formally show consistency of the FTLS with the model.
  </p><p>
  36) Informally show correspondence between the DTLS and the FTLS.
</p></blockquote>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-008 Version-1
</p><p>
<strong>Title:</strong> A Guide to Understanding Trusted Distribution
</p><p>
<strong>Color:</strong> Lavender
</p><p>
<strong>Date:</strong> 15 DEC 88
</p><p>
<strong>Highlights</strong>
</p><p>
1. Trusted Distribution (TD) gives the following assurances:
</p><blockquote>
  a. Assurance that the product evaluated is the one the manufacturer built.
  <p>
  b. Assurance that the product built is the one sent.
  </p><p>
  c. Assurance that the product sent is the one the customer site received.
</p></blockquote>
<p>
2. TD is required at the A1 level and higher.
</p><p>
3. TD should be used at lower levels as cost-effective.
</p><p>
4. TD should include the documentation.
</p><p>
5. TD protects against two threats (either of which can introduce Trojan
Horses, trapdoors, viruses, etc.):
</p><blockquote>
  a. Tampering during transit.
  <p>
  b. Counterfeit TCB updates.
</p></blockquote>
<p>
6. TD requires protection during three phases:
</p><blockquote>
  a. Post-Production.
  <p>
  b. Transit.
  </p><p>
  c. Receipt.
</p></blockquote>
<p>
7. Post-production protection and assurance come from the use of packing,
storage, and loading procedures which ensure that the product shipped is
the product intended. This protection and assurance can come from a combination
of one or more of the following:
</p><blockquote>
  a. Configuration Management procedures.
  <p>
  b. Shrink-Wrap packaging (assuming heat sensitivity allows this).
  </p><p>
  c. Bonded storage.
</p></blockquote>
<p>
8. In transit protection ensures that what is shipped arrives in an unaltered
state and that what arrives was sent by the purported sender. This assurance
can come from a combination of one or more of the following:
</p><blockquote>
  a. Shrink-Wrap packaging.
  <p>
  b. Tamper resistant seals.
  </p><p>
  c. Numbered container seals (with the number sent by separate secure means).
  </p><p>
  d. Active alarm systems.
  </p><p>
  e. Couriers.
  </p><p>
  f. Registered mail
  </p><p>
  g. Message authentication codes.
  </p><p>
  h. Encryption.
</p></blockquote>
<p>
9. Receipt verification lends assurance through three main methods:
</p><blockquote>
  a. Confirmation that the methods used previously do not indicate tampering,
  such as Authentication code checks, untriggered alarms, and unbroken seals.
  <p>
  b. Confirmation that the proper parties sent the shipment which has arrived.
  </p><p>
  c. Independent confirmation that the received TCB is the right TCB. This
  assurance can come from a combination of one or more of the following:
  </p><blockquote>
    1) Check-Sum confirmation.
    <p>
    2) Inventory.
    </p><p>
    3) Technical inspection.
  </p></blockquote>
</blockquote>
<p>
10. Each case is unique and must be viewed individually to determine the
appropriate TD methods. The active threats against the customer site, the
active threats against the vendor site, and the state-of-the-threat-art must
each be taken into account in determining the cost-effective methods to be
used.
</p><p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-009 Version-1
</p><p>
<strong>Title:</strong> Computer Security Subsystem Interpretation
</p><p>
<strong>Color:</strong> Venice Blue
</p><p>
<strong>Date:</strong> 16 SEP 88
</p><p>
<strong>Highlights</strong>
</p><p>
A. Introduction
</p><blockquote>
  1. For systems which do not have sufficient security there are four recognized
  areas which can be taken care of with "add-on" products:
  <blockquote>
    a. Discretionary Access Control (DAC).
    <p>
    b. Object Reuse (OR).
    </p><p>
    c. Identification and Authentication (I&amp;A).
    </p><p>
    d. Audit (AUD).
  </p></blockquote>
  <p>
  2. These products, by definition, do not meet all of the requirements for
  a system. The ratings which they are given are based on meeting the subset
  of the requirements pertaining to the area of protection. The ratings given
  are all "D" because of the incompleteness, but the ratings show area compliance
  in the following manner:
  </p><blockquote>
    a. D =&gt; Does not meet C1 (DAC, OR, I&amp;A, AUD).
    <p>
    b. D1 =&gt; Meets C1 for the area (DAC, I&amp;A).
    </p><p>
    c. D2 =&gt; Meets C2 for the area (DAC, OR, I&amp;A, AUD).
    </p><p>
    d. D3 =&gt; Meets B3 for the area (DAC, AUD).
  </p></blockquote>
  <p>
  3. In order to have the subsystems have meaning in the total system the necessary
  support from other areas must be present. The basic dependencies are:
  </p><blockquote>
    a. DAC requires I&amp;A for ID purposes and AUD (at D2) to track control
    permissions.
    <p>
    b. OR has no dependencies.
    </p><p>
    c. I&amp;A requires DAC (or domain isolation) and AUD (at D2).
    </p><p>
    d. AUD requires I&amp;A and DAC (or domain isolation).
  </p></blockquote>
  <p>
  4. The integration of the total system, with its subsystems, needs to be
  viewed to determine the total level of trust which can be granted.
</p></blockquote>
<p>
B. Required Features
</p><blockquote>
  1. DAC D1 Requirements:
  <blockquote>
    a. Access must be controlled by group or individual.
    <p>
    b. Means must be available to specify authorizations for all users and groups
    with access.
    </p><p>
    c. Mediation prior to access must allow (or disallow) the access.
  </p></blockquote>
  <p>
  2. DAC D2 Requirements:
  </p><blockquote>
    d. Access must be able to include/exclude at the individual user level.
    <p>
    e. Control permission must be limited to authorized users.
    </p><p>
    f. Passing of control permission must be limited to authorized users.
    </p><p>
    g. All access to objects must be denied unless explicit authorizing action
    is taken.
  </p></blockquote>
  <p>
  3. DAC D3 Requirements:
  </p><blockquote>
    h. DAC must allow users to specify the list of individuals or groups with
    access to each object and what access modes are allowed. (Implies ACLs.)
  </blockquote>
  <p>
  4. OR D2 Requirement::
  </p><blockquote>
    a. Before allowing a new user to have read access a previously used storage
    device, the storage area must be overwritten with meaningless bit patterns.
  </blockquote>
  <p>
  5. I&amp;A D1 Requirements:
  </p><blockquote>
    a. Users must identify themselves prior to use of the system.
    <p>
    b. Identification must be authenticated by a protected means (e.g. password).
    </p><p>
    c. Authentication data must be safeguarded from unauthorized users.
    </p><p>
    d. Authenticated identities must be passed to the protected system.
  </p></blockquote>
  <p>
  6. I&amp;I D2 Requirements:
  </p><blockquote>
    e. Identification must be to the individual level.
    <p>
    f. Audit records must be generated for successful and failed logins.
  </p></blockquote>
  <p>
  7. AUD D2 Requirements:
  </p><blockquote>
    a. The system must be able to call the AUD subsystem and hand off audit
    parameters.
    <p>
    b. The AUD subsystem must format the data and route to storage or an audit
    logger.
    </p><p>
    c. Audit data must be protected from unauthorized modification.
    </p><p>
    d. Access by authorized individuals must be through the AUD subsystem.
    </p><p>
    e. All security relevant events must be recorded.
    </p><p>
    f. For each event, UserID, date/time, event type, and success/failure must
    be recorded.
    </p><p>
    g. The AUD subsystem must be able to perform selection of audit data based
    on UserID.
  </p></blockquote>
  <p>
  8. AUD D3 Requirement:
  </p><blockquote>
    h. The AUD subsystem must be able to accept threshold values and immediately
    notify the security administrator of imminent security violation.
  </blockquote>
</blockquote>
<p>
C. Assurance Requirements
</p><blockquote>
  1. Architecture D1 Requirement (to be met by all D1 subsystems):
  <blockquote>
    a. Protection of the subsystem's mechanism and data must be protected from
    external interference and tampering.
  </blockquote>
  <p>
  2. Architecture D2 Requirement (to be met by all D2 subsystems):
  </p><blockquote>
    b. Operations of the subsystem must be nonbypassable and perform on all subjects
    and objects controlled by the subsystem.
  </blockquote>
  <p>
  3. Integrity D1 Requirement (to be met by all D1 subsystems):
  </p><blockquote>
    a. The capability must exist to validate the correct operation of the hardware
    and firmware elements of the subsystem even if they are part of the protected
    system.
  </blockquote>
  <p>
  4. Test D1 Requirements (to be met by all D1 subsystems):
  </p><blockquote>
    a. Subsystem must perform as documented.
    <p>
    b. Subsystem must not introduce new flaws to the system.
    </p><p>
    c. There must be no obvious ways to bypass or defeat the security features.
  </p></blockquote>
  <p>
  5. Test D2 Requirement (to be met by all D2 subsystems):
  </p><blockquote>
    d. Testing must include a search for obvious flaws which affect the security
    features.
  </blockquote>
</blockquote>
<p>
D. Documentation Requirements
</p><blockquote>
  5. Security Features User's Guide D1 Requirement (to be met by all D1
  subsystems):
  <blockquote>
    a. There must be clear, comprehensive, and centralized documentation describing
    the protection mechanisms of the subsystem and their use.
  </blockquote>
  <p>
  6. Trusted Facility Manual (TFM) D1 Requirements (to be met by all D1
  subsystems):
  </p><blockquote>
    a. TFM must give cautions about functions and privileges provided by the
    subsystem.
    <p>
    b. TFM must give precise directions for integration of the subsystem into
    the system.
  </p></blockquote>
  <p>
  7. Trusted Facility Manual (TFM) D2 Requirements (to be met by all D2
  subsystems):
  </p><blockquote>
    c. TFM must give full details about using the audit trail and the full formats
    and structure of the audit records.
  </blockquote>
  <p>
  8. Test Documentation D1 Requirements (to be met by all D1 subsystems):
  </p><blockquote>
    a. Test documentation must include the test plan, test procedures and test
    report for the security mechanisms.
  </blockquote>
  <p>
  9. Design Documentation D1 Requirements (to be met by all D1 subsystems):
  </p><blockquote>
    a. Contain threats protected against.
    <p>
    b. Describe Philosophy of Protection (PoP).
    </p><p>
    c. Explain implementation of the PoP.
    </p><p>
    d. Modular designs must describe the interfaces.
    </p><p>
    e. Specify the interactions with the system and other subsystems.
  </p></blockquote>
</blockquote>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-011 Version-1
</p><p>
<strong>Title:</strong> Trusted Network Interpretation Environments Guideline
</p><p>
<strong>Color:</strong> Red II
</p><p>
<strong>Date:</strong> 1 AUG 90
</p><p>
<strong>Highlights</strong>
</p><p>
1. This document is in support of the Trusted Network Interpretation [TNI]
(NCSC-TG-005). Its purpose is to show how to use the interpretations and
concepts found in the TNI and to mend the flaws which have surfaced in the
TNI. It is the first of a series (within the Rainbow Series) of trusted network
related documents, the Trusted Network Technology (TNT) set.
</p><p>
2. The areas where the TNI fell down revolve around the following set of
revised definitions which were not used consistently in, or were not properly
brought forth by, the TNI:
</p><blockquote>
  a. Network Trusted Computing Base (NTCB): The totality of protection mechanisms
  within a network system.
  <p>
  b. NTCB Partition: The totality of protection mechanisms within a single
  network subsystem.
  </p><p>
  c. Component: An individual physical unit that does not provide a complete
  set of end-user services.
  </p><p>
  d. System/Subsystem: A collection of hardware, software, and firmware configured
  to collect, create, communicate, disseminate, process, store, and/or control
  data and information.
  </p><p>
  e. NCSC-evaluation: The process in which the NCSC determines whether a COTS
  product satisfies the Orange Book.
  </p><p>
  f. Certification: The technical evaluation of a system's security features
  that establishes the extent to which a particular system's design and
  implementation meet a set of specified security requirements.
  </p><p>
  g. Accreditation: The managerial authorization and approval granted to a
  system or network to process sensitive data in an operational environment.
</p></blockquote>
<p>
3. Network Security Architecture and Design (NSAD):
</p><blockquote>
  a. An NSAD is required for each system. Each subordinate subsystem must have
  an NSAD which conforms to the system NSAD.
  <p>
  b. If the network is composed of previously accredited systems, the NSAD
  must include Memorandum of Agreement (MOA[s]) between the systems' accreditors,
  or a Memorandum of Record (MOR) if each of the systems had the same accreditor,
  covering the connection requirements for continued accreditation.
  </p><p>
  c. NSAD documents the security services for the network including the network
  configuration and allocation of security services to network components.
  </p><p>
  d. Suggested contents include:
  </p><blockquote>
    1) General description of information transmitted, by subsystem.
    <p>
    2) Summary description of trusted behavior, by subsystem.
    </p><p>
    3) Details of the system security plan and responsibilities.
    </p><p>
    4) Overall network security policy.
    </p><p>
    5) Additional security training and responsibilities.
    </p><p>
    6) Specification of security parameters transmitted.
    </p><p>
    7) Security details relevant to information exchange.
    </p><p>
    8) Description of the user community, including lowest clearance.
    </p><p>
    9) Considerations for dial-up connections, including safeguards.
    </p><p>
    10) Security protections provided by data communications, local and network.
    </p><p>
    11) Audited data and audit trail division of labor.
    </p><p>
    12) Information security procedures provided by subsystems, including:
    </p><blockquote>
      a) Types of processing; file query, individual user, general processing,
      etc.
      <p>
      b) Modes of operation.
      </p><p>
      c) Sensitivity levels processed.
    </p></blockquote>
  </blockquote>
</blockquote>
<p>
4. Risk Assessment:
</p><blockquote>
  a. Determine the system security mode of operations.
  <p>
  b. Determine minimum user clearance or authorization rating (RMIN).
  </p><p>
  c. Determine maximum data sensitivity rating (RMAX).
  </p><p>
  d. Determine Risk Index (RMAX - RMIN).
  </p><p>
  e. Determine security evaluation class for computer-based controls; C1, B3,
  etc.
  </p><p>
  f. Determine adjustments to the evaluation class required.
</p></blockquote>
<p>
5. Section 5.4.3 contains a step-by-step questionnaire for identifying needed
security services functionality. (It has not been repeated here.)
</p><p>
6. Network Security Services
</p><pre><b>   Network Security Service         Criterion       Evaluation Range</b>
<b>____________________________________________________________________</b>

<b>Communications Integrity</b>
<b>   Continuity of Operations         Functionality   None | Present</b>
<b>                                    Strength        None - Good</b>
<b>                                    Assurance       None - Good</b>
<b>   Communications Field Integrity   Functionality   None - Good</b>
<b>                                    Strength        None - Good</b>
<b>                                    Assurance       None - Good</b>
<b>   Non-Repudiation                  Functionality   None | Present</b>
<b>                                    Strength        None - Good</b>
<b>                                    Assurance       None - Good</b>
<b>Denial of Service</b>
<b>   Authentication                   Functionality   None - Good</b>
<b>                                    Strength        None - Good</b>
<b>                                    Assurance       None - Good</b>
<b>   Protocol Based Protection        Functionality   None - Good</b>
<b>                                    Strength        None - Good</b>
<b>                                    Assurance       None - Good</b>
<b>   Network Management               Functionality   None | Present</b>
<b>                                    Strength        None - Good</b>
<b>                                    Assurance       None - Good</b>

<b>Compromise Protection</b>
<b>   Data Confidentiality             Functionality   None | Present</b>
<b>                                    Strength        Sensitivity Level</b>
<b>                                    Assurance       None - Good</b>
<b>   Traffic Flow Confidentiality     Functionality   None | Present</b>
<b>                                    Strength        Sensitivity Level</b>
<b>                                    Assurance       None - Good</b>
<b>   Selective Routing                Functionality   None | Present</b>
<b>                                    Strength        None - Good</b>
<b>                                    Assurance       None - Good</b>
<b>____________________________________________________________________</b>

</pre>
<p>
7. Risk Index, Assurance Rating, and Minimum Evaluation Class
</p><pre><b>Risk Index    Strength of Mechanism   Assurance Rating   Evaluation Class</b>
<b>_________________________________________________________________________</b>

<b>  0                  None                   None                 D</b>
<b>  1                  Minimum                Minimum              C1</b>
<b>  2                  Fair                   Fair                 C2</b>
<b>  &gt;2                 Good                   Good                 B2</b>
<b>_________________________________________________________________________</b>

 <br wp="br1"><hr>
</pre>
<p>
<strong>Document Number:</strong> NCSC-TG-013 Version-1
</p><p>
<strong>Title:</strong> Rating Maintenance Phase Program Document
</p><p>
<strong>Color:</strong> Hot Pink
</p><p>
<strong>Date:</strong> 23 JUN 89
</p><p>
<strong>Highlights</strong>: The Rating Maintenance Phase (RAMP) Program
is intended to simplify the continuance of ratings for a vendor's products
after evaluation. This would allow ongoing versions of the Operating System
software and hardware suites to be listed on the Evaluated Product List (EPL)
without the need for reevaluation. The following is a summary of RAMP
requirements which must be met by the vendor in order to participate in the
RAMP Program.
</p><p>
1. Preevaluation Phase
</p><blockquote>
  a. Vendor establishes an intent to participate in RAMP in the product's
  evaluation package.
</blockquote>
<p>
2. Vendor Assistance Phase/Design Analysis Phase
</p><blockquote>
  a. The vendor must identify and maintain a responsible corporate officer.
  <p>
  b. The vendor must complete training of one or more Vendor Security Analysts
  (VSAs) and provide Dockmaster access. A lead VSA must be identified, if more
  than one VSA.
  </p><p>
  c. NCSC will provide training for the VSAs.
  </p><p>
  d. The vendor must develop an NCSC approved Rating Maintenance Plan (RM-Plan)
  prior to its implementation and implement the RM-Plan prior to start of
  development on the version to supersede the evaluated product.
  </p><p>
  e. NCSC will review for purposes of approval the PM-Plan.
</p></blockquote>
<p>
3. Evaluation Phase
</p><blockquote>
  a. The vendor must maintain a responsible corporate officer.
  <p>
  b. The vendor must maintain one or more Vendor Security Analysts (VSAs) and
  provide Dockmaster access. A lead VSA must be identified, if more than one
  VSA.
  </p><p>
  c. NCSC will provide training for the VSAs.
  </p><p>
  d. The vendor must complete his own RAMP audit to ensure that security feature
  functionality and assurances are being maintained by adherence to the approved
  RM-Plan.
  </p><p>
  e. The NCSC evaluation team will review the results of the vendor audit to
  ensure the vendor's RAMP process follows the approved RM-Plan procedures.
  </p><p>
  f. NCSC assigns A Technical Point of Contact (TPOC) and a Business Point
  of Contact (BPOC) before completion of the evaluation phase.
</p></blockquote>
<p>
4. Rating Maintenance Phase
</p><blockquote>
  a. The vendor must maintain a responsible corporate officer.
  <p>
  b. The vendor must maintain one or more Vendor Security Analysts (VSAs) and
  provide Dockmaster access. A lead VSA must be identified, if more than one
  VSA.
  </p><p>
  c. NCSC will provide training for the VSAs.
  </p><p>
  d. NCSC maintains a BPOC and a TPOC.
  </p><p>
  e. The vendor must provide product instruction to the TPOC as needed throughout
  RAMP.
  </p><p>
  f. The vendor will provide informal quarterly status reports via Dockmaster.
  </p><p>
  g. The vendor must conduct at least one RAMP audit per RAMP cycle.
  </p><p>
  h. TPOC will review the vendor's RAMP audit results.
  </p><p>
  i. The vendor will submit the following documents for each version of the
  evaluated product for which the vendor desires to have the rating maintained
  via RAMP:
  </p><blockquote>
    1) Rating Maintenance Report (RMP)
    <p>
    2) Rating Maintenance Plan (RM-Plan) with change bars
    </p><p>
    3) Final Evaluation Report (FER) with change bars
    </p><p>
    4) FER with integrated changes
    </p><p>
    5) Proposed Product description for EPL
  </p></blockquote>
  <p>
  j. NCSC will review the vendor's documents for the purpose of extending the
  rating to the specific release and placement on the EPL.
  </p><p>
  k. The vendor's RAMP process is subject to Interim Reviews and Aperiodic
  Reviews by the NCSC to ensure the adherence to the vendor's approved RM-Plan
  procedures.
</p></blockquote>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-014 Version-1
</p><p>
<strong>Title:</strong> Guidelines for Formal Verification Systems
</p><p>
<strong>Color:</strong> Purple
</p><p>
<strong>Date:</strong> 1 APR 89
</p><p>
<strong>Highlights </strong>Formal specification and verification systems
used in the development of systems for submittal to the NCSC for evaluation
at the A1 level are to be selected from the Endorsed Tools List (ETL). These
are the procedures and requirements for candidates for the ETL.
</p><p>
1. Major Steps Leading To Endorsement And ETL Listing:
</p><blockquote>
  a. Developer submits a request for evaluation to the NCSC Committee Chairperson.
  <p>
  b. The Committee meets to see if the verification system has something new
  to offer.
  </p><p>
  c. On favorable result, an evaluation team is formed and evaluation starts.
  </p><p>
  d. On completion of evaluation, a Technical Assessment Report (TAR) is written.
  </p><p>
  e. The Committee reviews the TAR and makes recommendations on endorsement.
  </p><p>
  f. The Committee Chairperson Approves/disapproves endorsement.
  </p><p>
  g. If approved, an ETL entry is issued for the verification system.
  </p><p>
  h. A TAR is issued on the verification system.
</p></blockquote>
<p>
2. Major Steps Leading To Endorsement And ETL Listing For A Revised System:
</p><blockquote>
  a. Vendor submits the Vendor Report (VR) and other materials to the Chairperson.
  <p>
  b. An evaluation team is formed to review the VR.
  </p><p>
  c. The team adds comments and submits them to the Committee.
  </p><p>
  d. The vendor defends the VR to the Committee.
  </p><p>
  e. As Above.
</p></blockquote>
<p>
3. Major Steps Leading To The Removal Of A Verification System From The ETL:
</p><blockquote>
  a. The Committee questions the endorsement of a verification system on the
  ETL.
  <p>
  b. As Above.
</p></blockquote>
<p>
4. The components of the verification system include:
</p><blockquote>
  a. A mathematical specification language that allows the use of correctness
  conditions.
  <p>
  b. A specification processor that interprets the specification and generates
  conjectures.
  </p><p>
  c. A Reasoning mechanism that interprets the conjectures and checks the proof.
</p></blockquote>
<p>
5. The four technical factors for the verification system are:
</p><blockquote>
  a. Methodology.
  <p>
  b. Features.
  </p><p>
  c. Assurance.
  </p><p>
  d. Documentation.
</p></blockquote>
<p>
6. The methodology must consist of a set of propositions used as rules for
performing formal verification in the system. The methodology must have a
sound logical basis.
</p><p>
7. Features include:
</p><blockquote>
  a. Specification Language.
  <p>
  b. Specification Processing.
  </p><p>
  c. Reasoning Mechanism.
  </p><p>
  d. User Interface.
  </p><p>
  e. Hardware Support.
</p></blockquote>
<p>
8. Assurance is provided by:
</p><blockquote>
  a. Sound Basis.
  <p>
  b. Correctness.
  </p><p>
  c. Predictability.
  </p><p>
  d. Previous Use.
  </p><p>
  e. Error Recovery.
  </p><p>
  f. Software Engineering.
  </p><p>
  g. Logical Theory.
  </p><p>
  h. Machine Independence.
  </p><p>
  i. Configuration Management.
  </p><p>
  j. Support and Maintenance.
  </p><p>
  k. Testing.
</p></blockquote>
<p>
9. Required Documentation:
</p><blockquote>
  a. Informal Justification.
  <p>
  b. Formal Definition.
  </p><p>
  c. Explanation of Methodology.
  </p><p>
  d. CM Plan.
  </p><p>
  e. CM Evidence.
  </p><p>
  f. Source Code.
  </p><p>
  g. Test Documentation.
  </p><p>
  h. User's Guide.
  </p><p>
  i. Reference Manuals.
  </p><p>
  j. Facilities Manuals.
  </p><p>
  k. Vendor Report.
  </p><p>
  l. Worked Examples.
</p></blockquote>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-015 Version 1
</p><p>
<strong>Title:</strong> A Guide to Understanding Trusted Facility Management
</p><p>
<strong>Color:</strong> Brown
</p><p>
<strong>Date:</strong> 18 OCT 89
</p><p>
<strong>Highlights</strong>
</p><p>
1. At B2 and B3 levels the ISSO functions must be differentiated to allow
for compartmentalization of functionality to limit the damage which can be
caused by error and malicious intent. The required separations are:
</p><blockquote>
  a. For B2, the Administrator and Operator functions.
  <p>
  b. For B3, the security-relevant and non-security-relevant Administrator
  functions.
  </p><p>
  c. For all levels, the separations should be in place as possible (even if
  not required).
</p></blockquote>
<p>
2. The duties of the ISSO can be differentiated into the following roles:
</p><blockquote>
  a. Security Administrator:
  <blockquote>
    1) Setting the parameters for the Login/Logout mechanisms.
    <p>
    2) Setting the authentication parameters.
    </p><p>
    3) Defining the user account and registration profile.
    </p><p>
    4) Defining the group accounts and registration profile.
    </p><p>
    5) Defining and maintaining the Security Label (SL) map.
    </p><p>
    6) Setting SL limits and default SLs.
    </p><p>
    7) Labeling of imported unlabeled data and media.
    </p><p>
    8) Reclassifying objects.
    </p><p>
    9) Initializing DAC privileges.
    </p><p>
    10) Defining and maintaining group memberships.
    </p><p>
    11) Checking consistency of tables, installed TCB, allowed configuration,
    etc.
    </p><p>
    12) Terminating and deleting accounts.
    </p><p>
    13) Responding to real-time alarms.
    </p><p>
    14) Destroying errant processes.
  </p></blockquote>
  <p>
  b. Secure Operator:
  </p><blockquote>
    1) Booting and shutting down the system.
    <p>
    2) Locating damaged user files and volumes.
    </p><p>
    3) Performing routine maintenance of TCB databases.
    </p><p>
    4) Performing on-line tests.
    </p><p>
    5) Mounting/unmounting Labelled removable media on user request.
    </p><p>
    6) Importing/exporting Labelled data on user request.
  </p></blockquote>
  <p>
  c. Account Administrator:
  </p><blockquote>
    1) Installing and maintaining accounting files.
    <p>
    2) Turning system accounting on/off.
    </p><p>
    3) Running accounting/billing tools.
    </p><p>
    4) Enabling/disabling accounts at user request.
    </p><p>
    5) Establishing rates, prices, and policies.
    </p><p>
    6) Collecting system statistics on availability, configuration, and
    disk/CPU/memory.
    </p><p>
    7) Publishing revenue/costs reports.
  </p></blockquote>
  <p>
  d. Auditor:
  </p><blockquote>
    1) Selecting/deselecting audit features.
    <p>
    2) Managing the audit files.
    </p><p>
    3) Setting delays and randomization factors for covert channel handling.
    </p><p>
    4) Performing postprocessing on the audit data collected.
  </p></blockquote>
  <p>
  e. Operator:
  </p><blockquote>
    1) Performing user volume backups.
    <p>
    2) Performing system performance metering.
    </p><p>
    3) Adjusting resource quotas.
    </p><p>
    4) Responding to various non-security -relevant user requests.
  </p></blockquote>
  <p>
  f. System Programmer:
  </p><blockquote>
    1) Trusted system distribution.
    <p>
    2) Setting of system configuration parameters.
    </p><p>
    3) Analyzing of dumps.
    </p><p>
    4) Installing patches.
    </p><p>
    5) Recovering from system crashes.
    </p><p>
    6) Repairing damaged SLs.
  </p></blockquote>
</blockquote>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-017 Version-1
</p><p>
<strong>Title:</strong> Identification and Authentication
</p><p>
<strong>Color:</strong> Light Blue
</p><p>
<strong>Date:</strong> SEP 91
</p><p>
<strong>Highlights</strong>
</p><p>
1. Identification and Authentication (I&amp;A) are often referred to as login.
The valid identification of the user is critical to the effective execution
of access controls.
</p><p>
2. There are three types of Authentication:
</p><blockquote>
  a. Authentication by Knowledge: (Something you know)
  <blockquote>
    1) The classic password login.
    <p>
    2) Also pass-phrases and entry quizzes.
    </p><p>
    3) Cannot be stolen or lost but can be readily copied.
    </p><p>
    4) Implementation and data storage are relatively straight-forward.
  </p></blockquote>
  <p>
  b. Authentication by Ownership: (Something you have)
  </p><blockquote>
    1) Physical object based.
    <p>
    2) Relatively vulnerable to theft.
    </p><p>
    3) Difficult to copy (duplicate).
  </p></blockquote>
  <p>
  c. Authentication by Characteristic: (Something you are)
  </p><blockquote>
    1) Physical characteristics like retinal pattern, fingerprint, DNA, etc.
    <p>
    2) Relatively expensive and non-standard computer equipment.
    </p><p>
    3) Not foolproof.
  </p></blockquote>
</blockquote>
<p>
3. Authentication data must be protected from access by all but the System
Security Officer (SSO) and the SSO must not be allowed to see the plain-text
version of the data.
</p><p>
4. Implementation
</p><blockquote>
  a. No method is totally foolproof.
  <p>
  b. Lower levels - one method will suffice. (Passwords are well-understood.)
  </p><p>
  c. Higher levels - may require combinations of methods.
</p></blockquote>
<p>
5. I&amp;A Requirements by Class
</p><blockquote>
  a. C1 Requirements
  <blockquote>
    1) Users identify themselves.
    <p>
    2) TCB authenticate via protected means.
    </p><p>
    3) TCB protect authentication data.
    </p><p>
    4) Group identities allowed.
  </p></blockquote>
  <p>
  b. C2 Requirements (Additional)
  </p><blockquote>
    1) Uniquely identify each user.
    <p>
    2) Audit the I&amp;A action.
  </p></blockquote>
  <p>
  c. B1 Requirements (Additional)
  </p><blockquote>
    1) Authenticate clearance and authorizations.
    <p>
    2) Run MAC based on I&amp;A results.
  </p></blockquote>
  <p>
  d. B2 Requirements (Additional)
  </p><blockquote>
    1) Trusted path is required for I&amp;A.
    <p>
    2) Operator and administrator functions separate.
  </p></blockquote>
  <p>
  e. B3 Requirements (Additional)
  </p><blockquote>
    1) Trusted path expanded beyond just I&amp;A.
    <p>
    2) Lists for access and non-access by named individual and group for each
    object.
  </p></blockquote>
</blockquote>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-019 Version-1
</p><p>
<strong>Title:</strong> Trusted Product Evaluation Questionnaire
</p><p>
<strong>Color:</strong> Blue
</p><p>
<strong>Date:</strong> 16 OCT 89
</p><p>
<strong>Highlights</strong>
</p><p>
1. The questionnaire (185 questions) is to point developers into the proper
lines of thought while developing the system.
</p><p>
2. The questionnaire may be completed in an intelligent manner (not answering
meaningless questions, putting off answers until the appropriate phase, etc.)
</p><p>
3. The primary groupings for the questions are:
</p><blockquote>
  a. Subjects.
  <p>
  b. Objects.
  </p><p>
  c. Hardware Architecture.
  </p><p>
  d. Software.
  </p><p>
  e. Identification &amp; Authentication (I&amp;A).
  </p><p>
  f. Object Reuse.
  </p><p>
  g. Discretionary Access Control (DAC) Policy.
  </p><p>
  h. Labels.
  </p><p>
  i. Mandatory Access Control (MAC) Policy.
  </p><p>
  j. Integrity.
  </p><p>
  k. Audit.
  </p><p>
  l. Modeling and Analysis.
  </p><p>
  m. Testing.
  </p><p>
  n. Other Assurances.
  </p><p>
  o. Other Documentation.
</p></blockquote>
<p>
4. The questionnaire is only intended for use with operating systems, not
networks or subsystems.
</p><p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-020-A Version 1
</p><p>
<strong>Title:</strong> Access Control List (ACL) Features for UNIX
</p><p>
<strong>Color:</strong> Gray
</p><p>
<strong>Date:</strong> 18 AUG 89
</p><p>
<strong>Highlights: </strong>These are the recommendations for ACL features
for use with UNIX from the Trusted UNIX Working Group (TRUSIX) set up by
the NCSC.
</p><p>
1. ACLs are required for files, IPC objects, and UNIX system domain sockets.
</p><p>
2. Access modes required are Read, Write, and Execute.
</p><p>
3. Each ACL entry should specify permissions for a User XOR a Group.
</p><p>
4. ACL entry permissions are masked by the group class file protection bits.
</p><p>
5. Multiple concurrent groups, with group subsetting, should be supported.
</p><p>
6. Evaluation of ACLs should be (system-defined) from most specific to least
specific. Multiple group permissions should be ORed.
</p><p>
7. Existing mechanisms should remain as is and used as much as possible.
</p><p>
8. For new mechanisms which must be added, get/set operations should be used.
</p><p>
9. Named ACLs are not needed.
</p><p>
10. Default ACLs should be used along with a user-specifiable Use/No Use
mechanism.
</p><p>
11. Default ACLs for IPC objects are not recommended.
</p><p>
12. Default ACLs should be set by directory.
</p><p>
13. Protection bits are not affected when a new object with default ACL is
created unless an explicit mechanism is provided.
</p><p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-021 Version 1
</p><p>
<strong>Title:</strong> Trusted Database Management System Interpretation
</p><p>
<strong>Color:</strong> Lilac
</p><p>
<strong>Date:</strong> APR 91
</p><p>
<strong>Highlights: </strong>Because the Orange Book was developed with an
atomic system in mind, the advances in computer architectures and designs
has led to discontinuities in the interpretation of the Orange book requirements.
This document covers evaluation by parts and how to deal with the evaluation
of trusted systems which are composed of multiple pieces which individually
enforce policy.
</p><p>
1. Conditions for Evaluating by Parts
</p><blockquote>
  a. TCB subsets are identified.
  <p>
  b. System policy allocated to TCB subsets.
  </p><p>
  c. Each TCB subset includes all trusted subjects with respect to its policy.
  </p><p>
  d. Each TCB subset structures or architecture explicitly defined.
  </p><p>
  e. Each TCB subset occupies distinct subset-domains.
  </p><p>
  f. More primitive TCB subsets support the less primitive TCB subsets.
</p></blockquote>
<p>
2. Local/Global Requirements: Some requirements can be evaluated completely
within the TCB subset in question (Local), while others deal with interrelations
between TCB subsets (Global). The differentiated requirements follow:
</p><blockquote>
  a. Local Requirements
  <blockquote>
    1) Discretionary Access Control (DAC).
    <p>
    2) Object reuse.
    </p><p>
    3) Labels (except Subject Sensitivity Labels).
    </p><p>
    4) Mandatory Access Control (MAC).
    </p><p>
    5) System Architecture (except domains and address spaces).
    </p><p>
    6) System Integrity.
    </p><p>
    7) Configuration Management.
    </p><p>
    8) Security Features User's Guide (SFUG).
    </p><p>
    9) Design Documentation:
    </p><blockquote>
      a) Models.
      <p>
      b) DTLSs.
      </p><p>
      c) FTLSs.
      </p><p>
      d) Non-FTLS internals.
    </p></blockquote>
  </blockquote>
  <p>
  b. Global Requirements:
  </p><blockquote>
    1) Subject Sensitivity Labels.
    <p>
    2) Identification and Authentication.
    </p><p>
    3) Trusted Path.
    </p><p>
    4) Audit.
    </p><p>
    5) System Architecture:
    </p><blockquote>
      a) Domains of Execution.
      <p>
      b) Distinct Address Spaces.
    </p></blockquote>
    <p>
    6) Covert Channel Analysis.
    </p><p>
    7) Trusted Facility Management.
    </p><p>
    8) Security Testing.
    </p><p>
    9) Design Specification and Verification:
    </p><blockquote>
      a) Correspondence between System Policy and the set of TCB Subset Models.
      <p>
      b) Consistency of the TCB Interface between TCB Subset DTLSs.
      </p><p>
      c) Consistency of the TCB Interface between TCB Subset FTLSs.
    </p></blockquote>
    <p>
    10) Trusted Distribution.
    </p><p>
    11) Trusted Facility Manual.
    </p><p>
    12) Test Documentation.
    </p><p>
    13) Design Documentation (Other than the Local Requirements.)
  </p></blockquote>
</blockquote>
<p>
3. Interpretation of the Orange Book Requirements: Some of the requirements
from the Orange Book are interpreted for the context of this document. Those
that are reinterpreted are listed below. (Others which did not require
reinterpretation are not listed here.)
</p><blockquote>
  a. Security Policy - Labels
  <blockquote>
    General: DBMS objects which require labels include:
    <blockquote>
      a) Stored View Definitions
      <p>
      b) Files
      </p><p>
      c) Records
      </p><p>
      d) Relations
      </p><p>
      e) Tuples
      </p><p>
      f) Directories
      </p><p>
      g) Schemas
      </p><p>
      h) Indices
      </p><p>
      i) Data Dictionaries
      </p><p>
      j) Discretionary Authorization Tables
      </p><p>
      k) Recovery Logs
      </p><p>
      l) Transaction Logs
    </p></blockquote>
    <p>
    B2: Internal variables within the TCB which are not accessible to untrusted
    subjects do not need to be labelled, but care should be taken to ensure that
    internal variables are not usable for covert channels through the visible
    actions of the variables on the system behavior.
  </p></blockquote>
  <p>
  b. Accountability - Audit
  </p><blockquote>
    General: The emphasis in audit is to provide individual accountability of
    a user's actions. Access (or attempted access) to the protected objects should
    be audited. Internal actions within the TCB subset (DBMS) need not be audited.
    If there are multiple audit logs built correlation methodologies must also
    be present.
  </blockquote>
  <blockquote>
    C2: All mediated DAC accesses which are visible to the user must be auditable.
    <p>
    B1: All mediated DAC and MAC accesses which are visible to the user must
    be auditable.
  </p></blockquote>
  <p>
  c. Assurance - System Architecture: Each subset of the TCB must satisfy these
  system architecture requirements.
  </p><blockquote>
    C2: Separate execution domain that protects it from interference and tampering.
    <p>
    B2: User interface to be fully defined and all elements of the TCB be identified.
    </p><p>
    B2: Effectively use available hardware to separate the protection-critical
    portions.
  </p></blockquote>
  <p>
  d. Life Cycle Assurance - Design Specification and Verification
  </p><blockquote>
    B1: An informal argument must be given the the set of formal or informal
    policy models represents the security policy supported by the composite TCB.
    <p>
    B2: An informal argument must be given the the set of formal policy models
    represents the security policy supported by the composite TCB.
    </p><p>
    B2: Descriptive Top Level Specifications (DTLSs) must be maintained for each
    TCB subset.
    </p><p>
    B2: DTLS interface descriptions must cover the interfaces between TCB subsets
    as well as the external user interface.
    </p><p>
    B3: For a convincing argument that the DTLSs are consistent with the Model,
    MAC and DAC access checks at state transitions and visual checking for exceptions
    must be covered for each subset.
    </p><p>
    A1: Formal Top Level Specifications must be maintained for each TCB subset
    and must cover all facets of the policy (Mac, DAC, etc.)
    </p><p>
    A1: Each TCB subset must cover the user interface as well as the interfaces
    with other subsets. In addition, there should be a description of how to
    accurately describe the total TCB accurately.
    </p><p>
    A1: The FTLSs must be shown by formal and informal methods to be consistent
    with the Model; MAC and DAC access checks at state transitions and visual
    checking for exceptions must be covered for each subset.
  </p></blockquote>
  <p>
  e. Documentation - Design Documentation
  </p><blockquote>
    C1: Intermodular interfaces within and between TCB subsets must be described.
    <p>
    B1: The protection mechanisms for each TCB subset must be described and be
    shown to satisfy the model. The protection mechanisms must include the mechanisms
    which support the subset structure and separate subset-domains.
    </p><p>
    B2: Intermodular interfaces within and between TCB subsets must be described.
    </p><p>
    B2: DTLS interface descriptions must cover the interfaces between TCB subsets
    as well as the external user interface. In addition, there should be a
    description of how to accurately describe the total TCB accurately.
    </p><p>
    B2: Each TCB subset must how it implements the reference monitor concept
    within its own technical policy. In addition,there must be a documented informal
    argument that the the cooperative actions of the TCB subsets makes the TCB
    tamper resistant, non-bypassable, and correct.
    </p><p>
    B2: The documentation for each TCB subset must describe how the subset is
    structured to facilitate testing and enforce least privilege.
    </p><p>
    B3: Each TCB subset must be informally shown to be consistent with the DTLS.
    </p><p>
    A1: Each TCB subset must be informally shown to be consistent with the FTLS.
  </p></blockquote>
</blockquote>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-025 Version-2
</p><p>
(Supersedes: CSC-STD-005-85)
</p><p>
<strong>Title:</strong> Data Remanence in Automated Information Systems
</p><p>
<strong>Color:</strong> Green
</p><p>
<strong>Date:</strong> SEP 91
</p><p>
<strong>Highlights:</strong> This is an important topic but not covered by
the evaluation process. The document is guidance only and is not meant to
replace policy on the issue. The Degausser Product List (DPL) is included
in the NSA's Information Systems Security Products and Services Catalogue
available through the U.S. Government Printing Office.
</p><p>
1. Standard Clearing / Purging Methods
</p><blockquote>
  a. Overwrite: The media is rewritten one or more times with unclassified
  data and/or the bit patterns 0011 0101, 1100 1010, 1001 0111 (HEX: 35, BA,
  97) followed by unclassified data. This must be written to all memory locations
  and the number of repetitions required is based upon the various considerations
  listed. Disk exercisers have many advantages for overwrite including ignoring
  "bad" sectors and variable write frequencies.
  <p>
  b. Degaussing: The media is subjected to a magnetic field to randomly align
  the memory locations. The DPL lists tested degaussing products. Type I Degaussers
  are generally sufficient for Type I Media and Type II Degaussers are generally
  sufficient for Types I &amp; II Media. No Degaussers have been found to be
  sufficient for Type III Media. (If the degausser is malfunctioning or not
  used properly, the results will be unsatisfactory.)
  </p><p>
  c. Destruction: The recommended destruction methods will remove the risk
  of compromise of sensitive data but they do tend to be a bit hard on the
  media and can be a bit expensive.
  </p><blockquote>
    1) Smelting, Disintegration, or Pulverization
    <p>
    2) Incineration
    </p><p>
    3) Emery Wheel or Disk Sander
    </p><p>
    4) Concentrated Hydroiodic Acid (HI) for Gamma Ferric Oxide Disk Surfaces
    </p><p>
    5) Dubais Race A and Dubais Race B followed by Acetone
  </p></blockquote>
</blockquote>
<p>
2. Considerations which should be observed with regards to data remanence
include:
</p><blockquote>
  a. Destination of Released Media
  <p>
  b. Effects of Heat and Age
  </p><p>
  c. Equipment Failures
  </p><p>
  d. Storage Device Segments not Receptive to Overwrite
  </p><p>
  e. Overwrite Software Suitability for Clearing and Purging
  </p><p>
  f. Contractual Obligations
  </p><p>
  g. Maintenance
  </p><p>
  h. Data Sensitivity
  </p><p>
  i. Degaussing Failures
</p></blockquote>
<p>
3. Approved Procedures for Various Media:
</p><blockquote>
  a. Magnetic tape: Clear - Type I Degausser; Purge - appropriate Degausser.
  <p>
  b. Hard Disks: Overwriting and degaussing for Clear and Purge.
  </p><p>
  c. Magnetic Drums: Overwriting and degaussing for Clear and Purge. Degaussing
  by approved hand held magnet.
  </p><p>
  d. Floppy Disks/Cards: Overwriting for Clearing. Type I Degausser for Purge.
  </p><p>
  e. Magnetic Core: Overwriting and Type I Degaussing for Clear and Purge.
  </p><p>
  f. Plated Wire Memory: Overwriting and Type I Degaussing for Clear and Purge.
  </p><p>
  g. Thin Film Memory: Overwriting and Type I Degaussing for Clear and Purge.
  </p><p>
  h. Bubble Memory: Overwriting and Type I Degaussing for Clear and Purge.
  </p><p>
  i. RAM: Overwrite and Removal of Power for Clear and Purge.
  </p><p>
  j. ROM: Destruction.
  </p><p>
  k. UVPROM: UV.
  </p><p>
  l. EEPROM: Overwriting for Clear or Purge.
  </p><p>
  m. Optical Disks: Destruction.
  </p><p>
  n. Ferromagnetic RAM: No Standards yet set. Overwrite should do for Clear.
</p></blockquote>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> NCSC-TG-026 Version 1
</p><p>
<strong>Title:</strong> Security Features User's Guide
</p><p>
<strong>Color:</strong> Fluorescent Orange
</p><p>
<strong>Date:</strong> SEP 91
</p><p>
<strong>Highlights: </strong>"A single summary, chapter, or manual in user
documentation shall describe the protection mechanisms provided by the TCB,
guidelines on their use, and how they interact with one another." Orange
Book.
</p><p>
1. The user is the audience (may or may not be a computer person.)
</p><p>
2. A separate manual is usually the best choice, especially in the higher
classes.
</p><p>
3. Presentation:
</p><blockquote>
  a. Information needed by the user to securely operate the system.
  <p>
  b. Explain the user's role in the security of the system.
</p></blockquote>
<p>
4. Content: Organized either feature-oriented or task-based. (Feature-oriented
preferred.)
</p><p>
a. Example Task-Oriented Security Features User's Guide (SFUG)
</p><p>
1. Introduction to the SFUG
</p><p>
2. System Security Overview
</p><blockquote>
  2.1 System Philosophy of Protection
  <p>
  2.2 Definition of Terms and Conditions
  </p><p>
  2.3 The Information System Security Officer (ISSO)
  </p><p>
  2.4 User Security Responsibilities
</p></blockquote>
<p>
3. Security-Related Commands for Users
</p><p>
3.1 System Access
</p><blockquote>
  3.1.1 Session Initiation
  <p>
  3.1.2 Changing the Session Profile
  </p><p>
  3.1.3 Changing the User Profile
  </p><p>
  3.1.4 Potential Access Problems and Solutions
</p></blockquote>
<p>
3.2 Access Control facilities
</p><p>
3.3 Protecting Removable Objects
</p><p>
3.4 Logging Security-Relevant Events
</p><blockquote>
  b. Example Feature-Oriented Security Features User's Guide (SFUG)
  <blockquote>
    1. Introduction to the SFUG
    <p>
    2. System Security Overview
    </p><blockquote>
      2.1 System Philosophy of Protection
      <p>
      2.2 Definition of Terms and Conditions
      </p><p>
      2.3 The Information System Security Officer (ISSO)
      </p><p>
      2.4 User Security Responsibilities
    </p></blockquote>
    <p>
    3. Security Related Commands for Users
  </p></blockquote>
  <blockquote>
    <blockquote>
      3.1 User Identification and Authentication
      <blockquote>
	3.1.1 Trusted Path
	<p>
	3.1.2 Logging On to the System
	</p><p>
	3.1.3 Password Considerations
	</p><p>
	3.1.4 Changing Group Memberships
	</p><p>
	3.1.5 Changing Current MAC Authorizations
	</p><p>
	3.1.6 Logging Off the System
	</p><p>
	3.1.7 I&amp;A Errors and Their Causes
      </p></blockquote>
      <p>
      3.2 Discretionary Access Control Facilities
      </p><blockquote>
	3.2.1 Setting DAC on Named Objects
	<p>
	3.2.2 Default DAC Protection
	</p><p>
	3.2.3 DAC Groups
	</p><p>
	3.2.4 DAC Error and Their Causes
      </p></blockquote>
      <p>
      3.3 Mandatory Access Control Facilities
      </p><blockquote>
	3.3.1 Printing Labelled Objects
	<p>
	3.3.2 Accessing Single-Level Devices
	</p><p>
	3.3.3 Accessing Multilevel Devices
	</p><p>
	3.3.4 Downgrading Labelled Objects
	</p><p>
	3.3.5 MAC Errors and Their Causes
      </p></blockquote>
      <p>
      3.4 Object Manipulation Facilities
      </p><blockquote>
	3.4.1 Object Creation, Reuse, and Deletion
	<p>
	3.4.2 Importing Machine-Readable Objects
	</p><p>
	3.4.3 Exporting Machine-Readable Objects
	</p><p>
	3.4.4 Determining the Properties of Objects
	</p><p>
	3.4.5 Object Manipulation Errors and Their Causes
      </p></blockquote>
    </blockquote>
  </blockquote>
</blockquote>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> C Technical Report 79-91
</p><p>
<strong>Title:</strong> Integrity in Automated Information Systems
</p><p>
<strong>Color: </strong>Yellow<strong></strong>
</p><p>
<strong>Date:</strong> SEP 91
</p><p>
<strong>Highlights: </strong>Integrity is the "other half" of COMPUSEC. The
primary thrust of the Orange Book and the rest of the Rainbow Series is
confidentiality of sensitive data. Integrity is concerned with protecting
the data and the system from improper modification.
</p><p>
1. Integrity Goals
</p><blockquote>
  a. Preventing unauthorized users from making modifications.
  <p>
  b. Maintaining internal and external consistency.
  </p><p>
  c. Preventing authorized users from making improper modifications.
</p></blockquote>
<p>
2. Integrity Principles
</p><blockquote>
  a. Identity
  <p>
  b. Constraints
  </p><p>
  c. Obligation
  </p><p>
  d. Accountability
  </p><p>
  e. Authorization
  </p><p>
  f. Least Privilege
  </p><p>
  g. Separation
  </p><p>
  h. Monitoring
  </p><p>
  i. Alarms
  </p><p>
  j. Non-Reversible Actions
  </p><p>
  k. Reversible Actions
  </p><p>
  l. Redundancy
  </p><p>
  m. Minimization
  </p><blockquote>
    1) Variable Minimization
    <p>
    2) Data Minimization
    </p><p>
    3) Target Value Minimization
    </p><p>
    4) Access Time Minimization
  </p></blockquote>
  <p>
  n. Routine Variation
  </p><p>
  o. Elimination of Concealment
  </p><p>
  p. Access Deterrence
</p></blockquote>
<p>
3. Integrity Policies and Mechanisms
</p><blockquote>
  a. Policy of Identification and Authentication
  <blockquote>
    1) Policy of User Identification and Authentication
    <p>
    2) Policy of Originating Device Authentication
    </p><p>
    3) Policy of Object Identification and Authentication
  </p></blockquote>
  <p>
  b. Policy of Authorized Actions
  </p><blockquote>
    1) Policy of Conditional Authorization
    <blockquote>
      a) Conditional Enabling
      <p>
      b) Value Checks
    </p></blockquote>
    <p>
    2) Policy of Separation of Duties
    </p><blockquote>
      a) Rotation of Duties
      <p>
      b) Supervisory Control
      </p><p>
      c) N-Person Control
      </p><p>
      d) Process Sequencing
    </p></blockquote>
  </blockquote>
  <p>
  c. Policy of Separation of Resources
  </p><blockquote>
    1) Policy of Address Space Separation
    <blockquote>
      a) Descriptors
      <p>
      b) Separation of Name Spaces
    </p></blockquote>
    <p>
    2) Policy of Encapsulation
    </p><blockquote>
      a) Abstract Data Types
      <p>
      b) Strong Typing
      </p><p>
      c) Domains
      </p><p>
      d) Actors
      </p><p>
      e) Message Passing
      </p><p>
      f) Data Movement Primitives
      </p><p>
      g) Gates
    </p></blockquote>
    <p>
    3) Policy of Access Control
    </p><blockquote>
      a) Capabilities
      <p>
      b) Access Control Lists
      </p><p>
      c) Access Control Triples
      </p><p>
      d) Labels
    </p></blockquote>
  </blockquote>
  <p>
  d. Policy of Fault Tolerance
  </p><p>
  1) Policy of Summary Integrity Checks
  </p><blockquote>
    a) Transmittal Lists
    <p>
    b) Checksums
    </p><p>
    c) Cryptographic Checksums
    </p><p>
    d) Chained Checksums
  </p></blockquote>
  <p>
  2) Policy of Error Correction
  </p><blockquote>
    a) Duplication Protocols
    <p>
    b) Handshaking Protocols
    </p><p>
    c) Error-Correcting Codes
  </p></blockquote>
</blockquote>
<p>
4. Separation Policies
</p><blockquote>
  a. Hierarchical Levels
  <p>
  b. Non-Hierarchical Categories
  </p><p>
  c. Access Control Triples
  </p><p>
  d. Protected Subsystems
  </p><p>
  e. Digital Signatures / Encryption
  </p><p>
  f. Combination of Capabilities and ACLs
</p></blockquote>
<p>
5. General integrity Principles
</p><blockquote>
  a. Traditional Design Principles
  <blockquote>
    1) Economy of Mechanism
    <p>
    2) Fail-Safe Defaults
    </p><p>
    3) Complete Mediation
    </p><p>
    4) Open Design
    </p><p>
    5) Separation of Privilege
    </p><p>
    6) Least Privilege
    </p><p>
    7) Least Common Mechanism
    </p><p>
    8) Psychological Acceptability
  </p></blockquote>
  <p>
  b. Additional Design Principles
  </p><blockquote>
    1) Work Factor
    <p>
    2) Compromise Recording
  </p></blockquote>
  <p>
  c. Functional Control Levels
  </p><blockquote>
    1) Unprotected Systems
    <p>
    2) All-Or-Nothing Systems
    </p><p>
    3) Controlled Sharing
    </p><p>
    4) User-Programmed Sharing Controls
    </p><p>
    5) Labelling Information
  </p></blockquote>
</blockquote>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> NTISSAM COMPUSEC/1-87
</p><p>
<strong>Title:</strong> Advisory Memorandum on Office Automation Security
</p><p>
<strong>Date:</strong> 16 JAN 87
</p><p>
<strong>Highlights</strong>
</p><p>
User Responsibilities
</p><p>
1. Magnetic media must be protected at the level of the most restrictive
data which has been written to the media.
</p><p>
2. Removable magnetic media should be used when data at several levels is
to be processed on a single system.
</p><p>
3. Each user of the system should:
</p><blockquote>
  a. Know who the security officer for the system is.
  <p>
  b. Be aware of, and follow, the security guidelines for the system.
  </p><p>
  c. Report compromise and/or theft of data and equipment.
  </p><p>
  d. Only use authorized software.
</p></blockquote>
<p>
4. Physical access to the system should be limited to those individuals which
have need-to-know and authorization for all data stored and/or being processed
on the system.
</p><p>
5. Screens, printers, etc. should be oriented away from doors and windows.
</p><p>
6. Running systems should not be left unattended, especially with output
visible.
</p><p>
7. Electronic labels should not be trusted except in NCSC evaluated B1 (or
higher) systems.
</p><p>
8. Physical media should be physically marked.
</p><p>
9. Printers should:
</p><blockquote>
  a. Not be left unattended when printing.
  <p>
  b. Have output removed at the earliest possible time.
  </p><p>
  c. Have outputs marked immediately.
  </p><p>
  d. Have ribbons removed and protected at the level of the data printed.
</p></blockquote>
<p>
10. Remember TEMPEST.
</p><p>
11. Protect the hardware and media from food, drink, smoke, etc.
</p><p>
12. Manually review all output (intended for below the maximum level) to
ensure proper classification.
</p><p>
13. To operate the system at a level lower than currently being used:
</p><blockquote>
  a. Remove all media.
  <p>
  b. Power off the system for at least one minute.
  </p><p>
  c. Reboot using a copy of the operating system at the proper level.
  </p><p>
  d. Reload applications software at the proper level.
</p></blockquote>
<p>
14. Checklists for startup, shutdown, and downgrade should be kept near the
system and used for the operations.
</p><p>
15. Manual audit trails should be fully filled out if used for the system.
</p><p>
16. Downgrade of fixed magnetic media must be in accordance with Department
of Defense Magnetic Remanence Security Guideline, CSC-STD-005-85, Dark Blue
Book.
</p><p>
17. Passwords, especially network access passwords, must not be shared, written,
or stored in "Hot-Keys".
</p><p>
Security Officer Responsibilities
</p><p>
1. One person should be responsible for the security of the system. This
person should:
</p><blockquote>
  a. Ensure system certification and accreditation.
  <p>
  b. Ensure User awareness of and compliance with security requirements.
  </p><p>
  c. Investigate violations and determine what happened.
  </p><p>
  d. Report violations to proper authorities.
  </p><p>
  e. Ensure configuration control is properly carried out.
  </p><p>
  f. Review audit logs for anomalies, if used.
  </p><p>
  g. Enforce downgrade procedures.
</p></blockquote>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> MIL-STD 1785
</p><p>
<strong>Title:</strong> System Security Engineering Program Management
Requirements
</p><p>
<strong>Date:</strong> 1 SEP 89
</p><p>
<strong>Highlights: </strong>
</p><p>
1. This standard does not come to bear on Computer Security directly; the
primary focus of the standard is Physical Security. The basic plan over the
course of the program lifecycle is sound and if the specifics aren't overly
worried about, the standard can give good guidance for the development of
a COMPUSEC Program or a total System Security Engineering Program. In Particular,
the DIDs which were produced in association with the standard are fairly
good models from which to work the appropriate COMPUSEC DIDs.
</p><p>
2. The System Security Engineering (SSE) Management Program should:
</p><blockquote>
  a. Enhance the operational readiness and mission success of the defense resource.
  <p>
  b. Identify and reduce potential vulnerabilities to security threats.
  </p><p>
  c. Provide management information essential to system security planning.
  </p><p>
  d. Minimize its own impact on program cost and schedule.
</p></blockquote>
<p>
3. The SSE requirements carry through the each program lifecycle phase in
the following way:
</p><blockquote>
  a. Concept Exploration Phase:
  <blockquote>
    1) Develop the System Security Management Plan (SSMP). [DI-MISC-80839]
    <p>
    2) Threat definition and analysis.
    </p><p>
    3) Develop Preliminary System Security Concept (PSSC). [DI-MISC-80840]
    </p><p>
    4) Define security requirements.
    </p><p>
    5) Assess technology and perform cost studies.
    </p><p>
    6) Prepare a Logistics Support Plan (LSP). [DI-S-1817]
    </p><p>
    7) Identify security training requirements.
    </p><p>
    8) Develop an Reliability and Maintainability (R&amp;M) program for the system.
    </p><p>
    9) Conduct a Preliminary Security Vulnerability Analysis (SVA). [DI-MISC-80841]
    </p><p>
    10) Prepare Security Classification Guide (SCG).
  </p></blockquote>
  <p>
  b. Demonstration and Validation Phase:
  </p><blockquote>
    1) Conduct Adversary Mission Analysis (AMA). [DI-MISC-80842]
    <p>
    2) Update and expand PSSC.
    </p><p>
    3) Review security regulatory requirements.
    </p><p>
    4) Update SVA.
    </p><p>
    5) Conduct security systems trade-off analysis.
    </p><p>
    6) Prepare preliminary specification inputs. [DI-S-30551B]
    </p><p>
    7) Identify manpower requirements associated with security systems deployment.
  </p></blockquote>
  <p>
  c. Full-Scale Development Phase:
  </p><blockquote>
    1) Define System Security Requirements.
    <p>
    2) Update SSMP.
    </p><p>
    3) Develop Subsystem and interface specifications.
    </p><p>
    4) Perform preliminary design of the major subsystems in the security system.
    </p><p>
    5) Perform subsystem verification analysis.
    </p><p>
    6) Perform subsystem and system response analysis.
  </p></blockquote>
  <p>
  d. Production and Deployment Phase:
  </p><blockquote>
    1) Monitor and support acceptance testing.
    <p>
    2) Monitor and analyze initial security systems training for adequacy.
    </p><p>
    3) Support Program Management Responsibility Transfer (PMRT).
    </p><p>
    4) Provide product security.
  </p></blockquote>
</blockquote>
<p>
  </p><hr>
<p>
<strong>Document Number:</strong> DRS-2600-5502-86
</p><p>
<strong>Title:</strong> System High and Compartmented Mode Workstations
</p><p>
<strong>Date:</strong> MAY 86
</p><p>
<strong>Highlights</strong>
</p><p>
1. This document gives the DIA views on the topics basically covered by the
Orange Book for NSA. While not in complete agreement with each other, the
differences between this document and the Orange Book are more in the approach
taken than in goal sought. The largest difference is in the groupings of
requirements. Rather than the six classes (in three divisions) used in the
Orange Book, only two groupings of requirements are made and they are based
on two of the allowed modes of operation, System High and Compartmented.
The requirements are well defined in this document with level of requirement
and alternatives identified in the requirement identifier.
</p><p>
2. System High Workstation Requirements: SH1 Discretionary Access Control
(DAC)
</p><blockquote>
  SH1.1a Access Control Lists (ACL)
  <p>
  SH1.1b Self/Group/Public Permissions (Protection Bits)
  </p><p>
  SH2 Object Reuse
  </p><blockquote>
    SH2.1 Object Reuse
  </blockquote>
  <p>
  SH3 Labels
  </p><blockquote>
    SH3.1a Floating Labels
    <blockquote>
      SH3.1a.1 Label Contents
      <p>
      SH3.1a.2 Process Data Sensitivity Level (PDSL)
      </p><p>
      SH3.1a.3 Window Labels
      </p><p>
      SH3.1a.4 Interwindow Data Moves
      </p><p>
      SH3.1a.5 Input Labels
      </p><p>
      SH3.1a.6 File Labels
      </p><p>
      SH3.1a.7 Printed Output Labeling
      </p><p>
      SH3.1a.8 Network Output Labeling
      </p><p>
      SH3.1a.9 Imported Data labeling
    </p></blockquote>
    <p>
    SH3.1b Stored Labels
    </p><blockquote>
      SH3.1b.1 Label Contents
      <p>
      SH3.1b.2 Window Labels
      </p><p>
      SH3.1b.3 Interwindow Data Moves
      </p><p>
      SH3.1b.4 Input Labels
      </p><p>
      SH3.1b.5 File Labels
      </p><p>
      SH3.1b.6 Printed Output Labeling
      </p><p>
      SH3.1b.7 Network Output Labeling
      </p><p>
      SH3.1b.8 Imported Data labeling
    </p></blockquote>
    <p>
    SH3.1c Export Labels
    </p><blockquote>
      SH3.1c.1 Label Contents
      <p>
      SH3.1c.2 Window Labels
      </p><p>
      SH3.1c.3 Interwindow Data Moves
      </p><p>
      SH3.1c.4 Input Labels
      </p><p>
      SH3.1c.5 Printed Output Labeling
      </p><p>
      SH3.1c.6 Network Output Labeling
      </p><p>
      SH3.1c.7 Imported Data labeling
    </p></blockquote>
  </blockquote>
  <p>
  SH4 Mandatory Access Control (MAC)
  </p><p>
  SH5 User Identification and Authentication
  </p><p>
  SH5.1 Password Authentication
  </p><blockquote>
    SH5.2a Local Authentication Data
    <blockquote>
      SH5.2a.1a Protected Passwords
      <p>
      SH5.2a.1b Encrypted Passwords
      </p><p>
      SH5.2a.1c Protected Encrypted Passwords
    </p></blockquote>
    <p>
    SH5.2b External Authentication Data
    </p><p>
    SH5.3a Password Generation
    </p><p>
    SH5.3b Password Selection
  </p></blockquote>
  <p>
  SH6 Identification of User Terminal
  </p><p>
  SH7 Trusted Path
  </p><blockquote>
    SH7.1 Trusted Path
  </blockquote>
  <p>
  SH8 Audit
  </p><blockquote>
    SH8.1 Audit Data
    <p>
    SH8.2a Selective Collection
    </p><p>
    SH8.2b Selective Reduction
    </p><p>
    SH8.3a Local Data Storage
    </p><p>
    SH8.3b External Data Storage
  </p></blockquote>
  <p>
  SH9 System Architecture
  </p><blockquote>
    SH9.1 System Architecture
  </blockquote>
  <p>
  SH10 System Integrity
  </p><blockquote>
    SH10.1 System Integrity
  </blockquote>
  <p>
  SH11 Trusted Facility Management
  </p><blockquote>
    SH11.1 Trusted Facility Management
  </blockquote>
  <p>
  SH12 Trusted Recovery - No Requirement
  </p><p>
  SH13 Security Testing
  </p><p>
  SH14 Design Specification and Verification - No Requirement
  </p><p>
  SH15 Configuration Management
  </p><p>
  SH16 Trusted Distribution
  </p><p>
  SH17 System Security Statement/Plan
  </p><p>
  SH18 Security Features Users Guide/Briefing
  </p><p>
  SH19 Trusted Facility Manual
  </p><p>
  SH20 Test Documentation
  </p><p>
  SH21 Design Documentation
  </p><p>
  SH22 Communications Security
  </p><p>
  SH23 Physical Security
  </p><p>
  SH24 TEMPEST
  </p><p>
  SH25 Personnel Security
  </p><p>
  SH26 Annual Accreditation
  </p><p>
  SH27 Protection Software
  </p><p>
  SH28 (No) Dial-up Lines
  </p><p>
  SH29 Access Authentication
</p></blockquote>
<p>
3. Compartmented Mode Workstation Requirements:
</p><blockquote>
  CM1 Discretionary Access Control (DAC)
  <blockquote>
    CM1.1a Access Control Lists (ACL)
    <p>
    CM1.1b Self/Group/Public Permissions (Protection Bits)
  </p></blockquote>
  <p>
  CM2 Object Reuse -SH-
  </p><blockquote>
    CM2.1 Object Reuse -SH-
  </blockquote>
  <p>
  CM3 Labels
  </p><blockquote>
    CM3.1 Label Contents
    <p>
    CM3.2 Process Data Sensitivity Level (PDSL) -SH-
    </p><p>
    CM3.3 Window Labels -SH-
    </p><p>
    CM3.4 Interwindow Data Moves
    </p><p>
    CM3.5 Input Labels -SH-
    </p><p>
    CM3.6 File Labels -SH-
    </p><p>
    CM3.7 Printed Output Labeling
    </p><p>
    CM3.8 Network Output Labeling
    </p><p>
    CM3.9 Imported Data labeling -SH-
  </p></blockquote>
  <p>
  CM4 Mandatory Access Control (MAC)
  </p><blockquote>
    CM4.1 Mandatory Access Control Levels
    <blockquote>
      CM4.1.1 Process Levels
      <p>
      CM4.1.2 Window Levels
      </p><p>
      CM4.1.3 File Levels
    </p></blockquote>
    <p>
    CM4.2 Mandatory Access Control Policy
  </p></blockquote>
  <p>
  CM5 User Identification and Authentication
  </p><blockquote>
    CM5.1 Password Authentication -SH-
    <p>
    CM5.2a Local Authentication Data
    </p><blockquote>
      CM5.2a.1a Protected Passwords -SH-
      <p>
      CM5.2a.1b Encrypted Passwords -SH-
      </p><p>
      CM5.2a.1c Protected Encrypted Passwords -SH-
    </p></blockquote>
    <p>
    CM5.2b External Authentication Data
    </p><p>
    CM5.3a Password Generation -SH-
    </p><p>
    CM5.3b Password Selection -SH-
    </p><p>
    CM5.4 Maximum Security Level Determination
  </p></blockquote>
  <p>
  CM6 Identification of User Terminal -SH-
  </p><p>
  CM7 Trusted Path
  </p><blockquote>
    CM7.1 Trusted Path
  </blockquote>
  <p>
  CM8 Audit -SH-
  </p><blockquote>
    CM8.1 Audit Data -SH-
    <p>
    CM8.2a Selective Collection -SH-
    </p><p>
    CM8.2b Selective Reduction -SH-
    </p><p>
    CM8.3a Local Data Storage -SH-
    </p><p>
    CM8.3b External Data Storage -SH-
  </p></blockquote>
  <p>
  CM9 System Architecture
  </p><blockquote>
    CM9.1 System Architecture
  </blockquote>
  <p>
  CM10 System Integrity -SH-
  </p><blockquote>
    CM10.1 System Integrity -SH-
  </blockquote>
  <p>
  CM11 Trusted Facility Management -SH-
  </p><blockquote>
    CM11.1 Trusted Facility Management -SH-
  </blockquote>
  <p>
  CM12 Trusted Recovery
  </p><p>
  CM13 Security Testing -SH-
  </p><p>
  CM14 Design Specification and Verification
  </p><p>
  CM15 Configuration Management -SH-
  </p><p>
  CM16 Trusted Distribution -SH-
  </p><p>
  CM17 System Security Statement/Plan -SH-
  </p><p>
  CM18 Security Features Users Guide/Briefing -SH-
  </p><p>
  CM19 Trusted Facility Manual -SH-
  </p><p>
  CM20 Test Documentation -SH-
  </p><p>
  CM21 Design Documentation
  </p><p>
  CM22 Communications Security -SH-
  </p><p>
  CM23 Physical Security -SH-
  </p><p>
  CM24 TEMPEST -SH-
  </p><p>
  CM25 Personnel Security
  </p><p>
  CM26 Annual Accreditation -SH-
  </p><p>
  CM27 Protection Software -SH-
  </p><p>
  CM28 (No) Dial-up Lines -SH-
  </p><p>
  CM29 Access Authentication -SH-
</p></blockquote>
<p>
4. In the naming of the requirements (LLxx.ym.zn):
</p><blockquote>
  a. LL gives the Mode of Operation CM or SH.
  <p>
  b. xx is the general requirement number.
  </p><p>
  c. y is the specific requirement.
  </p><p>
  d. m is the option of the specific requirement.
  </p><p>
  e. z is the subrequirement.
  </p><p>
  f. n is the option of the subrequirement.
</p></blockquote>
<p>
  </p><hr>
<p>
</p><h1 align="center">
  <strong>Section <a name="IV">IV</a>:</strong>
</h1>
<h1 align="center">
  <strong>Case Studies</strong>
</h1>
<h2 align="center">
  <strong>IV. Case Studies</strong>
</h2>
<p>
To help bring the other sections of this book into clear focus, this section
gives four Case Studies of actual systems and their encounters with Computer
Security. In order for the studies to cover as much ground as possible, the
programs included span a wide variety of equipment types and levels of security.
(The names have been changed to protect the innocent and guilty alike.)
</p><p>
Note: Gonculator translates roughly as Potrezebie.
</p><p>
A. The New Development Gonculator (NDG) is a current development with massive
integration of the on-board computer systems and uses data with significant
restrictions on its dissemination. The security features concentrate on limiting
data access for personnel with other access to the aircraft.
</p><p>
B. Upgrade Gonculator (UG) CompuSec is for upgrades to an aircraft which
is also an FMS favorite and thus is not always in the hands of US Nationals.
The security measures concentrate on protecting US-only data and control
code.
</p><p>
C. Communications Gonculator Group (CGG) is a highly portable communications
network which processes and transmits data at SCI levels while operating
in the System High mode of operations. The security features concentrate
on blocking communications eavesdropping and sudden hardware (involuntary)
turnover.
</p><p>
D. Ground Intelligence Gonculator System (GIGS) is a bunkered ground station
for a reconnaissance program which processes and transmits intelligence data
at various levels and flavors. The security functionality permeates the system;
it tracks and mediates all access to data and equipment.
</p><p>
E. Yellow Book Evaluations: Each of the four Gonculator systems is evaluated
per the Yellow Books' (CSC-STD-003-85 and CSC-STD-004-85) algorithms to determine
the "required" Orange Book level for each system, both before and after changes
to allow looser requirements.
</p><p>
  </p><hr>
<h3>
  <strong>A. NDG: New Development Gonculator</strong>
</h3>
<p>
1. Threats: The threats to the NDG can be grouped into three main categories:
threats related to the aircraft sitting on the flight line unattended, threats
related to the aircraft coming down in an unscheduled fashion (crashes),
and the personnel with some level of access to the NDG.
</p><blockquote>
  a. Flight Line: On the flight line the NDG is protected to some degree from
  overt attack by fences and guards, but these measures are not sufficient
  to protect an unattended aircraft from covert attempts to gain access to
  sensitive data held on the aircraft.
  <p>
  b. Fall Down: When the NDG is operating, all possible data must be assumed
  to be available at the time of a crash. The threat inherent in this situation
  is that the aircraft may retain the data after the event. If the event occurs
  in an area populated, or controlled, by Not So Friendly people, this will
  give the Not So Friendlies virtually unlimited time and access to derive
  from the aircraft any data which survived the event.
  </p><p>
  c. Personnel: Any time that people are involved with data (or data containers)
  there is some level of risk involved. This is fundamental to security in
  general and CompuSec as well (clearances, Need-To-Know, least privilege,
  etc.). In the case of the NDG, there are three levels of personnel with differing
  needs and differing treatments.
  </p><blockquote>
    1) Pilot: In order to fly the aircraft to its full capabilities the pilot
    must have access to the sensitive data residing on the aircraft. However
    the access which the pilot requires is not necessarily personal access; most
    of the access required is limited to access by the computers on-board the
    aircraft with the pilot only seeing the results.
    <p>
    2) Special Maintenance: The maintenance personnel who are actively involved
    in the maintenance of the flight computers, sensor systems, data busses,
    etc. have a need for direct access to the data in order to diagnose problems,
    effect repairs on these systems, and load upgrades to the software and data
    stores.
    </p><p>
    3) Flight Line Maintenance: The other maintenance personnel (servicing the
    engine, fueling the NDG, etc.) don't need the data - just access to the NDG.
  </p></blockquote>
</blockquote>
<p>
2. Data / Classified Material: Data and code stored and processed on the
NDG run the gamut from unclassified through plain Vanilla Secret to Special
Access Required (SAR) data. Not all of the data is needed by all of the
personnel.
</p><p>
3. Implementation:
</p><blockquote>
  a. Layered Encryption: Data stored on-board the NDG is encrypted by level
  of data. The mission data cartridge contains the decryption data which allows
  the system to come to full capabilities while loading the mission data. In
  the event of failure of the cartridge, the pilot can key in the decryption
  data to allow the NDG to become fully functional. With the separate encryption
  by level the pilot can generally gain access to what is needed without having
  the data accessible to those who have no need for the data. The maintenance
  personnel have decryption capabilities commensurate with their Need-To-know
  and clearances.
  <p>
  b. Working System Without Decryption: In the event of total decryption failure,
  the NDG is still able to fly the mission. Some of the functionality will
  be impaired by the inaccessibility of portions of the data, by the ability
  to fly and fight will be present.
  </p><p>
  c. Security As a Compromise With the User: While the security measures taken
  for the NDG do not cover all of the threats fully, the security does cover
  the major problems relatively well and still allows the User to have a system
  which will fill the need. The compromise between mission need and security
  need is always a difficult call to make, but it should be remembered that
  a useless system (through over-securing) is not going to help the security
  situation either.
  </p><blockquote>
    1) While on the flight line, the NDG has no data available for gathering
    by covert means which is not encrypted.
    <p>
    2) In the event that the NDG falls down the RAM is purged by powering down
    the craft, either purposefully or by failure on collision, thus the only
    classified data remaining is in encrypted ROM.
    </p><p>
    3) The pilots are cleared for the data which is needed to operate the craft
    in a fully functional manner and Identification and Authentication (I&amp;A)
    is accomplished through either Ownership of the mission data cartridge or
    Knowledge of the code to key in for encryption. The special maintenance personnel
    accomplish I&amp;A through various keying procedures and by duplicating,
    for test and diagnostic purposes, the pilots I&amp;A procedures. The other
    flight line personnel have neither the need nor the means to decrypt the
    data.
  </p></blockquote>
</blockquote>
<h3>
  <strong>B. UG: Upgrade Gonculator</strong>
</h3>
<p>
1. Threats: The threats to the UG can be grouped into three main categories:
threats related to the aircraft sitting on the flight line unattended, threats
related to the aircraft coming down in an unscheduled fashion (crashes),
and the personnel with some level of authorized access to the UG. Each of
these threat categories is discussed in the following paragraphs.
</p><blockquote>
  a. Flight Line: On the flight line the UG is protected to some degree from
  overt attack by fences and guards, but these measures are not sufficient
  to protect an unattended aircraft from covert attempts to gain access to
  sensitive data held on the aircraft. In addition to the usual problems associated
  with the flight lines on US bases, the UG is scheduled for sale through the
  FMS program to various foreign countries. The level of flight line physical
  security is subject to the policies and standards of the acquiring country
  - which may or may not always meet the US standards.
  <p>
  b. Fall Down: When the UG is operating, all possible data must be assumed
  to be available at the time of a crash. The threat inherent in this situation
  is that the aircraft may retain the data after the event. If the event occurs
  in an area populated, or controlled, by Not So Friendly people, this will
  give the Not So Friendlies virtually unlimited time and access to derive
  from the aircraft any data which survived the event.
  </p><p>
  c. Personnel: Any time that people are involved with data (or data containers)
  there is some level of risk involved. This is fundamental to security in
  general and CompuSec as well (clearances, Need-To-Know, least privilege,
  etc.). In the case of the UG, there are three levels of personnel with differing
  needs and differing treatments. The US personnel, the foreign personnel,
  and the contractor field engineers are discussed below.
  </p><blockquote>
    1) US Personnel: The UG is used as a US fighter with US personnel operating
    and maintaining the system. With the data and code stored by UG, the clearing
    all of these personnel is not a problem.
    <p>
    2) Foreign Personnel: Oddly enough, the foreign nationals from the nations
    which buy the UG will also want access to the craft and its data. Unfortunately,
    some of the data is currently not releasable to non-US personnel.
    </p><p>
    3) Contractor Field Engineers: Along with the UG come the contractor field
    engineers who, among other things, load new versions of the Operational Flight
    Program (OFP) and other control code. These field engineers are cleared US
    citizens.
  </p></blockquote>
</blockquote>
<p>
2. Data / Classified Material: The data and classified material related to
the UG basically fall into the sets which are discussed in the following
paragraphs:
</p><blockquote>
  a. Unclassified: The majority of the OFP, other code, and stored data is
  unclassified and there is no need to protect the data any more stringently
  than the aircraft will already be protected as the high-value item that it
  is.
  <p>
  b. US - only Weapons and Control Code: Some of the weapons which are available
  for use on the UG system are currently limited to US-only use. There is,
  however, great pressure to sell the FMS customers the "same" system which
  we use - including the US-only weapons and control code.
</p></blockquote>
<p>
3. Implementation: Because this is an UpGrade to an existing system the options
are not as open as they would be in a new development. The previous methods
employed such as distributing just the object code (not the source code)
have not stood the test of reverse-engineering. The contractor field engineers
will continue to load the new versions of the OFP, etc. and additionally
the following steps are being explored and taken as possible:
</p><blockquote>
  a. Downgrading: Where possible, the dissemination-limited data is being
  downgraded to allow for release to the FMS customers. This entails careful
  study and evaluation of the subject material and determining actual risk
  involved with the downgrade.
  <p>
  b. Encryption: Classified data is being encrypted for storage on-board the
  aircraft. This allows for shortened pre-flight preparation while limiting
  the risk of compromise of the data.
  </p><p>
  c. Don't Disperse Weapons: Those weapons subsystems which are not available
  for the downgrading effort above will not be a part of the FMS purchase packages.
  This does not, however, directly address the question of the control code
  for the weapons - just the weapons themselves.
  </p><p>
  d. Modularize and Excise: The control code for non-distributed weapons subsystems
  is to be "non-distributed" as well. As a part of the UpGrade, a new mission
  computer system is being installed with an accompanying software rewrite.
  during the rewrite, the code will be modularized with permanent "stub"
  replacements written for those portions of the code which cannot be released
  to non-US personnel. The stubbed version will be compiled for FMS distribution
  and the un-stubbed version will be used for US distribution.
</p></blockquote>
<h3>
  <strong>C.</strong> <strong>CGG: Communications Gonculator Group</strong>
</h3>
<p>
1. Threats: The threats to the data residing on CGG and transmitted by CGG
fall into three main categories: physical overrun by Not So Friendly troops,
Eavesdropping on the communications transmitted by CGG, and the personnel
actually using CGG.
</p><blockquote>
  a. OverRun: A goodly portion of the CGG terminals are used by tactical ground
  forces in relatively forward areas. In addition, the field terminals are
  portable and thus even more susceptible to hostile actions. In the event
  that a live terminal were to be overrun (without opportunity to clear/destroy
  the equipment), the terminal would continue to send and receive, encrypt
  and decrypt, etc. until the network is informed, via other channels, of the
  overrun. This could lead to serious compromise of sensitive data and compromise
  the integrity of the CGG network through spurious messages sent from the
  captured CGG unit.
  <p>
  b. Eavesdrop: Being a communications system, the CGG is vulnerable to
  interception of transmissions. The communications are via radio leaving no
  physical signs of the interception having been made. Additionally, the far
  forward field terminals are vulnerable to discovery when transmitting.
  </p><p>
  c. Personnel: All personnel with authorized access to the CGG network have
  clearances and formal authorizations for all data on the net. [This simplifies
  the personnel aspects of the system because partial screening of portions
  of the data from portions of the personnel (like NDG and UG required) is
  not needed.]
</p></blockquote>
<p>
2. Data / Classified Material: All data on and in CGG is treated at the level
of the highest data allowed. The data falls into two main groups which are
discussed below.
</p><blockquote>
  a. Messages: Messages, both received and to be sent, are stored on the system
  as space allows. These messages must be protected at the highest level allowed
  on the system (even if they are just setting up dinner on Friday) because
  the system cannot differentiate between the (possibly) various levels of
  data within the system.
  <p>
  b. Stored Crypto Material: In order to facilitate orderly key change operations,
  the CGG stores keying material for the next change and further into the future
  as needed by operational requirements in the field. If this crypto material
  is not protected, the CGG network security is compromised for an extended
  time period (until all of the stored keying material has been replaced over
  the entire net, which could take a while with units in the field and net
  security compromised.)
</p></blockquote>
<p>
3. Implementation:
</p><blockquote>
  a. Separate Encryption of Header and Message: In order to ensure that the
  messages only go to the intended recipients, the header and body of the messages
  are encrypted separately. The message header is decrypted (transparent to
  the operator) for all messages and only those messages which are intended
  for that particular terminal are made visible to the operator of the terminal.
  With both header and message encrypted and all messages going to each terminal,
  there is no unencrypted data available for analysis and analysis of the
  transmission patterns is limited.
  <p>
  b. Security at Net Control: Primary security is performed at the network
  level by the addition of a MicroVAX workstation dedicated to security. It
  is within this MicroVAX that auditing of events, journalling of messages,
  and Identification and Authentication occur. All actions which take place
  over the net are audited by Terminal, User, and event type. Each message
  which is sent
  </p><p>
  c. Security Down ? Net Down: In the event that the security work station
  becomes inoperable, the cabling can bypass the security processing and allow
  mission essential work to continue. During this time, the field terminals
  will still require their users to login, but the field terminal will accept
  the non-response from the (off-line) security workstation as a non-negative
  response and allow access even if passwords and such are incorrect. In addition,
  no event auditing or message journalling will take place until the workstation
  is back on line.
  </p><p>
  d. Security Operator ? Operator: Because the security is handled at the network
  level within an add-on MicroVAX workstation, the security personnel are separate
  from the user/operator personnel. While cleared at the same level as the
  users, the security personnel are given access to the MicroVAX and its
  functionality. The user password sets and the Security password sets are
  separate and if one person is both a user and a security operator that person
  will have two distinct IDs and passwords for the two distinct roles.
  </p><p>
  e. Clear Field Unit: The field unit has built-in clearing circuitry to clear
  all memory and all crypto keys. This can be operated either by the operator
  (in the event of imminent overrun or by the security operator at the MicroVAX
  (in the event of unannounced overrun, etc.). These clearing actions are
  non-destructive and will only require rekeying and reentry of operational
  data (like frequencies) to become operational again. For those circumstances
  where the changing of hands is more certain and there is sufficient lead
  time, provisions have been made for the physical destruction of the field
  terminal.
</p></blockquote>
<h3>
  <strong>D. GIGS: Ground Intelligence Gonculator System</strong>
</h3>
<p>
1. Threats: Because GIGS is a bunkered system, the threats from without are
greatly lessened by the physical security of the locale. The threats to GIGS
revolve around the personnel and functionality of the system itself. These
threat groupings are discussed in the paragraphs below.
</p><blockquote>
  a. Mixed Intel Types: While all users within GIGS are cleared to the same
  (high) level and all have formal access permissions for all of the data resident
  within the system, not all of the users have a verified Need-To-Know for
  all of the data. In particular, the two sets of intelligence analysts have
  little or no Need-To-Know for the data analyzed by the other set, with the
  exception of that data which is used synergistically to feed the collection
  schemes and build combined reports.
  <p>
  b. Bad Message Distribution: With the massive message processing capabilities
  of GIGS the possibility of mis-labelled, mis-routed, and mis-distributed
  messages looms large as a threat. With high volume message traffic, both
  incoming and outgoing, even a small probability flaw in the system can lead
  to substantial loss. With communications channels at varying classification
  levels there is an imperative need for the data to be well labelled so the
  computer can mediate the access to the communications port for each message
  sent.
  </p><p>
  c. Personnel: As with any situation involving people, a major threat source
  (of low probability) is the personnel. In the case of GIGS, with hundreds
  of personnel possessing high levels of access to the data, the risk is tangible.
  The personnel can be grouped as discussed below. (All personnel in both groupings
  are cleared to the level of and haves formal access permission to all of
  the data.)
  </p><blockquote>
    1) Two Sides of the Intelligence Community: The intelligence analysts on
    both sides of the house need to deal with the data itself. Both sides of
    the house guard their data closely from prying eyes outside their side of
    the house as well as the official Not So Friendly persons.
    <p>
    2) Comm and Maintenance: The communications and maintenance personnel do
    not need close access to the data itself but the nature of their duties lead
    to close contact with the data as it flows along their comm channels and
    needs to be diagnosed and tested during maintenance actions. In fact, the
    maintenance personnel have closer access than anyone because their actions
    naturally bypass the safeguards.
  </p></blockquote>
</blockquote>
<p>
2. Classified Data / Material: The sensitive (classified) material in GIGS
is at varying levels but the primary concern is the types of material. The
primary data categories are discussed below. Each category contains data
which may be at various levels of classification.
</p><blockquote>
  a. Messages: Incoming and outgoing messages resident in GIGS are classified
  at various levels from Unclassified But Sensitive through Top Secret
  compartmentalized data. In addition, the incoming messages must be sorted
  and distributed based on classification and data set. The volume of incoming
  precludes hand sorting of the messages in a timely manner and the volume
  of the outgoing messages precludes a Man-In-The-Loop implementation.
  <p>
  b. Keying Material: With many network connectivities and dedicated lines,
  GIGS has numerous crypto devices of various types. These keys must be protected
  to ensure integrity of the communications channels and availability of the
  system to the Users.
  </p><p>
  c. Intel Databases: Massive databases are stored and updated by GIGS to support
  the analysts efforts. In addition, pertinent messages (both incoming and
  outgoing) are parsed, bent, folded, spindled, and mutilated to fit into the
  database as reference material. Bulk uploads from several agencies are fed
  to GIGS databases as available. These bulk uploads use various classification
  schemas and must be converted into GIGS format for classification and storage.
  The scale of the update effort is sufficient to require computer-driven
  reformatting and translation.
  </p><p>
  d. Security Data: The scope of the computer security functionality dictated
  massive data stores for the functionality. This data runs the gamut from
  Identification and Authentication (I&amp;A) data, to system security
  configuration files, to audit trails and message journals. This data must
  be protected not only from prying eyes within the system (and without) but
  must also be protected from unauthorized modification, particularly the audit
  and journal data. This data is classified at the level of the source of the
  data so pure Mandatory Access Controls (MAC) will not protect the data from
  within; for protection of the security data, the Discretionary Access Controls
  (DAC) must be the primary driver.
</p></blockquote>
<p>
3. Implementation: Th implementation of GIGS CompuSec is an integral part
of the GIGS system as a whole. The DAC, MAC, and audit capabilities handle
the primary burden with ancillary Information System Security Officer (ISSO)
functionality rounding out the package. Because the security functionality
primarily operates in a newly developed segment of GIGS, the implementation
was able to be built-in not added-on. MAC, DAC, and audit are discussed below.
</p><blockquote>
  a. DAC: DAC is one of the least understood and defined areas in CompuSec.
  This lack of understanding and definition of the DAC arena gives more opportunity
  to adapt the security features to the conditions at hand. This also gives
  more opportunity for the DAC features to fail to meet the need. Care was
  taken with GIGS to ensure that the DAC functionality fit the situation and
  were sufficient.
  <blockquote>
    1) Team Concept: Operationally, GIGS is manned by many people working in
    shifts of teams for a particular analysis type. The need for truly private
    data is essentially eliminated by the teaming and shift work. While there
    is still a need for personal data stores for preferences in setup and such,
    the data itself must be accessible to members of the team on all shifts.
    <blockquote>
      a) User Groups: Access is granted by the DAC mechanisms based on the user
      group(s) in which the user has membership. The user groups determine access
      to sets of data, terminals, and peripherals. Each of the teams mentioned
      above is divided into one or more user groups for DAC purposes and individual
      users are granted membership to the appropriate user groups.
      <p>
      b) Personal Subdirectory: For personal data (work in progress, etc.) and
      personal preferences (screen layouts, open windows, standing queries, etc.)
      are stored in a personal subdirectory with a name based on the UserID which
      no one else has access to through ordinary channels.
    </p></blockquote>
    <p>
    2) Menu Environment: GIGS has a menu-driven DECWindows implementation with
    no access to the bare system. This allows the system to only permit access
    to functionality by not offering the non-allowed functionality in the menus.
    GIGS operates based on function groups which are available to the user groups.
    On login for a user, the I&amp;A background data is checked for function
    group membership for that user, based on the user group memberships for the
    user, and builds menus which offer all of the user's allowed function access
    and no other functionality.
    </p><p>
    3) Bit Map Decision: The actual DAC decision mechanism is a simple ANDing
    of the bit pattern for a user's DAC user groups and the bit pattern of the
    object in question. If a non-zero answer results from the AND, access is
    granted because some user group in the user's DAC label matched a user group
    in the objects DAC label.
  </p></blockquote>
  <p>
  b. MAC: MAC is well understood in and of itself. It is, after all, the security
  requirements which govern the classification and dissemination of paper data
  as well. The problems come with implementing the requirements in a computer.
  The classification levels themselves work well because they are strictly
  hierarchical (U&lt;C&lt;S&lt;TS). The compartments and code words, releasability,
  handling caveats, etc. add to the task of an orderly implementation because
  they are not always hierarchical. This leads to a lattice based view of MAC
  and partially ordered dominance being the basis of the MAC access decisions.
  </p><blockquote>
    1) Analysis of Levels: For GIGS, the set of all meaningful components of
    the security lattice needed to be identified and the relations between the
    combined elements determined. While this sounds straight-forward, the relations
    (especially between groups in the intel community) were sometimes not
    well-defined. To simplify matters, the lattice was divided into sublattices
    of like markings. These sublattices were then well defined and melded into
    the complete lattice as the relations were completed.
    <p>
    2) Master Lattice List: The physical implementation of the lattice took the
    form of a series of arrays which contained the representations of the lattice
    elements suitable to the various needs. These representations include the
    bit patterns for each element (grouped by sublattice), the standard English
    version of the label in full and short forms and aliases for the standard
    version.
    </p><blockquote>
      a) Bit Patterns: The combined lattice in bit form allows for simple access
      decisions because the patterns were allocated assign dominance a numeric
      superiority for the hierarchical portion and a simple subset check can handle
      the non-hierarchical portions.
      <p>
      Note: This was more than a simple bit setting though; for instance NATO
      Releasability is shown by turning bits off, not on because no releasability
      commentary (positive or negative) is the same as NOFORN.
      </p><p>
      b) Aliases: Aliases include the forms of the label which the system is allowed
      to accept in incoming messages (abbreviations, typical misspellings, etc.),
      and the ISSO defined form of the label to be used in various ways throughout
      the system (screen, window, icon, printed banner, message classification
      line, etc.). The standard English version of each lattice component is stored
      in long and short forms as FORTRAN Include files compiled into the code.
      The aliases are stored in tables readily alterable by the ISSO as needed.
    </p></blockquote>
  </blockquote>
  <p>
  c. Audit: The menu environment of GIGS makes auditing somewhat simpler than
  on a bare system. Because the actions available to the users are well defined
  and substantially limited, via the windowing process, the need to audit the
  lower level actions are reduced and the actions can be more clearly identified
  in the audit trail.
  </p><blockquote>
    1) Menu Selections and Errors: Essentially all of the audited actions are
    based on the menu selection made or errors/non-allowed access attempts. Each
    of these event types can be selected to be audited or not as the ISSO deems
    necessary with usability of the audit trail, operational demands, and available
    storage and processing power taken into account. The TCB has table-driven
    functionality for this auditing feature and the ISSO can readily modify the
    tables.
    <p>
    2) Message Journal: Each message sent from GIGS or received by GIGS is stored
    in its entirety in the message journal. (This is in addition to the parsed
    versions which may go to the database and the Read File version where users
    access to read their incoming mail or review outgoing mail.) The only user
    group with Read access to the journal is the ISSO Group. The only write access
    available to the ISSO is a message delete function (well audited) for the
    removal of messages classified outside the GIGS lattice inadvertently received
    by GIGS.
    </p><p>
    3) Size: The sheer magnitude of the operation of GIGS leads to sizing problems
    for the audit trail - approximately 24 gigabytes a month for 24 hour operation
    with all possible auditable events being audited. The message journal is
    over and above this figure. Off line storage is only a partial answer, because
    as the data set grows, it becomes increasingly difficult to access the needed
    data in the event of an incident. This leads to the ISSO auditing only those
    events which are most meaningful. This is made possible through ISSO tables,
    which allow each event type to be turned on and off at both the individual
    event level and as classes of events. The risk in doing business like this
    is that the incident may well make use of a not particularly security relevant
    function in a means not previously considered.
  </p></blockquote>
</blockquote>
<p>
  </p><hr>
<h3>
  <strong>E. Yellow Books</strong>
</h3>
<p>
Calculations for the "required" Orange Book class are performed per the
algorithms set forth in CSC-STD-003-85 Computer Security Requirements and
CSC-STD-004-85 Rationale Behind Computer Security Requirements. The digests
of these two documents are on pages 112 and 114 of this book. (For simplicity,
the algorithms used for this subsection are found in the digest of
CSC-STD-003-85, pages 112 and 113 of this book.)
</p><p>
1. NDG: New Development Gonculator: Dedicated Mode of Operations
</p><blockquote>
  a. Initial Calculated Level
  <blockquote>
    Rmin = 3 (Pilot, Special Maintenance,Flight line Personnel)
    <p>
    Rmax = 5 (SAR data)
    </p><p>
    Risk Index = 2
    </p><p>
    Required Class = B2 (Open or Closed Development Environment)
  </p></blockquote>
  <p>
  b. I&amp;A for Computer Access: This removes the flight line personnel from
  data access. (No longer users.)
  </p><p>
  c. Final Calculated Level
  </p><blockquote>
    Rmin = 3 (Pilot and Special Maintenance)
    <p>
    Rmax = 3 (Categories aren't counted because all users have access.)
    </p><p>
    Risk Index = 0
    </p><p>
    Required Class = C1 or Less
  </p></blockquote>
</blockquote>
<p>
2. UG: Upgrade Gonculator: Dedicated Mode of Operations
</p><blockquote>
  a. Initial Calculated Level
  <blockquote>
    Rmin = 3 (Foreign Nationals)
    <p>
    Rmax = 5 (Various)
    </p><p>
    Risk Index = 2
    </p><p>
    Required Class = B2 (Open or Closed Development Environment)
  </p></blockquote>
  <p>
  b. Downgrade, Don't Disperse Weapons, Modularize and Excise
  </p><p>
  c. Final Calculated Level
  </p><blockquote>
    Rmin = 3 (All Personnel)
    <p>
    Rmax = 3 (No Categories)
    </p><p>
    Risk Index = 0
    </p><p>
    Required Class = C1 or Less
  </p></blockquote>
</blockquote>
<p>
3. CGG: Communication Gonculator Group
</p><blockquote>
  a. Calculated Level: System High Mode of Operations
  <blockquote>
    Rmin = 6 (All Personnel TS 1 Category)
    <p>
    Rmax = 6 (1 Category)
    </p><p>
    Risk Index = 0
    </p><p>
    Required Class = C1 or Less
  </p></blockquote>
</blockquote>
<p>
4. GIGS
</p><blockquote>
  a. Initial Calculated Level: System High Mode of Operations
  <blockquote>
    Rmin = 3 (Maintenance Personnel)
    <p>
    Rmax = 7 (2 or More Categories at TS)
    </p><p>
    Risk Index = 4
    </p><p>
    Required Class = A1 (for Open Development Environment)
    </p><p>
    B3 (for Closed Development Environment)
  </p></blockquote>
  <p>
  b. Clear all Personnel and Grant formal Access Permission for All Data
  </p><p>
  c. Final Calculated Level: System High Mode of Operations
  </p><blockquote>
    Rmin = 7 (All Personnel TS Multiple Categories)
    <p>
    Rmax = 7 (2 Categories at TS)
    </p><p>
    Risk Index = 0
    </p><p>
    Required Class = C2
    </p><p>
    Note: Agreement with the accrediting agencies resulted in B1ish requirements.
  </p></blockquote>
</blockquote>
<p>
  </p><hr>
<p>
</p><h1 align="center">
  <strong>Section <a name="V">V</a>:</strong>
</h1>
<h1 align="center">
  <strong>Notes</strong>
</h1>
<h1 align="center">
  <strong>Abbreviations and Acronyms</strong>
</h1>
<p>
<b>1C</b> One Category
</p><p>
<b>30DAC</b> 30 Days After Contract Award
</p><p>
<b>90DAC</b> 90 Days After Contract Award
</p><p>
<b>ACL</b> Access Control List
</p><p>
<b>AIS</b> Automated Information Systems
</p><p>
<b>AKA</b> Also Known As
</p><p>
<b>AMA</b> Adversary Mission Analysis
</p><p>
<b>ATM</b> Automatic Teller Machine
</p><p>
<b>AUD</b> Audit
</p><p>
<b>BI</b> Background Investigation
</p><p>
<b>BPOC</b> Business Point of Contact
</p><p>
<b>bps</b> Bits Per Second
</p><p>
<b>BSCS</b> Bachelor of Science in Computer Science
</p><p>
<b>C</b> Confidential
</p><p>
<b>CCB</b> Configuration Control Board
</p><p>
<b>CDR</b> Critical Design Review
</p><p>
<b>CDR+90</b> 90 Days After CDR
</p><p>
<b>CDRL</b> Contract Data Requirements List
</p><p>
<b>CGG</b> Communication Gonculator Group
</p><p>
<b>CM</b> Configuration Management
</p><p>
<b>CMS</b> Code Management System
</p><p>
<b>COMPUSEC</b> Computer Security
</p><p>
<b>COMSEC</b> Communications Security
</p><p>
<b>Con Ops</b> Concept of Operations
</p><p>
<b>COTS</b> Commercial Off the Shelf
</p><p>
<b>CPU</b> Central Processing Unit
</p><p>
<b>CSC</b> Computer Security Center
</p><p>
<b>CSMP</b> Computer Security Management Plan
</p><p>
<b>D&amp;UG</b> Dissemination and Use Group
</p><p>
<b>DAA</b> Designated Approving Authority
</p><p>
<b>DAC</b> Discretionary Access Control
</p><p>
<b>DAL</b> Data Accession List
</p><p>
<b>DBMS</b> Database Management System
</p><p>
<b>DIA</b> Defense Intelligence Agency
</p><p>
<b>DID</b> Data Item Description
</p><p>
<b>DNA</b> Deoxyribonucleic Acid
</p><p>
<b>DoD</b> Department of Defense
</p><p>
<b>DTLS</b> Descriptive Top-Level Specification
</p><p>
<b>EEPROM</b> Electrically Erasable Programmable Read Only Memory
</p><p>
<b>EMD</b> Engineering and Manufacturing Development
</p><p>
<b>EMSEC</b> Emanations Security
</p><p>
<b>EPL</b> Evaluated Product List
</p><p>
<b>ETL</b> Endorsed Tools List
</p><p>
<b>FER</b> Final Evaluation Report
</p><p>
<b>FOC</b> Full Operational Capability
</p><p>
<b>FORTRAN</b> Formula Translation
</p><p>
<b>FSD</b> Full Scale Development
</p><p>
<b>FTLS</b> Formal Top-Level Specification
</p><p>
<b>GAWG</b> Gonculator Accreditation Working Group
</p><p>
<b>GIGS</b> Ground Intelligence Gonculator System
</p><p>
<b>HI</b> Hydroiodic Acid
</p><p>
<b>I&amp;A</b> Identification and Authentication
</p><p>
<b>I/O</b> Input / Output
</p><p>
<b>ID</b> Identification
</p><p>
<b>IIV&amp;V</b> Internal IV&amp;V
</p><p>
<b>INFOSEC</b> Information Security
</p><p>
<b>IOC</b> Initial Operating Capability
</p><p>
<b>IPC</b> Inter-Process Communication
</p><p>
<b>ISSO</b> Information System Security Officer
</p><p>
<b>IV&amp;V</b> Independent Verification and Validation
</p><p>
<b>KISS</b> Keep It Simple, Stupid
</p><p>
<b>LSP</b> Logisical Support Plan
</p><p>
<b>MAC</b> Mandatory Access Control
</p><p>
<b>MC</b> Multiple Categories
</p><p>
<b>MOA</b> Memorandum of Agreement
</p><p>
<b>MOR</b> Memorandum of Record
</p><p>
<b>MSCS</b> Master of Science in Computer Science
</p><p>
<b>NATO</b> North Atlantic Treaty Organization
</p><p>
<b>NCR</b> National Cash Register
</p><p>
<b>NCSC</b> National Computer Security Center
</p><p>
<b>NDG</b> New Development Gonculator
</p><p>
<b>NIST</b> National Institute for Standards and Technology
</p><p>
<b>NOFORN</b> Not Releasable to Foreign Nationals
</p><p>
<b>NSA</b> National Security Agency
</p><p>
<b>NSAD</b> Network Security Architecture Design
</p><p>
<b>NTCB</b> Network TCB
</p><p>
<b>NTISSAM</b> National Telecommunications and Information Systems Security
</p><p>
<b>ObjectID</b> Object Identification
</p><p>
<b>OFP</b> Operational Flight Program
</p><p>
<b>OPSEC</b> Operations Security
</p><p>
<b>OR</b> Object Reuse
</p><p>
<b>P3I</b> Pre-Planned Product Improvement
</p><p>
<b>PC</b> Personal Computer
</p><p>
<b>PDR</b> Preliminary Design Review
</p><p>
<b>PDR-30</b> Thirty Days Before PDR
</p><p>
<b>PDSL</b> Process Data Sensitivity Level
</p><p>
<b>PHIP</b> PLATFORM Host Interface Processor
</p><p>
<b>PM</b> Program Management
</p><p>
<b>PMRT</b> Program Management Responsibility Turnover
</p><p>
<b>PoP</b> Philosophy of Protection
</p><p>
<b>PSSC</b> Preliminary System Security Concept
</p><p>
<b>R&amp;M</b> Reliability and Maintainability
</p><p>
<b>RAM</b> Random Access Memory
</p><p>
<b>RAMP</b> RAting Maintenance Phase
</p><p>
<b>RM-Plan</b> Rating Maintenance Plan
</p><p>
<b>RMax</b> Maximum Data Sensitivity Rating
</p><p>
<b>RMin</b> Minimum User Clearance Rating
</p><p>
<b>RMP</b> Rating Maintenance Report
</p><p>
<b>S</b> Secret
</p><p>
<b>SAR</b> Special Access Required
</p><p>
<b>SBI</b> Special Background Investigation
</p><p>
<b>SCCS</b> Source Code Control System
</p><p>
<b>SCG</b> Security Classification Guide
</p><p>
<b>SCI</b> Special Compartmented Information
</p><p>
<b>SDR</b> System Design Review
</p><p>
<b>SDR-30</b> 30 Days Before SDR
</p><p>
<b>SFUG</b> Security Features User's Guide
</p><p>
<b>SH</b> System High
</p><p>
<b>SL</b> Security Label
</p><p>
<b>SOW</b> Statement of Work
</p><p>
<b>SRR</b> System Requirements Review
</p><p>
<b>SRR-30</b> 30 Days Before SRR
</p><p>
<b>SS</b> System/Subsystem Specification
</p><p>
<b>SSE</b> System Security Engineering
</p><p>
<b>SSEM</b> SSE Management
</p><p>
<b>SSEP</b> SSE Program
</p><p>
<b>SSMP</b> System Security Management Program
</p><p>
<b>SSO</b> System Security Officer
</p><p>
<b>STD</b> Standard
</p><p>
<b>SVA</b> Security Vulnerability Analysis
</p><p>
<b>TAR</b> Technical Assessment Report
</p><p>
<b>TCB</b> Trusted Computing Base
</p><p>
<b>TCSEC</b> Trusted Computer System Evaluation Criteria
</p><p>
<b>TD</b> Trusted Distribution
</p><p>
<b>TerminalID</b> Terminal Identification
</p><p>
<b>TFM</b> Trusted Facility Manual
</p><p>
<b>TG</b> Technical Guidance
</p><p>
<b>TNI</b> Trusted Network Interpretation
</p><p>
<b>TNT</b> Trusted Network Technology
</p><p>
<b>TPOC</b> Technical Point of Contact
</p><p>
<b>TRIGS</b> TR-1 Ground Station
</p><p>
<b>TRUSIX</b> Trusted UNIX Working Group
</p><p>
<b>TS</b> Top Secret
</p><p>
<b>U</b> Unclassified
</p><p>
<b>UG</b> UpGrade Gonculator
</p><p>
<b>US</b> United States
</p><p>
<b>UserID</b> User Identification
</p><p>
<b>UV</b> Ultraviolet
</p><p>
<b>VR</b> Vendor Report
</p><p>
<b>VSA</b> Vendor Security Analyst
</p><p>
<b>WBS</b> Work Breakdown Structure
</p><p>
<b>XOR</b> Exclusive Logical Or
</p><p>
  </p><hr>
<h1 align="center">
  <strong>Glossary</strong>
</h1>
<p>
<b>access modes:</b> Types of interactions between subjects and objects which
result in the flow of information between them. (Read, Write, etc.)
</p><p>
<b>accountability:</b> The ability to hold an individual responsible for
the activities of that individual.
</p><p>
<b>ACL: access control list:</b> A list of users and/or groups associated
with an object.
</p><p>
<b>alphabet size: </b>The number of unique components available for use in
a "Password". (English letters -&gt; 26, English letters and numbers -&gt;
36, English 4, 5, and 6 letter words -&gt; 23300)
</p><p>
<b>archival storage: </b>Off-line long term storage, often in the form of
magnetic tape, often stored at a site other than the site generating the
stored information. A requirement for old audit trail data.
</p><p>
<b>assurance: </b>The ability to sufficiently evaluate the system to ensure
proper implementation of necessary safeguards to enforce the security policy.
</p><p>
<b>audit trails:</b> The stored audit records. (So you'll know who to take
out and shoot.)
</p><p>
<b>audit:</b> Records kept of all security relevant activities on a system
and the ability to draw from the records a clear picture of the actions taken
and the user who took the actions.
</p><p>
<b>authentication: </b>The part of login concerned with the validity of the
identity. (Are you - you?)
</p><p>
<b>authorization:</b> Formal permission to gain access to data. (SCI billets,
SAR access, etc.)
</p><p>
<b>baseline:</b> In CM, the classic approach where at any given time there
is a "version" of the system which is held pure until the CCB changes to
the next baseline.
</p><p>
<b>BPOC:</b> business point of contact: The person at the NCSC responsible
for dealing with the business aspects of the RAMP program of a particular
vendor.
</p><p>
<b>capabilities:</b> DAC, access control based upon an unforgeable permission
for access which comes with the subject.
</p><p>
<b>cascading:</b> In controlled mode networks where two networks connect
with disparate ranges, the possibility that the lower-cleared users on the
lower-ranged net will gain access to the higher-ranged data on the higher
ranged net.
</p><p>
<b>centralized:</b> DAC, access control where all control permissions rest
with a centralized person.
</p><p>
<b>clearing:</b> The rendering of media not readily able to be read; single
overwrite, etc. Sufficient for reuse of the media in a secure facility but
not sufficient to leave the facility.
</p><p>
<b>closed environment:</b> Lifecycle environment for a system where the
developers are cleared and authorized for the data to be processed (or at
least to the Secret level) and CM is invoked to protect against malicious
logic insertion throughout the lifecycle.
</p><p>
<b>CM:</b> configuration management: The management of the system configuration
to ensure that the necessary changes are made without adversely affecting
the system security.
</p><p>
<b>Compartmented Mode:</b> The mode of operation suited to the conditions
prevalent when all users have clearances for all of the data but are not
formally authorized access to all of the data.
</p><p>
<b>compression/decompression:</b> In audit trails, when standard conditions
are given standard codes to relieve to massiveness of data flows and storage
with related decoding on retrieval. (Numeric codes for audit events vs. textual
accounts, etc.)
</p><p>
<b>computer security subsystem:</b> Hardware/software add-on packages to
handle (or expand upon) Audit, Identification and Authentication, Object
Reuse, or Discretionary Access Control.
</p><p>
<b>CCB:</b> configuration control board: Group set up to determine the need
and appropriateness of changes to the system configuration.
</p><p>
<b>Configuration control: </b>The CM task relating to evaluation and approval
of changes to the CM baseline.
</p><p>
<b>control objective:</b> The points behind the security requirements.
</p><p>
<b>control permission:</b> In DAC, the ability to change the access permissions.
</p><p>
<b>Controlled Mode:</b> A limited multilevel mode of operation where limits
are placed on the levels of data which can be processed.
</p><p>
<b>COTS: commercial off the shelf:</b> The development and production of
COTS secure systems is the goal of the NCSC.
</p><p>
<b>covert channel analysis:</b> The systematic investigation for possible
covert channels.
</p><p>
<b>covert channels:</b> The use of unintended data paths which are not under
TCB control to pass data in a manner not allowed by the security policy.
</p><p>
<b>covert storage channels:</b> Covert channels which make use of system
data stores.
</p><p>
<b>covert timing channels:</b> Covert channels which make use of modulation
of system timing and resource utilization.
</p><p>
<b>DAC: Discretionary Access Control: </b>The control of subjects accesses
to objects based on the subjects need-to-know.
</p><p>
<b>declassification:</b> The removal of all data from magnetic media to make
the media unclassified.
</p><p>
<b>Dedicated Mode:</b> The mode of operations appropriate when all users
have clearances, formal authorization, and need-to-know for all of the data
in the system.
</p><p>
<b>delete:</b> DAC, access mode which allows the subject to delete data from
the object.
</p><p>
<b>denial of service:</b> The undesirable condition where the authorized
users are not able to use the system effectively.
</p><p>
<b>design documentation:</b> The compilation of documents which define the
requirements and design for the secure system. Documentation requirements
vary with the class.
</p><p>
<b>device labels:</b> Internal labels on peripheral device to determine the
allowable levels of data to be processed.
</p><p>
<b>Dockmaster:</b> An NCSC sponsored and managed E-Mail and Bulletin Board
system.
</p><p>
<b>downgrade:</b> The act of writing data to an object of lower classification
than the subject.
</p><p>
<b>DTLS: Descriptive Top-Level Specification: </b>Top level specification
for a secure system written in English or design notation.
</p><p>
<b>electronic labels:</b> Data sensitivity labels which are stored in the
same (electronic) media as the data. At B1 and above, the labels are required
and should not be trusted upon below that level.
</p><p>
<b>EPL: Evaluated Product List: </b>NCSC list of secure systems which have
been evaluated and the class assigned.
</p><p>
<b>ETL: Endorsed Tools List:</b> NCSC list of endorsed formal verification
systems.
</p><p>
<b>execute:</b> DAC, access mode which allows subjects to run an executable
object (program).
</p><p>
<b>fixed magnetic media:</b> Magnetic media which cannot be readily removed
from the hardware.
</p><p>
<b>FTLS: Formal Top-Level Specification:</b> Top level specification for
a secure system written in formal mathematical specification language.
</p><p>
<b>group:</b> DAC, a set of users with intersecting needs-to-know. AKA: User
Group, Dissemination and Use Group, D&amp;UG, etc.
</p><p>
<b>guess rate:</b> How often a failed login attempt is allowed to be reattempted.
</p><p>
<b>hierarchical classifications:</b> Classification upon which greater then
works. (U, C, S, TS)
</p><p>
<b>human readable output:</b> Computer Output which a person can read. (Screen,
printer, etc.)
</p><p>
<b>I&amp;A: identification and authentication:</b> The mechanism which allows
the system to know who is on the system and who should not be on the system.
(Login)
</p><p>
<b>identification:</b> The passing of the identity of the subject to the
system as a part of I&amp;A.
</p><p>
<b>integrity policy: </b>The portion of the security policy which deals with
data corruption.
</p><p>
<b>label integrity:</b> The assurance that the data sensitivity label associated
with (exported) data is correct, uncorrupted and the right one.
</p><p>
<b>laissez-faire:</b> DAC, control permission methodology where the allowed
users of the data allow the data to be accessed by other users based on the
user's determination of need-to-know.
</p><p>
<b>least privilege:</b> Principle which calls for the least available level
of power to be used to perform needed actions. (Read not Read/Write, etc.)
</p><p>
<b>limited access:</b> A mode of operation roughly akin to Compartmented.
Falling into disuse.
</p><p>
<b>login:</b> The sequence of events which allow a user to identify himself
to the system and the system to verify the identity and right to access.
</p><p>
<b>MAC: Mandatory Access Control: </b>Access based on formal clearances and
classifications.
</p><p>
<b>magnetic media:</b> Data storage based on magnetic field manipulation.
(Tapes, floppies, etc.)
</p><p>
<b>magnetic remanence:</b> Traces of data left after clearing operations
have been executed (and not present after declassification) on magnetic media.
</p><p>
<b>marking:</b> The labeling of data within the system for access control
purposes.
</p><p>
<b>maximum data sensitivity:</b> In risk quantification, the maximum sensitivity
of the data allowed to be processed, stored, or transmitted by the system.
</p><p>
<b>minimum user clearance:</b> In risk quantification, the maximum clearance
level of the lowest cleared user allowed on the system.
</p><p>
<b>mode of operation:</b> The allowable conditions for the operation of a
trusted system, including data sensitivities and user clearances.
</p><p>
<b>multilevel devices: </b>Computer devices which are allowed to operate
on data of various classifications at the same time.
</p><p>
<b>Multilevel Mode:</b> The mode of operations used when not all of the users
have formal clearances, authorizations, and needs-to-know for all of the
data on the system.
</p><p>
<b>NCSC: National Computer Security Center:</b> Organization set up to foster
computer security availability, especially in COTS systems. (Formerly DoD
[NSA], presently NIST.[Sorta])
</p><p>
<b>non-hierarchical classifications: </b>Classifications without true
rankings.(noforn, etc.)
</p><p>
<b>non-repudiation:</b> In networks, the receipted and guaranteed delivery
of data.
</p><p>
<b>open environment:</b> Development environment with no Guarantees regarding
malicious logic.
</p><p>
<b>Operator:</b> The person who runs the computer for system starts, shutdown,
tape mounting, etc. (May or may not be a system user.)
</p><p>
<b>OR: object reuse: </b>The mechanisms which ensure that the new user of
a storage object (buffer, disk, etc.) gains no knowledge of the data stored
by the previous user.
</p><p>
<b>ownership:</b> DAC, control permission methodology where the owners of
the data allow the data to be accessed by users based on the owners'
determination of need-to-know.
</p><p>
<b>password:</b> A character string or phrase used to authenticate the validity
of a login identity.
</p><p>
<b>PoP: Philosophy of Protection: </b>Statement of the protection scheme
for a system, in English.
</p><p>
<b>profiles:</b> DAC, access control based on a listing of objects available
to the subject in question.
</p><p>
<b>protection bits:</b> DAC, access control based on Self, Group, and World
associations.
</p><p>
<b>RAMP: RAting Maintenance Phase: </b>An NCSC program to allow future versions
of evaluated products to be placed on the EPL without full new evaluation.
</p><p>
<b>read:</b> DAC, access mode which allows information to flow form the object
to the subject.
</p><p>
<b>reboot:</b> Cycling the power of the system, especially a small system,
to wipe all volatile memory before operating at a new classification level.
</p><p>
<b>reference monitor: </b>A mechanism which monitors all subject/object access
attempts and allows those attempts which are proper.
</p><p>
<b>Risk Index: </b>A quantitative measure of the risk on a system, based
on the disparity between the user clearances and the data sensitivity.
</p><p>
<b>secrecy policy:</b> The part of the security policy which deals with proper
dissemination of data.
</p><p>
<b>Secure Operator:</b> Special operator who runs the security relevant portions
of a secure system.
</p><p>
<b>Security Administrator:</b> The role in a secure facility concerned with
overall computer security. In a lower class system (B1 or lower) may be the
only player.
</p><p>
<b>Security Features User's Guide: </b>Single reference point for the description
of the security features of the system and their use.
</p><p>
<b>security level:</b> The combination of hierarchical and non-hierarchical
classification which represent the sensitivity of the information.
</p><p>
<b>security policy model: </b>A model of the security policy to show how
the policy will be implemented for a secure system.
</p><p>
<b>security policy:</b> A statement of the security policy to be enforced
by a secure system.
</p><p>
<b>selective collection:</b> In audit, the collection of specified events
and event types to reduce the volume of data collected to render the analysis
of the data easier.
</p><p>
<b>selective reduction:</b> In audit, the selection of specified events and
event type which have been collected to render the analysis of the data easier.
</p><p>
<b>sensitivity label:</b> A label which represents the security level of
the information.
</p><p>
<b>single level devices:</b> Peripheral devices which are allowed to handle
only one level of data.
</p><p>
<b>SL: </b>Ill-defined acronym, used variously as 'Sensitivity Label', 'Security
Level', 'Sensitivity Level', and 'Security Label'.
</p><p>
<b>System High Mode: </b>The mode of operations suitable for use when all
users have clearances and formal authorizations for all data, but not all
users have need-to-know for all of the data.
</p><p>
<b>System Programmer:</b> The role in a secure facility which is concerned
with the programmer aspects of the facility including bit-level repairs.
</p><p>
<b>TAR: Technical Assessment Report:</b> The name for the report covering
the evaluation of a formal verification system.
</p><p>
<b>TCB: Trusted Computing Base:</b> The mechanisms which enforce the security
policy.
</p><p>
<b>TD: Trusted Distribution:</b> The distribution of the TCB, especially
updates to the software, in such a way that the product delivered is the
product which was sent.
</p><p>
<b>threat:</b> Anything which can cause harm to the system, including
destruction, disclosure, or modification of the data or denial of service.
</p><p>
<b>TPOC: Technical Point of Contact:</b> The person at the NCSC responsible
for dealing with the technical aspects of the RAMP program of a particular
vendor.
</p><p>
<b>Trusted Facility Manual:</b> The manual which tells the security administrator
about the trusted facility including cautionary remarks.
</p><p>
<b>trusted identification forwarding:</b> The method of inter-network I&amp;A
where the Home system tells the Visited system that the user is that user.
</p><p>
<b>trusted path:</b> A communications path between the user and the TCB which
can be used for login, etc., and which cannot be faked.
</p><p>
<b>trusted recovery:</b> The ability to bring the system back from a crash
or degraded mode with the secure state untarnished.
</p><p>
<b>user:</b> Person accessing the computer system.
</p><p>
<b>UserID:</b> The unique 'name' for a user recognized by the TCB for I&amp;A
purposes.
</p><p>
<b>VR: Vendor Report:</b> The vendor's input to the evaluation of formal
verification systems.
</p><p>
<b>VSA: Vendor Security Analyst:</b> NCSC trained and recognized security
person working for the vendor on a particular system in the RAMP program.
</p><p>
<b>write access:</b> DAC, the access mode which allows information flow in
both directions between subject and object. Essentially, Read Access and
Write-Append Access.
</p><p>
<b>write-append access:</b> DAC, the access mode which allows information
to flow from the subject to the object but not from the object to the object.
(Write without Read.)
</p><p>
  </p><hr>
<p>
<i>[End of document]</i>
</p><p>
RTF to HTML by <a href="http://jya.com/index.htm">JYA/Urban Deadline</a>.
</p><p>

</p></body></html>